<!DOCTYPE html><html lang="en"> <head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><link rel="icon" type="image/svg+xml" href="/favicon.ico"><link rel="canonical" href="https://www.biosconfessions.com/posts/how-the-control-unit-makes-the-cpu-work-signals-microcode-and-decoding/"><meta name="generator" content="Astro v5.15.1"><!-- Google tag (gtag.js) --><script async src="https://www.googletagmanager.com/gtag/js?id=G-E96HPDSNG8">
        </script><script>
            window.dataLayer = window.dataLayer || [];
            window.gtag = function gtag(){ window.dataLayer.push(arguments); };

            window.gtag("js", new Date());
            window.gtag("consent", "default", {
                ad_storage: "denied",
                ad_user_data: "denied",
                ad_personalization: "denied",
                analytics_storage: "denied",
            });

            window.gtag("config", "G-E96HPDSNG8");
        </script><!-- Global Metadata --><title>How the Control Unit Makes the CPU Work: Signals, Microcode, and Decoding | BIOS Confessions</title><meta name="author" content="Gianni"><meta name="title" content="How the Control Unit Makes the CPU Work: Signals, Microcode, and Decoding | BIOS Confessions"><meta name="description" content="Understand how the CPU Control Unit fetches, decodes, and executes instructions. Learn the differences between hardwired and microprogrammed control with clear examples."><meta name="keywords" content="Computer Architecture, control unit, cpu control unit, microprogrammed control, hardwired control, microcode, fetch decode execute, computer architecture basics"><link rel="sitemap" href="/sitemap-index.xml"><link rel="alternate" type="application/rss+xml" title="How the Control Unit Makes the CPU Work: Signals, Microcode, and Decoding | BIOS Confessions" href="https://www.biosconfessions.com/rss.xml"><!-- Open Graph / Facebook --><meta property="og:title" content="How the Control Unit Makes the CPU Work: Signals, Microcode, and Decoding | BIOS Confessions"><meta property="og:description" content="Understand how the CPU Control Unit fetches, decodes, and executes instructions. Learn the differences between hardwired and microprogrammed control with clear examples."><meta property="og:type" content="website"><meta property="og:url" content="https://www.biosconfessions.com/posts/how-the-control-unit-makes-the-cpu-work-signals-microcode-and-decoding/"><meta property="og:image" content="https://www.biosconfessions.com/[object%20Object]"><!-- Twitter --><meta property="twitter:title" content="How the Control Unit Makes the CPU Work: Signals, Microcode, and Decoding | BIOS Confessions"><meta property="twitter:description" content="Understand how the CPU Control Unit fetches, decodes, and executes instructions. Learn the differences between hardwired and microprogrammed control with clear examples."><meta property="twitter:url" content="https://www.biosconfessions.com/posts/how-the-control-unit-makes-the-cpu-work-signals-microcode-and-decoding/"><meta property="twitter:image" content="https://www.biosconfessions.com/[object%20Object]"><meta property="twitter:card" content="summary_large_image"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/katex.min.css"><link rel="stylesheet" href="/assets/index.mFaSQr23.css"></head> <body class="bg-silicon-100 scroll-smooth flex flex-col min-h-screen">  <header id="header" class="py-3" role="banner"> <div class="mx-auto max-w-6xl px-4 sm:px-6 lg:px-8 py-1 w-full">  <nav class="flex flex-wrap lg:grid lg:grid-cols-12 basis-full items-center" aria-label="Primary navigation"> <!-- Logo --> <div class="lg:col-span-3 flex items-center"> <a href="/" class="flex-none rounded-xl text-2xl inline-block font-bold focus-visible:outline focus-visible:outline-2 focus-visible:outline-offset-2 focus-visible:outline-gray-400" aria-label="BIOS Confessions homepage">
BIOS Confessions
</a> </div> <!-- Button Group --> <div class="flex items-center gap-x-1 lg:gap-x-2 ms-auto py-1 lg:ps-6 lg:order-3 lg:col-span-3"> <!-- Search Button --> <button type="button" id="search-button" class="size-9.5 relative flex justify-center items-center rounded-xl bg-silicon-50 border border-silicon-200 text-black hover:bg-silicon-0 focus:outline-hidden focus:bg-silicon-0 disabled:opacity-50 disabled:pointer-events-none" aria-label="Open search"> <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="2.5" stroke="currentColor" class="size-4" data-slot="icon" aria-hidden="true"> <path stroke-linecap="round" stroke-linejoin="round" d="m21 21-5.197-5.197m0 0A7.5 7.5 0 1 0 5.196 5.196a7.5 7.5 0 0 0 10.607 10.607Z"></path> </svg> </button> <!-- Mobile Menu Toggle --> <div class="lg:hidden"> <button type="button" id="collapse-button" class="size-9.5 flex justify-center items-center text-sm font-semibold rounded-xl bg-silicon-50 border border-silicon-200 text-black hover:bg-silicon-0 focus:outline-hidden focus:bg-silicon-0 disabled:opacity-50 disabled:pointer-events-none" aria-expanded="false" aria-controls="primary-menu" aria-label="Toggle navigation"> <!-- Hamburger Icon --> <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" stroke="currentColor" class="size-5" data-slot="icon" aria-hidden="true"> <line x1="3" x2="21" y1="6" y2="6"></line> <line x1="3" x2="21" y1="12" y2="12"></line> <line x1="3" x2="21" y1="18" y2="18"></line> </svg> <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" stroke="currentColor" class="hidden size-5" data-slot="icon" aria-hidden="true"> <path d="M18 6 6 18"></path> <path d="m6 6 12 12"></path> </svg> </button> </div> </div> <!-- Collapsible Navigation --> <div id="collapse" class="hidden overflow-hidden transition-all duration-300 basis-full grow lg:block lg:w-auto lg:basis-auto lg:order-2 lg:col-span-6" role="region" aria-label="Main menu" aria-hidden="true"> <ul id="primary-menu" class="flex flex-col gap-y-4 gap-x-0 mt-5 lg:flex-row lg:justify-center lg:items-center lg:gap-y-0 lg:gap-x-7 lg:mt-0" role="menubar"> <li role="none"> <a href="/" role="menuitem" class="inline-block text-black focus-visible:outline focus-visible:outline-2 focus-visible:outline-offset-2 focus-visible:outline-gray-400 hover:text-gray-600 focus:text-gray-600"> Home </a> </li><li role="none"> <a href="/posts" role="menuitem" class="inline-block text-black focus-visible:outline focus-visible:outline-2 focus-visible:outline-offset-2 focus-visible:outline-gray-400 hover:text-gray-600 focus:text-gray-600"> Posts </a> </li><li role="none"> <a href="/about" role="menuitem" class="inline-block text-black focus-visible:outline focus-visible:outline-2 focus-visible:outline-offset-2 focus-visible:outline-gray-400 hover:text-gray-600 focus:text-gray-600"> Hello World </a> </li> </ul> </div> </nav>  </div> </header> <script type="module">document.addEventListener("DOMContentLoaded",()=>{const e=document.querySelector("#collapse-button"),t=document.querySelector("#collapse");if(!e||!t)return;const[n,d]=e.querySelectorAll("svg");e.addEventListener("click",()=>{const o=e.getAttribute("aria-expanded")==="true";e.setAttribute("aria-expanded",String(!o)),t.classList.toggle("hidden"),n.classList.toggle("hidden"),d.classList.toggle("hidden")}),document.querySelector("#search-button")?.addEventListener("click",()=>{window.dispatchEvent(new Event("openModal"))})});</script> <main id="main" class="shrink-0" role="main" tabindex="-1"> <article id="post" class="mt-20" aria-labelledby="post-heading"> <div class="mx-auto max-w-6xl px-4 sm:px-6 lg:px-8 py-1 w-full">  <header class="text-center mb-10 sm:mb-14"> <h1 id="post-heading" class="font-bold text-3xl sm:text-4xl mb-3"> How the Control Unit Makes the CPU Work: Signals, Microcode, and Decoding </h1> <p class="sr-only"> An article titled How the Control Unit Makes the CPU Work: Signals, Microcode, and Decoding by Gianni, published on November 16, 2025. </p> </header> <section class="flex flex-col sm:flex-row sm:items-center sm:justify-between my-8" aria-label="Post metadata"> <div> <p class="text-gray-800 font-semibold"> <span class="sr-only">Written by </span>Gianni </p> <div class="flex flex-wrap items-center gap-4 text-gray-600"> <time datetime="November 16, 2025" aria-label="Published on November 16, 2025"> November 16, 2025 </time> <span class="w-1 h-1 bg-gray-600 rounded-full" aria-hidden="true"></span> <p aria-label="Estimated reading time: 7 min"> 7 min </p> <span class="bg-yellow-200 text-yellow-800 text-sm font-medium px-2.5 py-0.5 rounded-full"> Intermediate </span> </div> </div> <aside class="flex items-center gap-3 mt-7.5 sm:mt-0" aria-label="Share this article"> <p class="text-gray-600">Share:</p> <div class="flex items-center gap-3"> <a aria-label="Share on X" title="Share on X" href="https://x.com/intent/tweet?url=https%3A%2F%2Fwww.biosconfessions.com%2Fposts%2Fhow-the-control-unit-makes-the-cpu-work-signals-microcode-and-decoding%2F&text=How%20the%20Control%20Unit%20Makes%20the%20CPU%20Work%3A%20Signals%2C%20Microcode%2C%20and%20Decoding" target="_blank" rel="noopener noreferrer" class="rounded-sm bg-gray-900 hover:bg-transparent p-1 text-silicon-0 hover:text-gray-900 transition"> <svg xmlns="http://www.w3.org/2000/svg" class="size-5" viewBox="0 0 1200 1227" fill="none"> <g> <path d="M714.163 519.284L1160.89 0H1055.03L667.137 450.887L357.328 0H0L468.492 681.821L0 1226.37H105.866L515.491 750.218L842.672 1226.37H1200L714.137 519.284H714.163ZM569.165 687.828L521.697 619.934L144.011 79.6944H306.615L611.412 515.685L658.88 583.579L1055.08 1150.3H892.476L569.165 687.854V687.828Z" fill="currentColor"></path> </g> <defs> <clipPath id="clip0_1_2"> <rect width="1200" height="1227" fill="none"></rect> </clipPath> </defs> </svg> </a> <a aria-label="Share on Facebook" title="Share on Facebook" href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.biosconfessions.com%2Fposts%2Fhow-the-control-unit-makes-the-cpu-work-signals-microcode-and-decoding%2F" target="_blank" rel="noopener noreferrer" class="rounded-xl hover:text-[#4267B2] transition"> <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 512 512" class="size-7"> <path d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" fill="currentColor"></path> </svg> </a> <a aria-label="Share on LinkedIn" title="Share on LinkedIn" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3A%2F%2Fwww.biosconfessions.com%2Fposts%2Fhow-the-control-unit-makes-the-cpu-work-signals-microcode-and-decoding%2F&title=How%20the%20Control%20Unit%20Makes%20the%20CPU%20Work%3A%20Signals%2C%20Microcode%2C%20and%20Decoding" target="_blank" rel="noopener noreferrer" class="rounded-xl hover:text-[#0077B5] transition"> <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 512 512" class="size-7"> <path d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" fill="currentColor"></path> </svg> </a> <a aria-label="Share on Reddit" title="Share on Reddit" href="https://www.reddit.com/submit?url=https%3A%2F%2Fwww.biosconfessions.com%2Fposts%2Fhow-the-control-unit-makes-the-cpu-work-signals-microcode-and-decoding%2F&title=How%20the%20Control%20Unit%20Makes%20the%20CPU%20Work%3A%20Signals%2C%20Microcode%2C%20and%20Decoding" target="_blank" rel="noopener noreferrer" class="rounded-xl hover:text-[#FF4500] transition"> <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 512 512" class="size-7"> <path d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" fill="currentColor"></path> </svg> </a> </div> </aside> </section> <figure class="mb-10 sm:mb-14"> <img src="/assets/BannerIntroduction.B_LErQtH_Z1K0qVq.webp" alt="Collection of computer components" loading="eager" decoding="async" fetchpriority="auto" width="1200" height="675" class="w-full max-h-[50vh] object-cover rounded-xl"> <figcaption class="sr-only">
Hero banner for the post titled How the Control Unit Makes the CPU Work: Signals, Microcode, and Decoding </figcaption> </figure>  </div> <div class="mx-auto max-w-4xl px-4 sm:px-6 lg:px-8 py-1 w-full"> <article class="prose !max-w-none mb-10 sm:mb-14"> <p>In the previous chapter, we explored the <strong>Arithmetic Logic Unit (ALU)</strong>, the part of the CPU responsible for performing arithmetic and logic operations. We saw how it can add, subtract, compare, and make decisions depending on the <strong>control signals</strong> it receives. But this raises an important question: <em>where do those control signals come from?</em> That’s the job of the <strong>Control Unit (CU),</strong> the CPU’s internal <strong>orchestrator</strong>.</p>
<h2 id="the-control-units-role">The Control Unit’s Role</h2>
<p>If we think of the CPU as a small orchestra, the <strong>ALU</strong> would be the musician, performing the actual notes (the operations). The <strong>Control Unit</strong>, on the other hand, is the <strong>conductor</strong>, ensuring that every part of the CPU works in perfect timing.</p>
<p>The Control Unit doesn’t do the math itself, but it <strong>directs</strong> all the components that do. It tells the ALU when to add or subtract, instructs the registers when to store or load data, and coordinates with memory to fetch new instructions.</p>
<p>In short, the Control Unit:</p>
<ul>
<li><strong>Fetches</strong> instructions from memory</li>
<li><strong>Decodes</strong> what those instructions mean</li>
<li><strong>Directs</strong> the ALU, registers, and memory to carry them out</li>
<li><strong>Repeats</strong> this cycle continuously</li>
</ul>
<p>This ongoing rhythm is known as the <strong>Fetch–Decode–Execute cycle</strong>. We’ll explore this cycle step by step in <strong>Chapter 6</strong>, once we’ve seen how the rest of the CPU fits together.</p>
<h2 id="hardwired-vs-microprogrammed-control">Hardwired vs. Microprogrammed Control</h2>
<p>Not all Control Units are built the same way. Broadly speaking, there are two main design approaches:</p>
<h3 id="1-hardwired-control">1. Hardwired Control</h3>
<p>In a <strong>hardwired control unit</strong>, control signals are generated directly by fixed electronic circuits made up of logic gates, flip-flops, and decoders. Each instruction’s behaviour is physically built into the hardware wiring.</p>
<ul>
<li><strong>Pros:</strong>
<ul>
<li>Speedy (no intermediate steps).</li>
<li>Efficient for simple instruction sets.</li>
</ul>
</li>
<li><strong>Cons:</strong>
<ul>
<li>It is difficult to modify, as changing the instruction set requires redesigning the hardware.</li>
<li>Complex to build for large CPUs with many instructions.</li>
</ul>
</li>
</ul>
<p>This approach is common in small or specialised processors (like microcontrollers), where performance and simplicity matter more than flexibility.</p>
<h3 id="2-microprogrammed-control">2. Microprogrammed Control</h3>
<p>In contrast, a <strong>microprogrammed control unit</strong> works more like a tiny interpreter.</p>
<p>Instead of using fixed wiring, it stores small <strong>microinstructions</strong> in a special memory area called the <strong>control store</strong>. Each microinstruction tells the CPU which control signals to activate during one small step of an operation.</p>
<p>So when the CPU executes a normal instruction (like <code>ADD A, B</code>), the Control Unit actually runs a short <strong>microprogram,</strong> a sequence of low-level steps that cause the ALU, registers, and buses to act in the right order.</p>
<ul>
<li><strong>Pros:</strong>
<ul>
<li>Easier to modify or extend (you can change the microcode instead of the hardware).</li>
<li>Ideal for complex instruction sets (like in older CISC CPUs).</li>
</ul>
</li>
<li><strong>Cons:</strong>
<ul>
<li>Slightly slower than hardwired designs, since each instruction is interpreted internally.</li>
</ul>
</li>
</ul>
<p>Modern CPUs often blend both approaches; some parts are hardwired for speed, while others use microcode for flexibility. x86 processors (like those from Intel and AMD) are a perfect example of a <strong>hybrid</strong> design:</p>
<ul>
<li>
<p><strong>Simple instructions</strong> such as <code>ADD</code>, <code>SUB</code>, <code>AND</code>, or <code>MOV</code> are usually handled by <strong>hardwired control</strong>.</p>
<p>These can be executed in just a few fast steps, so wiring them directly into hardware keeps performance high.</p>
</li>
<li>
<p><strong>Complex instructions</strong>, like <code>REP MOVSB</code> (which copies an entire block of memory) or older instructions that are kept for backwards compatibility are handled using <strong>microcode</strong>.</p>
<p>Internally, the CPU breaks these complicated instructions into a sequence of simpler micro-operations and runs them like a tiny program.</p>
</li>
</ul>
<p>This way, the CPU gets the <strong>speed</strong> of hardwired control for the common operations, and the <strong>flexibility</strong> of microcode for everything else, without needing to redesign the hardware every time the instruction set changes.</p>
<h2 id="how-instructions-are-decoded">How Instructions Are Decoded</h2>
<p>Every program you run, from a web browser to a video game, ultimately boils down to a long list of machine instructions. Each instruction is just a binary number. The Control Unit must interpret that number to decide what to do.</p>
<p>Let’s look at a simplified example. Suppose we have an 8-bit CPU where each instruction is one byte (8 bits):</p>
<pre class="astro-code github-light" style="background-color:#fff;color:#24292e;overflow-x:auto;white-space:pre-wrap;word-wrap:break-word" tabindex="0" data-language="bash"><code><span class="line"><span style="color:#6F42C1">Instruction:</span><span style="color:#005CC5"> 0100</span><span style="color:#005CC5"> 1010</span></span></code></pre>
<p>The Control Unit might divide this instruction into parts like this:</p>

















<table><thead><tr><th><strong>Bits</strong></th><th><strong>Meaning</strong></th></tr></thead><tbody><tr><td>0100</td><td>Operation code (Opcode) → tells the CPU what to do</td></tr><tr><td>1010</td><td>Operand → tells the CPU which register or memory address to use</td></tr></tbody></table>
<p>When the Control Unit reads this instruction, it <strong>decodes</strong> the opcode (<code>0100</code>) to determine which control signals to activate.</p>
<p>For example, opcode <code>0100</code> might mean “ADD,” while <code>0101</code> could mean “SUBTRACT.”</p>
<p>It then sends the appropriate signals:</p>
<ul>
<li>Enable the ALU’s “add” circuit.</li>
<li>Load inputs from registers A and B</li>
<li>Store the result back into register A</li>
</ul>
<p>All of this happens automatically, step by step, as the CPU clock ticks.</p>
<h2 id="timing-and-coordination">Timing and Coordination</h2>
<p>Computers work in rhythm. Every operation, from fetching data to performing arithmetic, happens in sync with the <strong>clock</strong>. The clock doesn’t measure time like a wall clock; instead, it provides a steady beat that synchronises all internal actions.</p>
<p>On each clock pulse, the Control Unit advances the CPU to its next step: reading an instruction, setting up the ALU, or writing a result back to memory. This precise timing ensures that signals don’t collide and that every operation occurs exactly when it should.</p> </article> <footer aria-label="Post tags" class="flex flex-wrap items-center gap-3 mb-10 sm:mb-14"> <p class="text-gray-600">Tags:</p> <ul class="flex flex-wrap items-center gap-3" role="list"> <li key="Computer Architecture"> <a href="/tags/computer-architecture" aria-label="View posts tagged Computer Architecture" class="focus-visible:outline focus-visible:outline-2 focus-visible:outline-blue-600 rounded"> <span class="bg-gray-300 text-gray-800 text-xs font-medium px-2.5 py-0.5 rounded-full"> 
#computer-architecture </span> </a> </li> </ul> </footer> <nav class="flex justify-center mb-10 lg:mb-14 gap-3" aria-label="Post navigation"> <section class="w-full max-w-3xl mx-auto text-center" aria-label="Navigation for From Transistor to System: A Friendly Guide to Computer Architecture"> <!-- Header --> <h2 class="text-lg font-semibold text-gray-800 mb-6">
Part of the <span class="text-blue-600">From Transistor to System: A Friendly Guide to Computer Architecture</span> series
</h2> <!-- Chapter List --> <ol class="flex flex-wrap justify-center gap-2 mb-8" aria-label="From Transistor to System: A Friendly Guide to Computer Architecture chapters"> <li key="from-transistor-to-system-a-friendly-guide-to-computer-architecture/0-introduction.mdx"> <a href="/posts/introduction-computer-architecture" class="inline-block px-3 py-1.5 rounded-lg border text-sm transition
            bg-silicon-50 border-silicon-200 text-gray-700 hover:bg-silicon-0"> 0. Intro </a> </li><li key="from-transistor-to-system-a-friendly-guide-to-computer-architecture/1-transistor.mdx"> <a href="/posts/transistors-the-tiny-switch-that-powers-modern-computers" class="inline-block px-3 py-1.5 rounded-lg border text-sm transition
            bg-silicon-50 border-silicon-200 text-gray-700 hover:bg-silicon-0"> 1. Transistor </a> </li><li key="from-transistor-to-system-a-friendly-guide-to-computer-architecture/2-logic.mdx"> <a href="/posts/understanding-logic-gates-and-or-xor-nand-adders-and-flip-flops" class="inline-block px-3 py-1.5 rounded-lg border text-sm transition
            bg-silicon-50 border-silicon-200 text-gray-700 hover:bg-silicon-0"> 2. Logic </a> </li><li key="from-transistor-to-system-a-friendly-guide-to-computer-architecture/3-alu.mdx"> <a href="/posts/understanding-the-alu-arithmetic-logic-and-control-signals-explained" class="inline-block px-3 py-1.5 rounded-lg border text-sm transition
            bg-silicon-50 border-silicon-200 text-gray-700 hover:bg-silicon-0"> 3. ALU </a> </li><li key="from-transistor-to-system-a-friendly-guide-to-computer-architecture/4-control-unit.mdx"> <a href="/posts/how-the-control-unit-makes-the-cpu-work-signals-microcode-and-decoding" class="inline-block px-3 py-1.5 rounded-lg border text-sm transition
            bg-blue-600 border-blue-600 text-white font-semibold" aria-current="page"> 4. Control Unit </a> </li> </ol> <!-- Prev / Next Buttons --> <div class="flex justify-center items-center gap-4"> <a href="/posts/understanding-the-alu-arithmetic-logic-and-control-signals-explained" class="inline-flex items-center gap-1 px-4 py-2 text-sm rounded-lg border border-silicon-200 bg-silicon-50 hover:bg-silicon-0"> <svg xmlns="http://www.w3.org/2000/svg" fill="currentColor" viewBox="0 0 20 20" class="size-4" data-slot="icon" aria-hidden="true"> <path d="M11.78 5.22a.75.75 0 0 1 0 1.06L8.06 10l3.72 3.72a.75.75 0 1 1-1.06 1.06l-4.25-4.25a.75.75 0 0 1 0-1.06l4.25-4.25a.75.75 0 0 1 1.06 0Z" clip-rule="evenodd" fill-rule="evenodd"></path> </svg> ALU </a>  </div> </section> </nav> </div> </article> </main> <footer id="footer" class="mt-auto text-gray-600" role="contentinfo"> <div class="mx-auto max-w-6xl px-4 sm:px-6 lg:px-8 py-1 w-full">   <div class="flex flex-col sm:flex-row justify-between gap-4 py-6"> <!-- Site description --> <section aria-labelledby="footer-about" class="sm:max-w-2/5"> <h2 id="footer-about" class="font-bold text-gray-700 mb-2">
BIOS Confessions
</h2> <p class="text-sm text-gray-500">
Our mission is to help curious minds grow by learning,
                    experimenting, and sharing knowledge in the world of
                    computer science.
</p> </section> <!-- Navigation --> <nav aria-labelledby="footer-navigation"> <h2 id="footer-navigation" class="font-bold text-gray-700">
Navigation
</h2> <ul class="mt-3 space-y-3 text-sm" role="list"> <li> <a href="/" class="inline-flex gap-x-2 text-gray-500 hover:text-gray-800 focus-visible:outline focus-visible:outline-2 focus-visible:outline-offset-2 focus-visible:outline-gray-400"> Home </a> </li><li> <a href="/posts" class="inline-flex gap-x-2 text-gray-500 hover:text-gray-800 focus-visible:outline focus-visible:outline-2 focus-visible:outline-offset-2 focus-visible:outline-gray-400"> Posts </a> </li><li> <a href="/about" class="inline-flex gap-x-2 text-gray-500 hover:text-gray-800 focus-visible:outline focus-visible:outline-2 focus-visible:outline-offset-2 focus-visible:outline-gray-400"> About </a> </li><li> <a href="/search" class="inline-flex gap-x-2 text-gray-500 hover:text-gray-800 focus-visible:outline focus-visible:outline-2 focus-visible:outline-offset-2 focus-visible:outline-gray-400"> Search </a> </li><li> <a href="/tags" class="inline-flex gap-x-2 text-gray-500 hover:text-gray-800 focus-visible:outline focus-visible:outline-2 focus-visible:outline-offset-2 focus-visible:outline-gray-400"> Tags </a> </li><li> <a href="/collections" class="inline-flex gap-x-2 text-gray-500 hover:text-gray-800 focus-visible:outline focus-visible:outline-2 focus-visible:outline-offset-2 focus-visible:outline-gray-400"> Collections </a> </li> </ul> </nav> <!-- Contact --> <section aria-labelledby="footer-contact"> <h2 id="footer-contact" class="font-bold text-gray-700 mb-2">
Contact
</h2> <a href="mailto:biosconfessions@gmail.com" class="text-sm text-gray-500 hover:text-gray-800 focus-visible:outline focus-visible:outline-2 focus-visible:outline-offset-2 focus-visible:outline-gray-400">
biosconfessions@gmail.com
</a> </section> </div>  <div class="border-t border-silicon-200 py-6"> <div class="flex flex-col sm:flex-row justify-center sm:justify-between items-center gap-4"> <p class="text-xs text-gray-600">
&copy; 2025 BIOS Confessions.
</p> <div class="flex gap-4"> <a href="/privacy-statement" class="text-xs text-gray-500 underline hover:text-gray-800 hover:decoration-2 focus-visible:outline focus-visible:outline-2 focus-visible:outline-offset-2 focus-visible:outline-gray-400">
Privacy Statement
</a> <button type="button" class="text-xs text-gray-500 underline hover:text-gray-800 hover:decoration-2 focus-visible:outline focus-visible:outline-2 focus-visible:outline-offset-2 focus-visible:outline-gray-400" data-cc="show-preferencesModal">
Cookie Settings
</button> </div> </div> </div>  </div> </footer>  <style>astro-island,astro-slot,astro-static-slot{display:contents}</style><script>(()=>{var e=async t=>{await(await t())()};(self.Astro||(self.Astro={})).only=e;window.dispatchEvent(new Event("astro:only"));})();</script><script>(()=>{var A=Object.defineProperty;var g=(i,o,a)=>o in i?A(i,o,{enumerable:!0,configurable:!0,writable:!0,value:a}):i[o]=a;var d=(i,o,a)=>g(i,typeof o!="symbol"?o+"":o,a);{let i={0:t=>m(t),1:t=>a(t),2:t=>new RegExp(t),3:t=>new Date(t),4:t=>new Map(a(t)),5:t=>new Set(a(t)),6:t=>BigInt(t),7:t=>new URL(t),8:t=>new Uint8Array(t),9:t=>new Uint16Array(t),10:t=>new Uint32Array(t),11:t=>1/0*t},o=t=>{let[l,e]=t;return l in i?i[l](e):void 0},a=t=>t.map(o),m=t=>typeof t!="object"||t===null?t:Object.fromEntries(Object.entries(t).map(([l,e])=>[l,o(e)]));class y extends HTMLElement{constructor(){super(...arguments);d(this,"Component");d(this,"hydrator");d(this,"hydrate",async()=>{var b;if(!this.hydrator||!this.isConnected)return;let e=(b=this.parentElement)==null?void 0:b.closest("astro-island[ssr]");if(e){e.addEventListener("astro:hydrate",this.hydrate,{once:!0});return}let c=this.querySelectorAll("astro-slot"),n={},h=this.querySelectorAll("template[data-astro-template]");for(let r of h){let s=r.closest(this.tagName);s!=null&&s.isSameNode(this)&&(n[r.getAttribute("data-astro-template")||"default"]=r.innerHTML,r.remove())}for(let r of c){let s=r.closest(this.tagName);s!=null&&s.isSameNode(this)&&(n[r.getAttribute("name")||"default"]=r.innerHTML)}let p;try{p=this.hasAttribute("props")?m(JSON.parse(this.getAttribute("props"))):{}}catch(r){let s=this.getAttribute("component-url")||"<unknown>",v=this.getAttribute("component-export");throw v&&(s+=` (export ${v})`),console.error(`[hydrate] Error parsing props for component ${s}`,this.getAttribute("props"),r),r}let u;await this.hydrator(this)(this.Component,p,n,{client:this.getAttribute("client")}),this.removeAttribute("ssr"),this.dispatchEvent(new CustomEvent("astro:hydrate"))});d(this,"unmount",()=>{this.isConnected||this.dispatchEvent(new CustomEvent("astro:unmount"))})}disconnectedCallback(){document.removeEventListener("astro:after-swap",this.unmount),document.addEventListener("astro:after-swap",this.unmount,{once:!0})}connectedCallback(){if(!this.hasAttribute("await-children")||document.readyState==="interactive"||document.readyState==="complete")this.childrenConnectedCallback();else{let e=()=>{document.removeEventListener("DOMContentLoaded",e),c.disconnect(),this.childrenConnectedCallback()},c=new MutationObserver(()=>{var n;((n=this.lastChild)==null?void 0:n.nodeType)===Node.COMMENT_NODE&&this.lastChild.nodeValue==="astro:end"&&(this.lastChild.remove(),e())});c.observe(this,{childList:!0}),document.addEventListener("DOMContentLoaded",e)}}async childrenConnectedCallback(){let e=this.getAttribute("before-hydration-url");e&&await import(e),this.start()}async start(){let e=JSON.parse(this.getAttribute("opts")),c=this.getAttribute("client");if(Astro[c]===void 0){window.addEventListener(`astro:${c}`,()=>this.start(),{once:!0});return}try{await Astro[c](async()=>{let n=this.getAttribute("renderer-url"),[h,{default:p}]=await Promise.all([import(this.getAttribute("component-url")),n?import(n):()=>()=>{}]),u=this.getAttribute("component-export")||"default";if(!u.includes("."))this.Component=h[u];else{this.Component=h;for(let f of u.split("."))this.Component=this.Component[f]}return this.hydrator=p,this.hydrate},e,this)}catch(n){console.error(`[astro-island] Error hydrating ${this.getAttribute("component-url")}`,n)}}attributeChangedCallback(){this.hydrate()}}d(y,"observedAttributes",["props"]),customElements.get("astro-island")||customElements.define("astro-island",y)}})();</script><astro-island uid="1Mi0CP" component-url="/assets/SearchModal.Dt4M_Us_.js" component-export="default" renderer-url="/assets/client.BfPWZUkF.js" props="{&quot;posts&quot;:[1,[[0,{&quot;id&quot;:[0,&quot;from-transistor-to-system-a-friendly-guide-to-computer-architecture/0-introduction.mdx&quot;],&quot;data&quot;:[0,{&quot;author&quot;:[0,&quot;Gianni&quot;],&quot;collection&quot;:[0,&quot;From Transistor to System: A Friendly Guide to Computer Architecture&quot;],&quot;chapter&quot;:[0,0],&quot;title&quot;:[0,&quot;Introduction: Computer Architecture&quot;],&quot;shortname&quot;:[0,&quot;Intro&quot;],&quot;date&quot;:[3,&quot;2025-09-03T00:00:00.000Z&quot;],&quot;tags&quot;:[1,[[0,&quot;Featured&quot;],[0,&quot;Computer Architecture&quot;],[0,&quot;Introduction&quot;]]],&quot;metaTags&quot;:[1,[[0,&quot;Computer architecture explained&quot;],[0,&quot;How computers work&quot;],[0,&quot;Understanding computer systems&quot;],[0,&quot;Digital logic&quot;]]],&quot;difficulty&quot;:[0,&quot;Intermediate&quot;],&quot;readTime&quot;:[0,&quot;1 min&quot;],&quot;image&quot;:[0,{&quot;src&quot;:[0,&quot;/assets/BannerIntroduction.B_LErQtH.jpg&quot;],&quot;width&quot;:[0,1200],&quot;height&quot;:[0,675],&quot;format&quot;:[0,&quot;jpg&quot;]}],&quot;alt&quot;:[0,&quot;Collection of computer components&quot;],&quot;description&quot;:[0,&quot;Introduction for From Transistor to System: A Friendly Guide to Computer Architecture&quot;]}],&quot;body&quot;:[0,&quot;Every click, tap, and swipe hides a story. Beneath the apps, screens, and machines you use every day lies a hidden world of circuits, instructions, and clever engineering. This series takes you on a bottom-up journey from bits and bytes, through memory, storage, and CPUs, to the input and output devices that bridge the digital and physical worlds. By the end, computers won&#39;t feel like mysterious black boxes, but like beautifully crafted, logical machines.&quot;],&quot;filePath&quot;:[0,&quot;src/content/posts/from-transistor-to-system-a-friendly-guide-to-computer-architecture/0-introduction.mdx&quot;],&quot;assetImports&quot;:[1,[[0,&quot;./assets/BannerIntroduction.jpg&quot;]]],&quot;digest&quot;:[0,&quot;4415cddc9fe81ee6&quot;],&quot;deferredRender&quot;:[0,true],&quot;collection&quot;:[0,&quot;posts&quot;],&quot;slug&quot;:[0,&quot;from-transistor-to-system-a-friendly-guide-to-computer-architecture/0-introduction&quot;],&quot;render&quot;:[0,null]}],[0,{&quot;id&quot;:[0,&quot;finding-p-values-and-false-hope/0-introduction.mdx&quot;],&quot;data&quot;:[0,{&quot;author&quot;:[0,&quot;Quinn&quot;],&quot;collection&quot;:[0,&quot;Finding P values and false hope&quot;],&quot;chapter&quot;:[0,0],&quot;title&quot;:[0,&quot;Finding P Values and False Hope — Intro to Quantitative Finance&quot;],&quot;shortname&quot;:[0,&quot;Intro&quot;],&quot;date&quot;:[3,&quot;2025-11-09T00:00:00.000Z&quot;],&quot;tags&quot;:[1,[[0,&quot;Featured&quot;],[0,&quot;Data Science&quot;]]],&quot;metaTags&quot;:[1,[[0,&quot;Quantitative Finance&quot;],[0,&quot;Python&quot;],[0,&quot;Statistics&quot;],[0,&quot;Financial Modeling&quot;],[0,&quot;quantitative finance tutorial&quot;],[0,&quot;Python for finance&quot;],[0,&quot;financial mathematics&quot;],[0,&quot;risk management&quot;],[0,&quot;data science in finance&quot;],[0,&quot;option pricing models&quot;],[0,&quot;bond valuation&quot;],[0,&quot;p values in finance&quot;],[0,&quot;statistics and programming&quot;]]],&quot;difficulty&quot;:[0,&quot;Intermediate&quot;],&quot;readTime&quot;:[0,&quot;6 min&quot;],&quot;image&quot;:[0,{&quot;src&quot;:[0,&quot;/assets/BannerIntro.f-0OlGOr.jpg&quot;],&quot;width&quot;:[0,3148],&quot;height&quot;:[0,2100],&quot;format&quot;:[0,&quot;jpg&quot;]}],&quot;alt&quot;:[0,&quot;Desk of a finance worker&quot;],&quot;description&quot;:[0,&quot;Discover how mathematics, statistics, and Python come together to explain and predict financial market behavior. In this introduction to quantitative finance, explore core concepts like interest rates, compounding, risk management, and bond pricing through practical, code-driven examples.&quot;]}],&quot;body&quot;:[0,&quot;Welcome to this series, where we’ll explore how mathematics, statistics, and programming come together to understand —and sometimes predict —the movements of financial markets. Whether you&#39;re a curious learner or data enthusiast, this series will explore some essential quantitative finance concepts with practical Python examples.\r\n\r\nWe start this series by understanding some fundamentals of financial mathematics, including interest rates, compounding, and present value. We will discuss risk management—how to measure and mitigate financial uncertainty —and show how to implement some risk management tools.\r\n\r\nIn this series, we will also learn about bond pricing, understand dynamic stock price fluctuations, explore different models for option pricing, and much more.\r\n\r\nEach post in the series will combine clear financial intuition with Python-based implementations, helping you move from theory to practical application. By the end, you’ll have a solid foundation in both the quantitative concepts that drive modern finance and the computational tools used to bring them to life.&quot;],&quot;filePath&quot;:[0,&quot;src/content/posts/finding-p-values-and-false-hope/0-introduction.mdx&quot;],&quot;assetImports&quot;:[1,[[0,&quot;./assets/BannerIntro.jpg&quot;]]],&quot;digest&quot;:[0,&quot;2eeef65ddd8f1fab&quot;],&quot;deferredRender&quot;:[0,true],&quot;collection&quot;:[0,&quot;posts&quot;],&quot;slug&quot;:[0,&quot;finding-p-values-and-false-hope/0-introduction&quot;],&quot;render&quot;:[0,null]}],[0,{&quot;id&quot;:[0,&quot;from-transistor-to-system-a-friendly-guide-to-computer-architecture/1-transistor.mdx&quot;],&quot;data&quot;:[0,{&quot;author&quot;:[0,&quot;Gianni&quot;],&quot;collection&quot;:[0,&quot;From Transistor to System: A Friendly Guide to Computer Architecture&quot;],&quot;chapter&quot;:[0,1],&quot;title&quot;:[0,&quot;Transistors: The Tiny Switch That Powers Modern Computers&quot;],&quot;shortname&quot;:[0,&quot;Transistor&quot;],&quot;date&quot;:[3,&quot;2025-09-03T00:00:00.000Z&quot;],&quot;tags&quot;:[1,[[0,&quot;Computer Architecture&quot;],[0,&quot;Electrical Engineering&quot;]]],&quot;metaTags&quot;:[1,[[0,&quot;Transistor basics&quot;],[0,&quot;Semiconductors&quot;],[0,&quot;Digital electronics&quot;],[0,&quot;Transistors&quot;],[0,&quot;MOSFET&quot;],[0,&quot;Silicon doping&quot;],[0,&quot;N-type doping&quot;],[0,&quot;P-type doping&quot;],[0,&quot;How transistors work&quot;],[0,&quot;What is a transistor&quot;]]],&quot;difficulty&quot;:[0,&quot;Intermediate&quot;],&quot;readTime&quot;:[0,&quot;5 min&quot;],&quot;image&quot;:[0,{&quot;src&quot;:[0,&quot;/assets/BannerTransistors.CMDGdanU.jpg&quot;],&quot;width&quot;:[0,1200],&quot;height&quot;:[0,675],&quot;format&quot;:[0,&quot;jpg&quot;]}],&quot;alt&quot;:[0,&quot;Collection of hardware components&quot;],&quot;description&quot;:[0,&quot;A beginner-friendly introduction to how transistors work, from electricity fundamentals to semiconductor doping, MOSFET operation, and the invention that shaped modern computers.&quot;]}],&quot;body&quot;:[0,&quot;In this chapter, we will uncover the details of the tiny switch at the heart of modern computing: the transistor. We start with an introduction to electricity, then dive into the details of the transistor. We finish with a brief history lesson.\n\n## Electricity Basics\n\nBefore we begin with transistors, here is a quick introduction to electricity concepts: voltage, current, and binary states. Feel free to skip this section if you are already familiar with them. In electricity, voltage is the pressure from a power source that pushes electric charges through the circuit. You can see it as a water hose; the higher the pressure, the harder the water wants to flow. Current is the flow or movement of electric charge. More current means more charges are moving through the wire per second, like the flow of water through a hose. Binary states are fairly simple. There are two states:\n\n- Off, no current or below a threshold.\n- On, current is flowing or above a threshold.\n\n## What Exactly Is a Transistor?\n\nLet&#39;s begin with a question, the answer to which is simple, but the specifics can become quite complicated: *What is a transistor?* At its core, a **transistor** is an electronic switch that regulates the flow of electrical current. When the switch is **on**, it represents a `1`. When it&#39;s **off**, it represents a `0`. This simple on/off behaviour is the foundation on which digital computing is built. Everything inside your computer, like images, sounds, and programs, can be reduced to tiny switches flipping between `0` and `1`.  They are essentially little bits of electric current. You may be asking whether this is the origin of the word “bits” in the context of digital computing. No, don&#39;t get confused; the abbreviation “bits” stands for “binary digits.”\n\n## Semiconductors\n\nUnlike the light switch on your wall, a **transistor** is microscopic, has no moving parts, and requires no human hand to operate. This is made possible by the physics of **semiconductors**. A semiconductor is a material whose electrical conductivity lies between that of an insulator and a conductor. To put it more simply, it conducts electricity better than something like plastic, but not as well as metals like copper. Silicon is one of these semiconducting materials, and the most important in modern electronics. Fun fact: about 28% of Earth&#39;s crust is silicon, so we&#39;re not running out anytime soon. Silicon atoms have four outer ([valence](https://en.wikipedia.org/wiki/Valence_electron)) electrons, allowing each atom to bond with four neighbours in a rigid, tetrahedral crystal structure. In pure silicon, nearly all electrons are locked in these bonds, so only a small fraction gains enough energy to move freely through the lattice. This limited number of mobile charges is what makes silicon a semiconductor. On its own, pure silicon isn&#39;t useful for building a transistor. Luckily for us, there is a process called **doping**. In doping, a small amount of impurity atoms (atoms of a different element) is injected, changing the electrical behaviour. There are two types of doping, N and P-type: \n\n- **N-type doping**: Atoms with three valence electrons (e.g. [boron](https://en.wikipedia.org/wiki/Boron)) are added. This creates “holes”, electron vacancies that behave like positive charge carriers.\n- **P-type doping**: Atoms with five valence electrons (e.g. [phosphorus](https://en.wikipedia.org/wiki/Phosphorus)) are added. The extra electron becomes free to move, creating an excess of negative charge carriers.\n\nTogether, N-type and P-type semiconductors form the foundation of transistors, and by combining them, we can create devices like the **MOSFET**, the tiny transistor at the heart of modern computing.\n\n![Examples of no, P-type, and N-type doping of silicon](assets/Doping.jpg)\n\n## Meet the MOSFET&#39;s three players\n\nA common type of transistor used in digital circuits is the **MOSFET** (Metal-Oxide-Semiconductor Field-Effect Transistor). It has three electrical contacts:\n\n- Source (where current enters)\n- Drain (where the current exits)\n- Gate (which controls the flow)\n\nThe gate is separated from the semiconductor by a thin oxide layer, allowing it to control current without direct contact. At rest, electrons from the N-type regions naturally diffuse into the P-type region, filling holes and creating a **depletion region**. In this region, mobile charges are absent, forming a barrier that blocks current flow. This is the **off state** of the transistor. When a small positive voltage is applied to the gate, it attracts electrons toward the channel. This reduces the depletion region, allowing current to pass freely from source to drain. This is the **on state**, where the transistor acts as a closed switch. You can think of the gate like a **drawbridge**: when it&#39;s up, nothing can cross (off state). When it&#39;s lowered with a voltage, it creates a path across the channel, letting current flow (on state). However, the MOSFET wasn&#39;t always there.\n\n&gt; If you like a more visual explanation, I highly recommend watching [this](https://youtu.be/IcrBqCFLHIY?si=-onKV_bj28ybzD6Z) YouTube video by [Veritasium](https://www.youtube.com/@veritasium)\n\n![Example of a MOSFET circuit](assets/TransistorSetup.jpg)\n\n## In The Beginning\n\nIt is hard to imagine, but before transistors were a thing, early computers relied on **vacuum tubes**. Glass tubes which looked a lot like light bulbs. As the name suggests, it uses vacuums to control the flow of electrical current. The vacuum inside the tube removes all materials, even air, that could conduct electricity. The story begins on **16 November 1904,** when British electrical engineer and physicist Sir John Ambrose Fleming patented the first vacuum tube. By **1939**, they were being demonstrated for computation, and in **1946**, the famous [**ENIAC**](https://en.wikipedia.org/wiki/ENIAC) computer was built with more than **17,000 tubes**. It was ground-breaking, but also fragile. Vacuum tubes often burned out, and when one failed, it could take 15 minutes to locate and two days to replace. Not ideal if you ask me. On the upside, it made electronic computing possible for the first time in history. The next leap came in **1947**, when **John Bardeen, Walter Brattain, and William Shockley** at AT&amp;T&#39;s Bell Labs invented the first working **transistor**. Smaller, faster, and more reliable than vacuum tubes. Then, between **1955 and 1960**, Bell Labs revolutionised and invented the **MOSFET**. This design became the backbone of microchips, and it still powers every smartphone, laptop, and server in use today.&quot;],&quot;filePath&quot;:[0,&quot;src/content/posts/from-transistor-to-system-a-friendly-guide-to-computer-architecture/1-transistor.mdx&quot;],&quot;assetImports&quot;:[1,[[0,&quot;./assets/BannerTransistors.jpg&quot;]]],&quot;digest&quot;:[0,&quot;7b0138c5a54f038c&quot;],&quot;deferredRender&quot;:[0,true],&quot;collection&quot;:[0,&quot;posts&quot;],&quot;slug&quot;:[0,&quot;from-transistor-to-system-a-friendly-guide-to-computer-architecture/1-transistor&quot;],&quot;render&quot;:[0,null]}],[0,{&quot;id&quot;:[0,&quot;from-transistor-to-system-a-friendly-guide-to-computer-architecture/3-alu.mdx&quot;],&quot;data&quot;:[0,{&quot;author&quot;:[0,&quot;Gianni&quot;],&quot;collection&quot;:[0,&quot;From Transistor to System: A Friendly Guide to Computer Architecture&quot;],&quot;chapter&quot;:[0,3],&quot;title&quot;:[0,&quot;Understanding the ALU: Arithmetic, Logic, and Control Signals Explained&quot;],&quot;shortname&quot;:[0,&quot;ALU&quot;],&quot;date&quot;:[3,&quot;2025-11-02T00:00:00.000Z&quot;],&quot;tags&quot;:[1,[[0,&quot;Computer Architecture&quot;],[0,&quot;Electrical Engineering&quot;],[0,&quot;Logic&quot;]]],&quot;metaTags&quot;:[1,[[0,&quot;Arithmetic Logic Unit&quot;],[0,&quot;ALU explained&quot;],[0,&quot;CPU architecture&quot;],[0,&quot;Digital logic&quot;],[0,&quot;Computer fundamentals&quot;],[0,&quot;Binary arithmetic&quot;],[0,&quot;Logic gates&quot;],[0,&quot;Adder and subtractor&quot;],[0,&quot;Multiplexer (MUX)&quot;],[0,&quot;Opcodes&quot;],[0,&quot;Control unit&quot;],[0,&quot;Computer engineering&quot;],[0,&quot;Digital electronics&quot;],[0,&quot;Building a 1-bit ALU&quot;],[0,&quot;How computers perform arithmetic&quot;]]],&quot;difficulty&quot;:[0,&quot;Intermediate&quot;],&quot;readTime&quot;:[0,&quot;14 min&quot;],&quot;image&quot;:[0,{&quot;src&quot;:[0,&quot;/assets/BannerALU.D-QN8UHs.jpg&quot;],&quot;width&quot;:[0,1200],&quot;height&quot;:[0,675],&quot;format&quot;:[0,&quot;jpg&quot;]}],&quot;alt&quot;:[0,&quot;Collection of ALU related components&quot;],&quot;description&quot;:[0,&quot;Discover how the ALU enables a CPU to perform arithmetic and logic operations using adders, subtractors, logic gates, and control signals.&quot;]}],&quot;body&quot;:[0,&quot;In the previous chapter, we constructed circuits that could add numbers together, starting from a simple **Half-Adder** and progressing to an **8-bit Adder**. That was our first glimpse into how arithmetic happens inside a computer. But adders are just the beginning. Computers need a dedicated component to perform not only arithmetic but also logical decisions. This is where the **Arithmetic Logic Unit**, or **ALU**, comes in.\n\n## Arithmetic… what?\n\nAs mentioned earlier, the 8-bit adder was our first look at how arithmetic works inside a computer. However, a computer needs to do much more than add two numbers. With some clever circuitry, we can extend our 8-bit adder to create an 8-bit Subtractor. If we fix the B input of both the adder and subtractor to 00000001, we effectively create an incrementer and a decrementer, respectively.\n\nInside the CPU, all these circuits live together inside a special component called the **Arithmetic Logic Unit (ALU)**. Whenever your computer needs to perform arithmetic operations or make logical decisions, the ALU is the one doing the work. You can think of it as the calculator at the heart of the processor, but one that also understands logic.\n\nAt its core, an ALU is a circuit that takes **inputs**, performs an **operation**, and produces an **output**. The inputs usually come from CPU registers, and the operation performed depends on what the program instructs. The result is then sent back to a register or to memory for later use.\n\nWhat makes the ALU powerful is its **flexibility**. The same hardware can perform many different tasks depending on the **control signals** it receives. Depending on the control signals it receives, the ALU might add two numbers one moment, compare them the next, or even shift bits left or right.\n\nModern ALUs are often divided into two main parts:\n\n- **Arithmetic Unit (AU):** Handles mathematical operations such as addition, subtraction, multiplication, and division.\n- **Logic Unit (LU):** Handles logical operations such as AND, OR, XOR, and NOT.\n\nSome CPUs take this even further, including separate arithmetic units for different types of data. For example, one unit might handle **fixed-point arithmetic** (integers), while another handles **floating-point arithmetic** (real numbers used in scientific or graphics calculations).\n\n## Arithmetic\n\nLet’s take a closer look at how the circuits inside the ALU perform arithmetic. We already know from the previous chapter how an 8-bit adder works, and how to build incrementers and decrementers from it. But we haven’t yet seen how a **subtractor** works. Let’s start there.\n\nJust like before, we begin small, with the **Half-Subtractor**. The Half-Subtractor is similar to the Half-Adder: it has two inputs and two outputs. However, unlike the Half-Adder, it includes a **NOT gate** before the AND gate.\n\nThe first output, referred to as the **Difference**, represents the result of subtracting B from A. The second output, the **Borrow**, indicates that when the digit being subtracted (B) is larger than the digit it’s subtracted from (A), we need to “borrow” from the next higher bit, just like in decimal subtraction.\n\nHere’s how that looks conceptually:\n\n![Animated schematic diagram of a Half-Subtractor](assets/HalfSubtractor.gif)\n\nThe truth table for a Half-Subtractor is as follows:\n\n| A | B | Difference | Borrow |\n| --- | --- | --- | --- |\n| 0 | 0 | 0 | 0 |\n| 1 | 0 | 1 | 0 |\n| 0 | 1 | 1 | 1 |\n| 1 | 1 | 0 | 0 |\n\nTo create the **Full-Subtractor**, we combine two Half-Subtractors. It has three inputs: **A**, **B**, and **B-in** (the borrow from a previous stage).\n\n- **A** and **B** connect to the first Half-Subtractor.\n- Its **Difference** output connects to the A input of the second Half-Subtractor, while **B-in** connects to its B input.\n- The two **Borrow** outputs are combined through an **OR gate** to produce a single **Borrow out (B-out)**.\n\nConnecting eight of these Full-Subtractors forms an **8-bit Subtractor**, which can handle multi-bit binary subtraction, just like the adder, but with borrowing instead of carrying.\n\n![Schematic diagram of Full-Subtractor](assets/Full-Subtractor.jpg)\n\n## Logic\n\nArithmetic is only half the story; the other half is logic. The **Logic Unit** performs operations like **AND**, **OR**, **XOR**, and **NOT** directly on the binary bits of its inputs. Why does this matter? Because logic operations allow a computer to **make decisions**. For example, the ALU can compare two numbers to determine whether they are equal, greater, or less than. This information is critical for loops, conditional statements, and control flow in programs. Without logic operations, a computer could calculate, but it couldn’t **decide**.\n\n## Control Signals\n\nNow that we understand what the ALU does and how it works, one question remains: how does it know what operation to perform? The ALU doesn’t choose its operation on its own. Instead, it listens to instructions sent by the Control Unit in the form of binary codes known as opcodes (operation codes). Depending on the opcode, the ALU may perform addition, subtraction, comparison, or logical operations.\n\nHere’s an example of how different control signals might map to ALU operations:\n\n| **Opcode (Control Signal)** | **Operation** |\n| --- | --- |\n| 000 | ADD |\n| 001 | SUBTRACT |\n| 010 | AND |\n| 011 | OR |\n| 100 | XOR |\n| 101 | NOT |\n\nInside the ALU, a **multiplexer (MUX)** acts as a selector. You can think of a multiplexer as an electronic switch that selects one of many inputs and forwards it to a single output, based on control signals. Each operation (add, subtract, AND, and so on) is implemented as a separate circuit. All of them receive the same inputs and produce their results **in parallel**, but only one of these outputs is actually sent to the final result line. The MUX, controlled by the opcode, chooses which one.\n\nThis approach might seem inefficient at first; after all, why compute everything if you only need one result? But it makes the ALU incredibly fast. Since all operations are ready at once, the MUX can instantly select the required output without waiting for a circuit to “turn on.”\n\n## Building a Simple 1-bit ALU\n\nNow that we know how arithmetic and logic operations work, and how control signals tell the ALU what to do, let’s put everything together and build a simple **1-bit ALU**.\n\nA 1-bit ALU performs one operation on one pair of input bits (**A** and **B**) at a time. When we combine multiple 1-bit ALUs (usually eight, sixteen, or thirty-two of them), we get a multi-bit ALU capable of handling entire binary numbers. But just like before, we’ll start small.\n\n### The Idea\n\nOur ALU will have:\n\n- Two **inputs**: A and B\n- One **control signal**: to decide what operation to perform\n- One **output**: the result of that operation\n\nFor simplicity, let’s say our ALU only performs the following operations:\n\n| **Opcode** | **Operation** | **Description** |\n| --- | --- | --- |\n| 00 | AND | Logical AND between A and B |\n| 01 | OR | Logical OR between A and B |\n| 10 | XOR | Logical XOR between A and B |\n| 11 | ADD | Adds A and B (with carry out) |\n\nIn circuit form, we’ll have **four separate mini-circuits,** one for each operation. The outputs from all four will feed into a **multiplexer (MUX)**. The MUX then selects which output to send to the final result, based on the control signal.\n\n![Schematic of a simple 1 bit ALU](assets/1BitALU.jpg)\n\n### How it works step-by-step\n\n1. **Inputs arrive:** Two bits, A and B, are fed into the ALU.\n2. **Each mini-circuit does its job:**\n    - The **AND gate** outputs `A AND B`.\n    - The **OR gate** outputs `A OR B`.\n    - The XOR gate outputs `A XOR B`.\n    - The **adder** calculates `A + B`.\n3. **Opcode is set:** The CPU sends a 2-bit control signal telling the ALU which operation to use.\n4. **MUX selects output:** The multiplexer chooses the correct result and passes it to the output line.\n\nHere’s an example of how it behaves:\n\n| **A** | **B** | **Control** | **Operation** | **Result** |\n| --- | --- | --- | --- | --- |\n| 0 | 1 | 00 | AND | 0 |\n| 0 | 1 | 01 | OR | 1 |\n| 1 | 1 | 10 | XOR | 0 |\n| 0 | 1 | 11 | ADD | 1 |\n\n## Summary\n\n- The **ALU** is the part of the CPU that performs both arithmetic and logic operations.\n- It consists of an **Arithmetic Unit (AU)** and a **Logic Unit (LU)**.\n- **Control signals** from the control unit tell the ALU which operation to perform.\n- A **multiplexer (MUX)** selects the correct operation result.\n\nIn the next chapter, we’ll meet the **Control Unit,** the “brain” of the CPU that tells the ALU and every other component exactly what to do and when to do it.&quot;],&quot;filePath&quot;:[0,&quot;src/content/posts/from-transistor-to-system-a-friendly-guide-to-computer-architecture/3-alu.mdx&quot;],&quot;assetImports&quot;:[1,[[0,&quot;./assets/BannerALU.jpg&quot;]]],&quot;digest&quot;:[0,&quot;eb5bf0f9a570a369&quot;],&quot;deferredRender&quot;:[0,true],&quot;collection&quot;:[0,&quot;posts&quot;],&quot;slug&quot;:[0,&quot;from-transistor-to-system-a-friendly-guide-to-computer-architecture/3-alu&quot;],&quot;render&quot;:[0,null]}],[0,{&quot;id&quot;:[0,&quot;from-transistor-to-system-a-friendly-guide-to-computer-architecture/2-logic.mdx&quot;],&quot;data&quot;:[0,{&quot;author&quot;:[0,&quot;Gianni&quot;],&quot;collection&quot;:[0,&quot;From Transistor to System: A Friendly Guide to Computer Architecture&quot;],&quot;chapter&quot;:[0,2],&quot;title&quot;:[0,&quot;Understanding Logic Gates: AND, OR, XOR, NAND, Adders, and Flip-Flops&quot;],&quot;shortname&quot;:[0,&quot;Logic&quot;],&quot;date&quot;:[3,&quot;2025-09-14T00:00:00.000Z&quot;],&quot;tags&quot;:[1,[[0,&quot;Computer Architecture&quot;],[0,&quot;Electrical Engineering&quot;],[0,&quot;Logic&quot;]]],&quot;metaTags&quot;:[1,[[0,&quot;Logic gates&quot;],[0,&quot;Combinational logic&quot;],[0,&quot;Sequential logic&quot;],[0,&quot;Half-adder&quot;],[0,&quot;Full-adder&quot;],[0,&quot;8-bit adder circuit&quot;],[0,&quot;XOR gate&quot;],[0,&quot;AND gate&quot;],[0,&quot;OR gate&quot;],[0,&quot;NOT gate&quot;],[0,&quot;Flip-flop&quot;],[0,&quot;Digital circuits&quot;],[0,&quot;Electronics tutorial&quot;],[0,&quot;Binary addition&quot;],[0,&quot;Digital logic design&quot;]]],&quot;difficulty&quot;:[0,&quot;Intermediate&quot;],&quot;readTime&quot;:[0,&quot;10 min&quot;],&quot;image&quot;:[0,{&quot;src&quot;:[0,&quot;/assets/BannerLogic.adz-gygG.jpg&quot;],&quot;width&quot;:[0,1200],&quot;height&quot;:[0,675],&quot;format&quot;:[0,&quot;jpg&quot;]}],&quot;alt&quot;:[0,&quot;Collection of logic components&quot;],&quot;description&quot;:[0,&quot;Learn digital logic circuits: AND, OR, NOT, XOR gates, combinational circuits, half-adder, full-adder, 8-bit adder, and sequential logic with flip-flops.&quot;]}],&quot;body&quot;:[0,&quot;In this chapter, we&#39;ll see how simple switches can be combined into **logic gates**, the fundamental building blocks of digital circuits. Step by step, we&#39;ll explore the basic gates: **NOT, AND, OR**, and a few useful variations. Then we move on to how they can be wired together into larger circuits, known as **combinational logic**. Along the way, we&#39;ll build our first arithmetic circuits: starting with the **Half-Adder**, then extending it into a **Full-Adder**, and finally chaining them together to create an **8-bit adder**, capable of adding entire binary numbers. Finally, we&#39;ll wrap up with an introduction to **sequential logic**, where circuits gain memory and can remember past states.\n\n## From switches to logic gates\n\nAs we saw in the previous chapter, a transistor at its core acts like an electronic switch: it either allows current to flow (on) or prevents it from flowing (off). In the simple circuit shown below, an AA battery provides the power, the LED indicates the on/off states, a transistor controls the electric flow, and the resistors limit the current to protect the transistor and LED from damaging or even exploding (which can happen to the best of us). \n\n![Simple battery-powered circuit with a transistor and an LED in serial](assets/SimpleSwitchCircuit.gif)\n\nBy looking at the circuit, you will notice that it is just an LED that turns on and off depending on the transistor&#39;s state. It may not look impressive, but here is the idea: by cleverly wiring transistors,  we can make them do more than switch a light on/off. We can make them process information. This is where **logic gates** come in. The very first one we&#39;ll explore is the **NOT gate**, followed by the **AND** and **OR** **gates**.\n\n### NOT Gate\n\nYou may wonder: What happens if we change how the LED is connected? Instead of wiring it directly to the transistor&#39;s output path, we place it on the transistor&#39;s collector side (the path to ground). Now something interesting happens: the circuit **flips the signal**. The output becomes the opposite of the input. This is called an **inverter**, or more commonly, a **NOT gate**.\n\n![Simple battery-powered circuit with a transistor and an LED in parallel](assets/NotGate.gif)\n\nWhen the transistor is **on**, current flows from the battery&#39;s positive side through the resistor and straight to its negative (ground) via the transistor. In this state, the transistor acts almost like a short circuit, providing a low-resistance path for the current to follow. A transistor isn&#39;t a perfect wire, and even when fully on, there is still a tiny “resistance” inside it. This tiny resistance causes a small [voltage drop](https://en.wikipedia.org/wiki/Voltage_drop) across the transistor. Most of the battery&#39;s voltage now falls across the first resistor and the transistor. Very little voltage is left for the LED, so it stays off. In digital circuits, this small leftover voltage is still seen as a logical **0 (low)**. When the transistor switches **off**, the path to ground vanishes. Current can now flow through the LED instead. The LED lights up, which we read as a logical **1 (high)**.\n\nIn logic and computer science, outputs for every possible input are often shown in a **truth table**. A truth table lists all input values (true or false) and the corresponding outputs. Below is the truth table for a NOT gate. In math, the output is often labelled as **Y**.\n\n| **Input (A)** | **Output (Y)** |\n| --- | --- |\n| 0 | 1 |\n| 1 | 0 |\n\n### AND Gate\n\nOf course, we are not limited to using just one transistor. By combining multiple, we can build circuits that only give an output under specific conditions. One of them is the **AND gate**. In the example below, we connect two transistors in series (one after the other) to create an AND gate. \nCurrent from the source must pass through both transistors before it can reach the output. In other words, the output will be high if and only if both inputs (A and B) are high. If either transistor is off, the path is broken, and no current reaches the output.\n\n![Animation of how an AND gate works](assets/AndGate.gif)\n\nHere follows the truth table for the AND gate:\n\n| **A** | **B** | **Y** |\n| --- | --- | --- |\n| 0 | 0 | 0 |\n| 1 | 0 | 0 |\n| 0 | 1 | 0 |\n| 1 | 1 | 1 |\n\n### OR Gate\n\nNow let&#39;s try wiring the transistors in **parallel** instead of in series. This gives us the **OR gate**. In this case, the current only needs one path or the other to reach the output to make it high, hence the name OR. \n\n![Animation of how an OR gate works](assets/OrGate.gif)\n\nHere is the truth table for the OR gate:\n\n| **A** | **B** | **Y** |\n| --- | --- | --- |\n| 0 | 0 | 0 |\n| 1 | 0 | 1 |\n| 0 | 1 | 1 |\n| 1 | 1 | 1 |\n\n### XOR Gate\n\nThere is one more gate that deserves special attention, and because we will need it later: the **XOR gate,** short for **exclusive OR**. This gate is like the regular OR gate, but with a twist. As we know from the previous section, with an OR, the output is high if one or both inputs are high. With the XOR, the output is only high if exactly one input is high. This behaviour makes XOR extremely useful, because it can act as a simple difference detector: output is 1 if the inputs are different, and 0 if they&#39;re the same. You&#39;ll see XOR pop up again in circuits that perform arithmetic, like adders.\n\nHere&#39;s the truth table for XOR:\n\n| **A** | **B** | **Y** |\n| --- | --- | --- |\n| 0 | 0 | 0 |\n| 1 | 0 | 1 |\n| 0 | 1 | 1 |\n| 1 | 1 | 0 |\n\n### NAND and NOR Gate\n\nBy combining the previous gates, we can create even more variations. For example, if we take the output of an AND gate and run it through a NOT gate, we get a **NAND gate** (short for NOT AND). Likewise, combining an OR with a NOT gives a **NOR gate** (NOT OR). NAND and NOR are called **universal gates** because you can combine them to perform any Boolean function and thus create any other type of logic gate (AND, OR, NOT, XOR, XNOR). \n\n## Combinational Logic\n\nSo far, we&#39;ve looked at the basic gates: NOT, AND, OR, and a few variations like XOR, NAND, and NOR. Each one flips, combines, or filters signals simply. The real magic begins when we **connect them**. By combining gates, we can create circuits that solve more interesting problems. These are called **combinational logic circuits**. The key feature of combinational logic is that the **output depends only on the current inputs**. These circuits are stateless. They don&#39;t remember what happened before, meaning that if you give the same inputs, you&#39;ll always get the same outputs. With enough combinational logic, we can create circuits that add, subtract, increment, and do much more. In fact, arithmetic operations in a computer all come down to cleverly arranging these simple logic gates.\n\nTo see combinational logic in action, let&#39;s build something practical: a circuit that can add two numbers together, the **Half-Adder**, a simple circuit that can add two binary bits together. Before we dive in, here&#39;s a quick overview of the most common gate symbols:\n\n![Overview of the most common gate symbols](assets/AllGates.jpg)\n\nOkay, let&#39;s start small. Suppose we add two **1-bit numbers**, A and B. The result of this addition has two parts: the **sum** and the **carry**. The sum is the result of the addition, and the carry is like the overflowing bit, indicating that the result is greater than we can hold in the sum. For example:\n\n| A | B | Sum | Carry |\n| --- | --- | --- | --- |\n| 0 | 0 | 0 | 0 |\n| 1 | 0 | 1 | 0 |\n| 0 | 1 | 1 | 0 |\n| 1 | 1 | 0 | 1 |\n\nHere&#39;s the fun part: we can build this exact behaviour using only the gates we&#39;ve already learned! When we look at the table above, we can see that the sum is only 1 when either A or B is 1. This exactly matches the behaviour of an XOR. Now for the carry, it is only 1 when both A and B are 1. This is the behaviour of the AND gate. If we put that together, it will look something like this:\n\n![Animation of how a Half-Adder works](assets/HalfAdder.gif)\n\nThis little circuit is our first glimpse at how computers perform arithmetic operations. It&#39;s neat, but it has a limitation: it doesn&#39;t handle a carry input. In real arithmetic, numbers don&#39;t exist in isolation. When adding multi-bit numbers, each column might produce a carry that needs to be added to the next. This is where the bigger brother of the Half-Adders comes into play, the Full-Adder. A Full-Adder extends the Half-Adder by including a **carry-in** bit (C-in). Its outputs are the **sum** and a **carry-out** bit (C-out). How do we build one? Well, it&#39;s surprisingly easy! Here is how it works:\n\n1. Take **two Half-Adders**.\n2. Feed the sum from the first into one input of the second (together with C-in).\n3. Use an extra **OR gate** to combine the carry outputs from both Half-Adders.\n\nThe result is a Full-Adder!\n\n![Overview of a Full-Adder circuit](assets/Full-Adder.jpg)\n\nNow, here&#39;s where it gets exciting: if we chain multiple Full-Adders together by feeding each carry-out into the next carry-in, we can add multi-bit numbers. For example, connecting 8 Full-Adders creates an **8-bit adder**, capable of adding two 8-bit numbers. The final carry-out then serves as an overflow signal if the result doesn&#39;t fit into 8 bits.\n\n![Overview of an 8-bit adder circuit](assets/8BitAdder.gif)\n\n## Sequential Logic\n\nSo far, we&#39;ve only looked at combinational logic circuits, circuits whose output only depends on the current inputs. Change an input, and the output changes immediately. A computer needs more than just that. If you write a sentence and your computer instantly forgets the previous letter every time you press a new key, it would not be useful. It also needs **memory**. This is where **sequential logic** comes in. Sequential circuits combine logic gates with feedback loops so that the output doesn&#39;t just depend on the current inputs, but also on the circuit&#39;s **previous state**. In other words, they have memory.\n\nA simple example of sequential logic in action is a flip-flop, a tiny circuit that can store a single bit of information. The information is stored until a new input changes it. One of the simplest types is the SR flip-flop (Set-Reset flip-flop). It has two inputs:\n\n- **S (Set)**: tells the circuit to remember a `1`\n- **R (Reset)**: tells the circuit to remember a `0`\n\nAnd it has the outputs **Q** and **Q′**, which hold the stored value and its inverse.\n\n![Overview of an SR Flip-Flop circuit](assets/SR-Flip-Flop.jpg)\n\nThe truth table looks like this:\n\n| **S (Set)** | **R (Reset)** | **Q (next state)** | **Q′ (next state)** | Notes |\n| --- | --- | --- | --- | --- |\n| 0 | 0 | No change (holds previous value) | Opposite of Q | Memory condition |\n| 0 | 1 | 0 | 1 | Reset state |\n| 1 | 0 | 1 | 0 | Set state |\n| 1 | 1 | Undefined (invalid) | Undefined (invalid) | Not allowed |\n\nNotice something new here: when **S = 0** and **R = 0**, the output doesn&#39;t change. The flip-flop remembers whatever it was holding before. That&#39;s memory in action. As you can see, this simple flip-flop has a flaw: the state where both S and R are 1 is undefined. Luckily, engineers have designed improved versions like the JK and D flip-flops that avoid the undefined state, making them more reliable building blocks for memory.&quot;],&quot;filePath&quot;:[0,&quot;src/content/posts/from-transistor-to-system-a-friendly-guide-to-computer-architecture/2-logic.mdx&quot;],&quot;assetImports&quot;:[1,[[0,&quot;./assets/BannerLogic.jpg&quot;]]],&quot;digest&quot;:[0,&quot;623b0948236ce8d9&quot;],&quot;deferredRender&quot;:[0,true],&quot;collection&quot;:[0,&quot;posts&quot;],&quot;slug&quot;:[0,&quot;from-transistor-to-system-a-friendly-guide-to-computer-architecture/2-logic&quot;],&quot;render&quot;:[0,null]}],[0,{&quot;id&quot;:[0,&quot;from-transistor-to-system-a-friendly-guide-to-computer-architecture/4-control-unit.mdx&quot;],&quot;data&quot;:[0,{&quot;author&quot;:[0,&quot;Gianni&quot;],&quot;collection&quot;:[0,&quot;From Transistor to System: A Friendly Guide to Computer Architecture&quot;],&quot;chapter&quot;:[0,4],&quot;title&quot;:[0,&quot;How the Control Unit Makes the CPU Work: Signals, Microcode, and Decoding&quot;],&quot;shortname&quot;:[0,&quot;Control Unit&quot;],&quot;date&quot;:[3,&quot;2025-11-16T00:00:00.000Z&quot;],&quot;tags&quot;:[1,[[0,&quot;Computer Architecture&quot;]]],&quot;metaTags&quot;:[1,[[0,&quot;control unit&quot;],[0,&quot;cpu control unit&quot;],[0,&quot;microprogrammed control&quot;],[0,&quot;hardwired control&quot;],[0,&quot;microcode&quot;],[0,&quot;fetch decode execute&quot;],[0,&quot;computer architecture basics&quot;]]],&quot;difficulty&quot;:[0,&quot;Intermediate&quot;],&quot;readTime&quot;:[0,&quot;7 min&quot;],&quot;image&quot;:[0,{&quot;src&quot;:[0,&quot;/assets/BannerIntroduction.B_LErQtH.jpg&quot;],&quot;width&quot;:[0,1200],&quot;height&quot;:[0,675],&quot;format&quot;:[0,&quot;jpg&quot;]}],&quot;alt&quot;:[0,&quot;Collection of computer components&quot;],&quot;description&quot;:[0,&quot;Understand how the CPU Control Unit fetches, decodes, and executes instructions. Learn the differences between hardwired and microprogrammed control with clear examples.&quot;]}],&quot;body&quot;:[0,&quot;In the previous chapter, we explored the **Arithmetic Logic Unit (ALU)**, the part of the CPU responsible for performing arithmetic and logic operations. We saw how it can add, subtract, compare, and make decisions depending on the **control signals** it receives. But this raises an important question: *where do those control signals come from?* That’s the job of the **Control Unit (CU),** the CPU’s internal **orchestrator**.\r\n\r\n## The Control Unit’s Role\r\n\r\nIf we think of the CPU as a small orchestra, the **ALU** would be the musician, performing the actual notes (the operations). The **Control Unit**, on the other hand, is the **conductor**, ensuring that every part of the CPU works in perfect timing.\r\n\r\nThe Control Unit doesn’t do the math itself, but it **directs** all the components that do. It tells the ALU when to add or subtract, instructs the registers when to store or load data, and coordinates with memory to fetch new instructions.\r\n\r\nIn short, the Control Unit:\r\n\r\n- **Fetches** instructions from memory\r\n- **Decodes** what those instructions mean\r\n- **Directs** the ALU, registers, and memory to carry them out\r\n- **Repeats** this cycle continuously\r\n\r\nThis ongoing rhythm is known as the **Fetch–Decode–Execute cycle**. We’ll explore this cycle step by step in **Chapter 6**, once we’ve seen how the rest of the CPU fits together.\r\n\r\n## Hardwired vs. Microprogrammed Control\r\n\r\nNot all Control Units are built the same way. Broadly speaking, there are two main design approaches:\r\n\r\n### 1. Hardwired Control\r\n\r\nIn a **hardwired control unit**, control signals are generated directly by fixed electronic circuits made up of logic gates, flip-flops, and decoders. Each instruction’s behaviour is physically built into the hardware wiring.\r\n\r\n- **Pros:**\r\n    - Speedy (no intermediate steps).\r\n    - Efficient for simple instruction sets.\r\n- **Cons:**\r\n    - It is difficult to modify, as changing the instruction set requires redesigning the hardware.\r\n    - Complex to build for large CPUs with many instructions.\r\n\r\nThis approach is common in small or specialised processors (like microcontrollers), where performance and simplicity matter more than flexibility.\r\n\r\n### 2. Microprogrammed Control\r\n\r\nIn contrast, a **microprogrammed control unit** works more like a tiny interpreter.\r\n\r\nInstead of using fixed wiring, it stores small **microinstructions** in a special memory area called the **control store**. Each microinstruction tells the CPU which control signals to activate during one small step of an operation.\r\n\r\nSo when the CPU executes a normal instruction (like `ADD A, B`), the Control Unit actually runs a short **microprogram,** a sequence of low-level steps that cause the ALU, registers, and buses to act in the right order.\r\n\r\n- **Pros:**\r\n    - Easier to modify or extend (you can change the microcode instead of the hardware).\r\n    - Ideal for complex instruction sets (like in older CISC CPUs).\r\n- **Cons:**\r\n    - Slightly slower than hardwired designs, since each instruction is interpreted internally.\r\n\r\nModern CPUs often blend both approaches; some parts are hardwired for speed, while others use microcode for flexibility. x86 processors (like those from Intel and AMD) are a perfect example of a **hybrid** design:\r\n\r\n- **Simple instructions** such as `ADD`, `SUB`, `AND`, or `MOV` are usually handled by **hardwired control**.\r\n    \r\n    These can be executed in just a few fast steps, so wiring them directly into hardware keeps performance high.\r\n    \r\n- **Complex instructions**, like `REP MOVSB` (which copies an entire block of memory) or older instructions that are kept for backwards compatibility are handled using **microcode**.\r\n    \r\n    Internally, the CPU breaks these complicated instructions into a sequence of simpler micro-operations and runs them like a tiny program.\r\n    \r\n\r\nThis way, the CPU gets the **speed** of hardwired control for the common operations, and the **flexibility** of microcode for everything else, without needing to redesign the hardware every time the instruction set changes.\r\n\r\n## How Instructions Are Decoded\r\n\r\nEvery program you run, from a web browser to a video game, ultimately boils down to a long list of machine instructions. Each instruction is just a binary number. The Control Unit must interpret that number to decide what to do.\r\n\r\nLet’s look at a simplified example. Suppose we have an 8-bit CPU where each instruction is one byte (8 bits):\r\n\r\n```bash\r\nInstruction: 0100 1010\r\n```\r\n\r\nThe Control Unit might divide this instruction into parts like this:\r\n\r\n| **Bits** | **Meaning** |\r\n| --- | --- |\r\n| 0100 | Operation code (Opcode) → tells the CPU what to do |\r\n| 1010 | Operand → tells the CPU which register or memory address to use |\r\n\r\nWhen the Control Unit reads this instruction, it **decodes** the opcode (`0100`) to determine which control signals to activate.\r\n\r\nFor example, opcode `0100` might mean “ADD,” while `0101` could mean “SUBTRACT.”\r\n\r\nIt then sends the appropriate signals:\r\n\r\n- Enable the ALU’s “add” circuit.\r\n- Load inputs from registers A and B\r\n- Store the result back into register A\r\n\r\nAll of this happens automatically, step by step, as the CPU clock ticks.\r\n\r\n## Timing and Coordination\r\n\r\nComputers work in rhythm. Every operation, from fetching data to performing arithmetic, happens in sync with the **clock**. The clock doesn’t measure time like a wall clock; instead, it provides a steady beat that synchronises all internal actions.\r\n\r\nOn each clock pulse, the Control Unit advances the CPU to its next step: reading an instruction, setting up the ALU, or writing a result back to memory. This precise timing ensures that signals don’t collide and that every operation occurs exactly when it should.&quot;],&quot;filePath&quot;:[0,&quot;src/content/posts/from-transistor-to-system-a-friendly-guide-to-computer-architecture/4-control-unit.mdx&quot;],&quot;assetImports&quot;:[1,[[0,&quot;./assets/BannerIntroduction.jpg&quot;]]],&quot;digest&quot;:[0,&quot;a1a83fb55891408a&quot;],&quot;deferredRender&quot;:[0,true],&quot;collection&quot;:[0,&quot;posts&quot;],&quot;slug&quot;:[0,&quot;from-transistor-to-system-a-friendly-guide-to-computer-architecture/4-control-unit&quot;],&quot;render&quot;:[0,null]}],[0,{&quot;id&quot;:[0,&quot;finding-p-values-and-false-hope/1-losing.mdx&quot;],&quot;data&quot;:[0,{&quot;author&quot;:[0,&quot;Quinn&quot;],&quot;collection&quot;:[0,&quot;Finding P values and false hope&quot;],&quot;chapter&quot;:[0,1],&quot;title&quot;:[0,&quot;The Art of Losing Slowly: How to Manage Risk, Variance and Decisions Under Uncertainty&quot;],&quot;shortname&quot;:[0,&quot;Losing&quot;],&quot;date&quot;:[3,&quot;2025-11-23T00:00:00.000Z&quot;],&quot;tags&quot;:[1,[[0,&quot;Data Science&quot;]]],&quot;metaTags&quot;:[1,[[0,&quot;risk management&quot;],[0,&quot;decision making under uncertainty&quot;],[0,&quot;expected value&quot;],[0,&quot;variance in finance&quot;],[0,&quot;diversification&quot;],[0,&quot;risk averse decision making&quot;],[0,&quot;financial uncertainty&quot;],[0,&quot;data science decision-making&quot;],[0,&quot;probability and outcomes&quot;]]],&quot;difficulty&quot;:[0,&quot;Intermediate&quot;],&quot;readTime&quot;:[0,&quot;5 min&quot;],&quot;image&quot;:[0,{&quot;src&quot;:[0,&quot;/assets/roulette-table.BZmCmYkY.jpg&quot;],&quot;width&quot;:[0,6240],&quot;height&quot;:[0,4160],&quot;format&quot;:[0,&quot;jpg&quot;]}],&quot;alt&quot;:[0,&quot;Roulette table&quot;],&quot;description&quot;:[0,&quot;Learn how to manage risk, leverage variance, and make better decisions under uncertainty. A practical guide to thoughtful losses, expected value, and long-term thinking.&quot;]}],&quot;body&quot;:[0,&quot;In a world obsessed with winning, few stop to consider the quiet art of losing. Not making reckless decisions, but instead being deliberate, patient, and purposeful. Managing risk and making decisions under uncertainty isn’t about avoiding loss; it’s about controlling its space, size, and impact. Success often belongs not to those who never fall, but to those who learn to fall well, who can endure small, calculated setbacks while keeping the bigger picture intact.\r\n\r\nLearning to “*lose slowly*” means embracing uncertainty without panic, balancing conviction with adaptability, and knowing when to press forward and when to hold back. It&#39;s playing the long game when the short term feels chaotic. By learning to lose slowly, we will be able to separate sustainable progress from mere luck.\r\n\r\n# Understanding Risk\r\n\r\nRisk is woven into almost every decision we make. We take it when we cross the street, start a new job, or trust someone’s word. Most of the time, we manage it intuitively, weighing outcomes, reading context, and adjusting as we go. Every day life trains us to navigate uncertainty, but it can create a dangerous illusion of being too comfortable with risk and of underestimating it.\r\n\r\nIn financial decisions, those illusions often break down. Even highly educated people who hold strong opinions about financial markets and financial risk struggle with it. The 2008-2009 financial crisis is a clear example of how financial risk was underestimated. It&#39;s important for us to have a deep enough understanding to manage the risk we can live with.\r\n\r\nLet&#39;s explore an example of risk evaluation in a financial decision involving gambling. Imagine this: you pay **€1** to draw a single card from a standard deck. If you pull the **ace of spades**, you win **€50**; otherwise, you get nothing. Would you take the bet?\r\n\r\nMost people would since it feels like a small risk for a high reward. But let&#39;s change the game. Would you play the banker? So now you get **€1** if no **ace of spades** is drawn, but you lose **€49** if an ace is drawn.\r\n\r\nWe can make this game more fun by upping the stake by ***x100***. Most of us would probably hesitate to lose **€4900** just to gain **€100**. This just feels like a bad deal, even though the odds are the same as with the lower amounts. We can calculate the expected value of this bet as:\r\n\r\n$$\r\nE(\\text{Bet}) = \\frac{1}{52}(-€4900) + \\frac{51}{52}(€100) = \\frac{100}{26} \\text{ or about €4}\r\n$$\r\n\r\nSo the bet still has a positive outcome, but what if we split it into 50 even smaller bets? With each round, we risk losing **€98** and have a chance to gain **€2**. Our maximum possible loss is still **€4900,** and the maximum possible gain is still **€100**. Did you notice what happened when we changed the game like this? The probability of us losing everything just changed to almost zero (about **10^-86**), while the probability of obtaining the maximum gain is (**51/52)^50 = 37.87%**.  \r\n\r\nWhat changed? Not the expected outcome—what stayed the same—but the variance did change. Variance captures how spread out the possible outcomes are, and it turns out to be a powerful way to distinguish a good from a bad bet.\r\n\r\nThe essence of variance is dividing a single large, risky bet into many smaller, uncorrelated ones. In finance, diversification transforms uncertainty into something manageable. It’s why investors might prefer to hold a **1%** stake in **100** **mortgages** than a **100% stake in one.** The total exposure is the same, but the risk behaviour is completely different. This is a great example of managing risk by leveraging variance. \r\n\r\n# Making decisions under uncertainty\r\n\r\nEvery meaningful decision we make lives in the space between what we know and what we can only guess. Whether we’re allocating capital or choosing when to exit a trade, uncertainty is the constant backdrop. Yet decisions must still be made. Good decision-making under uncertainty is not only about the probability of an event, but also about the consequences if it occurs. A rare event with a large impact can matter far more than a frequent one with small effects. However, in practice, this can be very difficult, since there are an infinite number of possible outcomes for certain events. For simplicity, let&#39;s imagine we have an event with a finite number of possibilities. Imagine we have a company that runs online ads. We need to decide whether to place the ad online. Based on historical data, we know the probability and outcome of each decision we can make:   \r\n\r\n| **Decsion** | **Probablity** | **Outcome** |\r\n| --- | --- | --- |\r\n| *Place the ads* | 20% | Customer buys → **€5 profit** |\r\n|  | 30% | Customer does not buy → **€1 loss** |\r\n| *Do not place the ads* | 50% | Customer shows interest but doesn’t buy → **€0 profit** |\r\n\r\nThere are several ways to evaluate the risk and the actions we should take. Let&#39;s discuss two simple methods to understand the principle of decision-making. The first one is the expected value decision. With this decision, we will calculate the expected value of each outcome with this formula:\r\n\r\n$$\r\n\\text{EV(decision)} = \\sum (\\text{Probability of outcome} \\times \\text{Value of outcome})\r\n$$\r\n\r\nWe can easily automate this decision-making process with Python. By defining the possible outcomes and their probabilities for each decision, the script will compute the expected value and compare your options programmatically.\r\n\r\n```python\r\ndef expected_value(outcomes):\r\n    \&quot;\&quot;\&quot;\r\n    outcomes: list of (probability, payoff) pairs.\r\n    \&quot;\&quot;\&quot;\r\n    return sum(p * v for p, v in outcomes)\r\n\r\ndef evaluate_decisions(decisions):\r\n    \&quot;\&quot;\&quot;\r\n    decisions: dict where key = decision name,\r\n               value = list of (probability, payoff) pairs.\r\n    \&quot;\&quot;\&quot;\r\n    results = {}\r\n    for name, outcomes in decisions.items():\r\n        results[name] = expected_value(outcomes)\r\n    return results\r\n\r\nif __name__ == \&quot;__main__\&quot;:\r\n    # All the options and their possible outcomes\r\n    decisions = {\r\n        \&quot;Place the ad\&quot;: [(0.2, 5), (0.3, -1)],\r\n        \&quot;Do not place the ad\&quot;: [(1, 0)],\r\n    }\r\n\r\n    ev_results = evaluate_decisions(decisions)\r\n    # Identify the best decision\r\n    best_decision = max(ev_results, key=ev_results.get)\r\n    print(f\&quot;Best decision under the Expected Value criterion: {best_decision}\&quot;)\r\n```\r\n\r\n**The script will give us this output:**\r\n\r\n```\r\nBest decision under the Expected Value criterion: Place the ad\r\n```\r\n\r\nSo we should place the ads based on the expected value decision. In general, we should make decisions based on expected value if the decision is made often enough for the law of large numbers to apply. The decision in our example is for every person who interacts with the ad. So in the end, we should make the most money by placing the ad.\r\n\r\nNot all decision makers will find this approach appropriate for this situation. A risk-averse decision maker will be more interested in minimising their loss. They will use the worst-case decision-making method. The decision based on the worst-case scenario should be made when it is a one-time occurrence and the worst-case scenario has a catastrophic effect. In this case, we should always cover the worst case. The worst-case scenario calculation does not account for the probability of an event. We simply look at what it would the worst possible outcome is.\r\n\r\nImagine we are going on holiday and you get the option to buy travel insurance. The total trip costs you **€5000**, and you can buy additional travel insurance for **€200**. So what could happen?\r\n\r\n| **Decision** | **Outcome** |\r\n| --- | --- |\r\n| *Buy Insurance* | Trip is fine → €200 loss |\r\n|  | Trip is canceled → €200 loss |\r\n| *Do NOT buy Insurance* | Trip is fine → €0 loss |\r\n|  | Trip is canceled → €5000 loss |\r\n\r\nThe worst thing that can happen is us losing **€5000** if we don&#39;t buy the insurance and the trip gets cancelled. Therefore, a risk-averse decision maker will choose to buy the insurance when going on the trip.\r\n\r\n# Closing thoughts\r\n\r\nLearning to **lose slowly** is not about avoiding failure; it’s about respecting uncertainty. It’s recognising that progress is rarely a straight line and that the cost of staying in the game is sometimes accepting small, intentional losses along the way.\r\n\r\nWe don’t control outcomes, but we *do* control our exposure: how much we risk, how often, and in what context. By diversifying, by sizing our decisions to our tolerance, and by keeping a long-term perspective even when the short term feels chaotic, we can build a path where setbacks are manageable rather than catastrophic.\r\n\r\nIn the end, winning isn’t about making the right decision every time. It’s about creating a system in which even the wrong decisions don’t break you.&quot;],&quot;filePath&quot;:[0,&quot;src/content/posts/finding-p-values-and-false-hope/1-losing.mdx&quot;],&quot;assetImports&quot;:[1,[[0,&quot;./assets/roulette-table.jpg&quot;]]],&quot;digest&quot;:[0,&quot;460f4df8c0bc76d0&quot;],&quot;deferredRender&quot;:[0,true],&quot;collection&quot;:[0,&quot;posts&quot;],&quot;slug&quot;:[0,&quot;finding-p-values-and-false-hope/1-losing&quot;],&quot;render&quot;:[0,null]}],[0,{&quot;id&quot;:[0,&quot;the-tough-love-architecture-guide/1-the-harsh-truth-about-your-design-pattern-choices.mdx&quot;],&quot;data&quot;:[0,{&quot;author&quot;:[0,&quot;Quinn&quot;],&quot;collection&quot;:[0,&quot;The Tough Love Architecture Guide&quot;],&quot;chapter&quot;:[0,1],&quot;title&quot;:[0,&quot;The Harsh Truth About Your Design Pattern Choices&quot;],&quot;shortname&quot;:[0,&quot;Truth&quot;],&quot;date&quot;:[3,&quot;2025-08-24T00:00:00.000Z&quot;],&quot;tags&quot;:[1,[[0,&quot;Software Design Patterns&quot;]]],&quot;metaTags&quot;:[1,[[0,&quot;Design pattern mistakes&quot;],[0,&quot;Choosing the right design pattern&quot;]]],&quot;difficulty&quot;:[0,&quot;Beginner&quot;],&quot;readTime&quot;:[0,&quot;5 min&quot;],&quot;image&quot;:[0,{&quot;src&quot;:[0,&quot;/assets/BannerTheHarshTruth.Dne4Iewa.jpg&quot;],&quot;width&quot;:[0,1920],&quot;height&quot;:[0,1600],&quot;format&quot;:[0,&quot;jpg&quot;],&quot;orientation&quot;:[0,1]}],&quot;alt&quot;:[0,&quot;Collection of computer windows&quot;],&quot;description&quot;:[0,&quot;Most developers misuse design patterns. Learn when to apply them, when to avoid them, and how to simplify your architecture for real-world projects.&quot;]}],&quot;body&quot;:[0,&quot;Imagine you&#39;re knees-deep in a project deadline, navigating through so many lines of messy code that resemble a spaghetti factory explosion. You&#39;ve probably been there: tempted to implement a clever design pattern you recently learned about, hoping it will be the magic bullet for all your coding woes. But here&#39;s a reality check: “most developers either misuse or don&#39;t know what they are doing with design patterns”. It&#39;s not because they&#39;re bad at coding, but they&#39;ve fallen into the trap I like to call ***Pattern worshiping.***\n\nIf you&#39;re the type of developer who finds themselves forcing a Pattern into a project that didn&#39;t need one, you&#39;re not alone, and this page is for you. By the end, you&#39;ll not only understand how to stop turning your architecture into a &#39;look what I have learned in school&#39; museum, but you&#39;ll discover how to save valuable time, reduce the introduction of bugs, and improve code review outcomes by choosing solutions that truly solve your problem.\n\n---\n\n## The myth of the “Perfect” Design Pattern\n\nLet me give you a quick reality check: THERE IS NO UNIVERSAL BEST PATTERN.\n\nThe right pattern in one project could be the wrong pattern in another. Yet, including myself at times, we developers often pick a pattern simply because a tutorial made it look sexy. This leads to bizarre overengineering, such as creating a simple object using a Builder, Factory, and Prototype pattern simply because the textbook made it look cool. Consider this: a startup once spent a month implementing an intricate Builder-Factory architecture, only to realize that it could be refactored in a single day using straightforward functions. This real-world example illustrates the potential pitfall of blindly applying complex patterns where simplicity would suffice.\n\nA pattern should never be your objective; it should only make your solution simpler, not more complex.\n\n---\n\n## Harsh Truth #1 - Patterns Are Tools, Not Goals\n\nHammers are a great tool when you have a bunch of nails, but they are awful when you try to fix a leaky pipe.\n\nDesign patterns are similar; they are tools that can be great for the right task. If you start a project and think, *“I want to use a singleton pattern,”* You are not addressing the underlying problem, but rather your desires\n\nA code base can quickly become overcomplicated when we use patterns that do not fit the task. Sometimes, a simple if statement will do a better job.\n\nBefore you begin implementing a new pattern, ask yourself these three questions:\n\n1. Does using a strategy pattern here reduce complexity, or are we simply rearranging it?\n2. Will the code be easier to maintain after implementing the pattern?\n3. Will future developers understand and appreciate the added complexity?\n\n---\n\n## Harsh Truth #2 - Ignoring Constraints will lead to wrong choices\n\nFor most of us, we are not writing code on supercomputers with unlimited memory, crazy performance, and super high concurrency. We work in a world where we are restricted by boundaries and constraints. When selecting a pattern, we must consider all our constraints, including the team&#39;s experience, deadlines, business requirements, and performance. To help ensure these constraints are at the forefront of consideration, here is a checklist of typical project limitations you should evaluate:\n\n- Memory availability\n- Latency requirements\n- Team skill levels\n- Project deadlines\n- Business needs\n- Performance targets\n- Scalability demands\n\nIf we ignore our constraint, we&#39;ll end up with mismatched solutions. The right pattern is the one that fits within our boundaries and doesn&#39;t violate our constraints.\n\n---\n\n## Harsh Truth #3 - You&#39;re Probably Copying, Not Designing\n\nThis one might be a bit awkward, but many developers don&#39;t apply patterns; they simply copy them. They find some pattern, copy it into their codebase, change some class name, and call it a solid architecture. The problem with this is that textbook examples all live in a perfect world where requirements never change and performance is someone else&#39;s problem. To truly embrace the creative process of design, ask yourself: &#39;Which parts of this pattern can we safely drop or modify while still achieving our goals?&#39; This mindset encourages adaptation rather than blind replication, allowing for solutions that are tailored to the specific challenges of your project.\n\nThe code we write will not live in that perfect world. This means we need to adapt and modify the pattern to make it fit within our domain. We need to tweak the pattern to ensure it operates within our boundaries and does not cross any constraints. Blindly copying a perfect example will fall apart when reality comes knocking.\n\n---\n\n## Patterns don&#39;t make you smart; good choices do\n\nA well-chosen pattern can make your code elegant and maintainable, but the wrong choice leads to unnecessary complexity. Choosing a pattern should always serve your problem, not overshadow it.\n\nThe harsh truth is: just knowing design patterns does not make you a good developer, but knowing when **not** to use them will bring you pretty close to being one.\n\nInstead of defaulting to whatever is trending, we can follow a simple framework. Next time you&#39;re faced with a problem, follow these five guidelines:\n\n1. **Define the problem clearly**\n2. **Identify constraints**\n3. **List candidate patterns**\n4. **Evaluate trade-offs**\n5. **prototype and test**\n\nSo next time, remember: your real goal isn&#39;t to use fancy patterns, but to solve the problem in front of you as directly as possible.&quot;],&quot;filePath&quot;:[0,&quot;src/content/posts/the-tough-love-architecture-guide/1-the-harsh-truth-about-your-design-pattern-choices.mdx&quot;],&quot;assetImports&quot;:[1,[[0,&quot;./assets/BannerTheHarshTruth.jpg&quot;]]],&quot;digest&quot;:[0,&quot;45d040f15b55ee69&quot;],&quot;deferredRender&quot;:[0,true],&quot;collection&quot;:[0,&quot;posts&quot;],&quot;slug&quot;:[0,&quot;the-tough-love-architecture-guide/1-the-harsh-truth-about-your-design-pattern-choices&quot;],&quot;render&quot;:[0,null]}],[0,{&quot;id&quot;:[0,&quot;hello-world/hello-world-asm.mdx&quot;],&quot;data&quot;:[0,{&quot;author&quot;:[0,&quot;Gianni&quot;],&quot;title&quot;:[0,&quot;Hello World in x86 Assembly: Step-by-Step Guide&quot;],&quot;date&quot;:[3,&quot;2025-10-19T00:00:00.000Z&quot;],&quot;tags&quot;:[1,[[0,&quot;Programming&quot;]]],&quot;metaTags&quot;:[1,[[0,&quot;assembly tutorial&quot;],[0,&quot;x86 assembly&quot;],[0,&quot;nasm hello world&quot;],[0,&quot;linux assembly programming&quot;],[0,&quot;docker development environment&quot;],[0,&quot;low-level programming&quot;],[0,&quot;system calls tutorial&quot;],[0,&quot;assembly language basics&quot;],[0,&quot;learn assembly&quot;],[0,&quot;programming optimization&quot;],[0,&quot;hello world in assembly&quot;],[0,&quot;nasm guide&quot;],[0,&quot;docker for developers&quot;]]],&quot;difficulty&quot;:[0,&quot;Intermediate&quot;],&quot;readTime&quot;:[0,&quot;10 min&quot;],&quot;image&quot;:[0,{&quot;src&quot;:[0,&quot;/assets/coding-setup.BGofQTTk.jpg&quot;],&quot;width&quot;:[0,3353],&quot;height&quot;:[0,2514],&quot;format&quot;:[0,&quot;jpg&quot;]}],&quot;alt&quot;:[0,&quot;Programming setup&quot;],&quot;description&quot;:[0,&quot;Learn how to write and run a classic “Hello, World!” program in pure x86 assembly, step by step, using Docker for a clean and portable setup.&quot;]}],&quot;body&quot;:[0,&quot;We’ve all seen the classic *“Hello, World!”* programs. But let’s be honest, you’re not a true Giga Chad until you’ve written one in **pure assembly**.\n\n## Why?\n\nYou might be asking yourself: *Why on earth would anyone learn assembly when high-level languages exist to make life easier?* The truth is, there are situations outside of programming a [space probe](https://science.nasa.gov/mission/voyager/frequently-asked-questions/) where assembly is still relevant. For example, imagine you’re working on a collision detection system for a self-driving car. In that scenario, every microsecond matters. You want to squeeze out every drop of performance to avoid disaster. Of course, this doesn’t mean writing the entire system in assembly. In practice, you’d only optimise the performance-critical parts, while leaving the rest in a higher-level language. And knowing how things work under the hood is always valuable\n\n## Environment\n\nBefore we start coding, we need to set up a proper environment. Let’s create a project directory. Throughout this tutorial, we’ll call it `hello-world-asm`.  To make sure our code runs anywhere (not just on my machine), we’ll use a Docker container with all the necessary tools for building and running assembly. If you don’t already have [Docker Desktop](https://www.docker.com/products/docker-desktop/) installed, go ahead and do that first. For your editor/IDE, feel free to use whatever you like; it doesn’t really matter. In this tutorial, I’ll be using [Visual Studio Code](https://code.visualstudio.com/Download), but it’s not a requirement.\n\n### Container\n\nInside your `hello-world-asm` directory, create a file named `Dockerfile`:\n\n```docker\nFROM ubuntu:latest\n\n# Build-time variable for noninteractive installs\nARG DEBIAN_FRONTEND=noninteractive\n\n# Install only the essentials for x86_64 assembly\nRUN apt update &amp;&amp; apt upgrade -y &amp;&amp; \\\n    apt install -y --no-install-recommends \\\n    build-essential \\\n    gdb \\\n    nasm &amp;&amp; \\\n    rm -rf /var/lib/apt/lists/*\n\n# Create non-root user \&quot;dev\&quot;\nRUN useradd -m -s /bin/bash dev &amp;&amp; \\\n    echo \&quot;dev ALL=(ALL) NOPASSWD: ALL\&quot; &gt;&gt; /etc/sudoers\n\nUSER dev\nWORKDIR /home/dev\n```\n\nLet’s break down what we just set up:\n\n- **Base image:** We start with `ubuntu:latest`, giving us a clean Linux environment.\n- **Non-interactive installs:** The `DEBIAN_FRONTEND=noninteractive` variable ensures `apt` doesn’t get stuck asking us questions.\n- **Install essentials:** We pull in just the tools we need for x86_64 assembly programming:\n    - `build-essential` → compiler, linker, common build tools (handy for your C/C++ projects too)\n    - `gdb` → the GNU Debugger, so we can step through our assembly code.\n    - `nasm` → the Netwide Assembler, the tool we use to assemble and link our `.asm` files.\n- **Non-root user:** We add a new user `dev`, so we don’t run everything as root (a good security practice).\n- **Working directory:** Finally, we set the container to drop us into `/home/dev`, which is where we’ll link our project directory to later.\n\n### Helper Script\n\nTyping Docker commands over and over can be a pain. To make life easier, let’s create a shell script to automate container management. Inside your `hello-world-asm` directory, create a file named `docker.sh` with the following content:\n\n```bash\n#!/bin/bash\n\nIMAGE_NAME=\&quot;dev-env\&quot;\nCONTAINER_NAME=\&quot;dev-env-container\&quot;\nCONTAINER_ENTRY=\&quot;/usr/bin/bash\&quot;\nWORK_DIR=\&quot;/home/dev/hello-world-asm\&quot;\n\nPROJECT_ROOT=\&quot;$(pwd)\&quot;\n\nfunction container_stop() {\n\tsudo docker stop $CONTAINER_NAME || echo \&quot;container already stopped\&quot;\n}\n\nfunction clean() {\n\tcontainer_stop\n\tsudo docker rm $CONTAINER_NAME || echo \&quot;container already removed\&quot;\n\tsudo docker image rm $IMAGE_NAME  || echo \&quot;image already removed\&quot;\n}\n\nfunction container_start() {\n\tif [ -z \&quot;$(sudo docker ps -a | grep $CONTAINER_NAME)\&quot; ]; then\n\t\techo \&quot;&gt;&gt; creating dev container\&quot;\n\n\t\tsudo docker run -w $WORK_DIR --hostname dev -it --name $CONTAINER_NAME \\\n\t\t\t--net=host \\\n\t\t\t--cap-add=SYS_PTRACE --security-opt seccomp=unconfined \\\n\t\t\t-v $PROJECT_ROOT:$WORK_DIR:z \\\n\t\t\t$IMAGE_NAME $CONTAINER_ENTRY\n\n\telse\n\t\techo \&quot;&gt;&gt; found existing dev container\&quot;\n\t\tsudo docker start $CONTAINER_NAME\n\t\tsudo docker exec -it $CONTAINER_NAME $CONTAINER_ENTRY\n\tfi\n}\n\nfunction image_build() {\n\tif [ -z \&quot;$(sudo docker images | grep $IMAGE_NAME)\&quot; ]; then\n\t\techo \&quot;&gt;&gt; building image: $IMAGE_NAME\&quot;\n\t\tsudo docker build -t $IMAGE_NAME ./\n\tfi\n}\n\nfunction print_usage() {\n\techo \&quot;Usage: ./docker.sh [container-start | container-stop | image-build | clean]\&quot;\n}\n\nfunction main() {\n\tif ! command -v docker &gt;/dev/null 2&gt;&amp;1; then\n\t\techo \&quot;Could not find docker. Please install it https://docs.docker.com/engine/install/\&quot;\n\t\texit 1\n\tfi\n\n\tcase \&quot;$1\&quot; in\n\t  container-start) container_start ;;\n\t  container-stop)  container_stop ;;\n\t  image-build)     image_build ;;\n\t  clean)           clean ;;\n\t  *)               print_usage ;;\n\tesac\n}\n\nmain $@\n```\n\nWhat this script does:\n\n- **`image-build`** Builds our Docker image from the `Dockerfile`.\n- **`container-start`** Starts a new container (or reuses an existing one) and drops you into a shell.\n- **`container-stop`** Stops the running container.\n- **`clean`** Removes the container and image, so you can start fresh.\n\nIn short, it hides the long Docker commands and gives you a simple interface.\n\n### First Run\n\nBefore we can use our container, we need to build the image. In your terminal (for Windows users, PowerShell works best), run:\n\n```bash\nsh docker.sh image-build   # Linux/macOS\nbash docker.sh image-build # Windows (PowerShell)\n```\n\nThen start the container with:\n\n```bash\nsh docker.sh container-start   # Linux/macOS\nbash docker.sh container-start # Windows (PowerShell)\n```\n\nThis will provide you with terminal access within your development environment. From here, we’re ready to write some assembly.\n\n## Assembly File Structure\n\nBefore we dive into coding, it’s important to understand how an assembly file is usually organized. Most assembly programs are divided into **sections**, each with a specific purpose. The exact details vary depending on the assembler and platform, but the structure is broadly similar everywhere.\n\nHere are the most common sections:\n\n- **`.data`** Holds variables and constants that are **initialised** when the program starts. For example, your “Hello, World!” string belongs here.\n- **`.bss`** Holds **uninitialised variables** (they start as zero by default). Think of this as a workspace where you can reserve space for data you’ll fill in later.\n- **`.text`** Contains the actual **instructions** of the program. This is where the CPU starts executing. The program’s entry point (often called `_start` on Linux or `main` in higher-level conventions) is defined in this section.\n\nA Simple Mental Model:\n\n- `.data` → “What I already know.”\n- `.bss` → “What I’ll figure out later.”\n- `.text` → “What I need to do.”\n\nFor our *Hello, World!* program, we only need two sections:\n\n- `.data` to store the message\n- `.text` to hold the instructions that display it\n\n## Writing Our First Assembly Program\n\nLet’s start building our first program! Inside your project directory, create a new file named `hello.asm`.\n\nThe first step is to set up the sections of our program. As we learned earlier, we’ll need:\n\n- a **`.data`** section for our message\n- a **`.text`** section for the instructions that display it.\n\nWe can declare these sections with the `section` keyword:\n\n```asm\nsection .data                           ; Create the data section\nsection .text                           ; Create the text section\n```\n\n### Adding Data\n\nOur program needs just two pieces of data:\n\n1. the **message** we want to print, and\n2. the **length** of that message.\n\nBecause this program is simple, we don’t need any dynamic memory management. We can store everything directly in the `.data` section. To define the message, we’ll use the assembler directive `db` (*define byte*). This instructs the assembler to allocate memory space and fill it with the values we provide. In this case, that’s the string `\&quot;Hello, World!\&quot;` followed by `0x0A`, which represents the newline character (`&#39;\\n&#39;`).\n\n```asm\n\nsection .data                           ; Create the data section\n    msg     db  \&quot;Hello, World!\&quot;, 0x0A   ; Our message plus a newline (0x0A = &#39;\\n&#39;)\n    \nsection .text                           ; Create the text section\n```\n\nNow we also need the **length of the message**. We can compute it automatically using the `equ` directive (*equate*). Unlike `db`, `equ` does not allocate memory. Instead, it defines a constant value that the assembler substitutes wherever the label is used. To get the length, we subtract the address of the beginning of the message (`msg`) from the current location counter (`$`). The symbol `$` always refers to the assembler’s current position, which in this case is right after the message we just defined.\n\n```asm\nsection .data                           ; Create the data section\n    msg     db  \&quot;Hello, World!\&quot;, 0x0A   ; Our message plus a newline (0x0A = &#39;\\n&#39;)\n    len     equ $ - msg                 ; Define a constant len with the message length\n    \nsection .text                           ; Create the text section\n```\n\n### Writing the Code\n\nNow that our data is defined, it’s time to write the actual instructions in the **`.text`** section. This is where the CPU will start executing our program. Every program needs an **entry point**, ****a place where execution begins. In Linux assembly, this is usually the label `_start`. We’ll declare it as a global symbol so the linker knows where to begin:\n\n```asm\nsection .data                           ; Create the data section\n    msg     db  \&quot;Hello, World!\&quot;, 0x0A   ; Our message plus a newline (0x0A = &#39;\\n&#39;)\n    len     equ $ - msg                 ; Define a constant len with the message length\n\nsection .text                           ; Create the text section\n    global _start                       ; Tell the linker the entry point is _start\n\n_start:                                 ; Entry point of our program\n```\n\nTo display text on the screen, we need to ask the operating system for help. In Linux, this is done using a **system call**. A system call is like raising your hand and asking the OS: “Hey, can you do this for me?” We’ll use the `write` system call, which has this signature:\n\n```c\nwrite(fd, buf, count)\n```\n\n- `fd` = file descriptor (1 means standard output, the terminal).\n- `buf` = address of the data to write (our `msg`).\n- `count` = number of bytes to write (our `len`).\n\nIn x86-64 Linux, [system calls](https://blog.rchapman.org/posts/Linux_System_Call_Table_for_x86_64/) are made by:\n\n1. putting the syscall number into the `rax` register,\n2. putting the arguments into registers (`rdi`, `rsi`, `rdx`, …), and\n3. executing the instruction `syscall`.\n\nThe syscall number for `write` is **1**.\n\nHere’s how we set up and call `write`:\n\n```asm\nmov     rax, 1                      ; Syscall number for write\nmov     rdi, 1                      ; File descriptor 1 = stdout\nmov     rsi, msg                    ; Address of the string\nmov     rdx, len                    ; Length of the string\nsyscall                             ; Invoke the system call\n```\n\nAfter printing the message, the program still needs to exit cleanly. That’s another syscall: `exit`.\n\n- The syscall number for `exit` is **60**.\n- Its only argument is the exit code (0 means success).\n\n```asm\nmov     rax, 60                     ; syscall number for exit\nxor     rdi, rdi                    ; exit code 0 (using xor to set rdi = 0)\nsyscall                             ; Invoke the system call\n```\n\nHere’s the full `hello.asm` so far:\n\n```asm\nsection .data                           ; Create the data section\n    msg     db  \&quot;Hello, World!\&quot;, 0x0A   ; Our message plus a newline (0x0A = &#39;\\n&#39;)\n    len     equ $ - msg                 ; Define a constant len with the message length\n\nsection .text                           ; Create the text section\n    global _start                       ; Tell the linker the entry point is _start\n\n_start:                                 ; Entry point of our program\n    ; write(fd1, msg, len)\n    mov     rax, 1                      ; Syscall number for write\n    mov     rdi, 1                      ; File descriptor 1 = stdout\n    mov     rsi, msg                    ; Address of the string\n    mov     rdx, len                    ; Length of the string\n    syscall                             ; Invoke the system call\n\n    ; exit(0)\n    mov     rax, 60                     ; syscall number for exit\n    xor     rdi, rdi                    ; exit code 0 (using xor to set rdi = 0)\n    syscall                             ; Invoke the system call\n```\n\n## Assembling, Linking, and Running\n\nWe’ve written our `hello.asm` file, now it’s time to bring it to life! The process has three steps:\n\n1. **Assemble:** convert the human-readable assembly into machine code (`.o` file).\n2. **Link:** package that machine code into a proper executable (`hello`).\n3. **Run:** execute it and see the magic happen.\n\n### Option 0: Use `make` (recommended)\n\nSince we installed `make` in our container, we can automate these steps with a **Makefile**. Inside your project folder, create a file named `Makefile`:\n\n```makefile\nall: hello\n\nhello: hello.o\n\tld hello.o -o hello\n\nhello.o: hello.asm\n\tnasm -f elf64 hello.asm -o hello.o\n\nclean:\n\trm -f hello hello.o\n```\n\nNow you can build your program with a single command:\n\n```bash\nmake\n```\n\nAnd when you want to clean up all build artefacts:\n\n```bash\nmake clean\n\n```\n\n### Step 1: Assemble\n\nManually, the first step is turning your source code into an **object file**:\n\n```bash\nnasm -f elf64 hello.asm -o hello.o\n```\n\n- `f elf64` → tells NASM to generate 64-bit ELF output (Linux’s standard format).\n- `hello.asm` → your assembly source file.\n- `o hello.o` → output file (`.o` = object file).\n\n### Step 2: Link\n\nNext, we use the GNU linker `ld` to create an **executable** from the object file:\n\n```bash\nld hello.o -o hello\n\n```\n\n- `hello.o` → the object file we just created.\n- `o hello` → the name of the final executable.\n\n### Step 3: Run\n\nNow execute your program:\n\n```bash\n./hello\n```\n\nYou should see:\n\n```\nHello, World!\n```\n\nCongratulations, you’ve just written, built, and executed your first **Hello World in pure x86 assembly**!&quot;],&quot;filePath&quot;:[0,&quot;src/content/posts/hello-world/hello-world-asm.mdx&quot;],&quot;assetImports&quot;:[1,[[0,&quot;./assets/coding-setup.jpg&quot;]]],&quot;digest&quot;:[0,&quot;aba9e843e4da864b&quot;],&quot;deferredRender&quot;:[0,true],&quot;collection&quot;:[0,&quot;posts&quot;],&quot;slug&quot;:[0,&quot;hello-world/hello-world-asm&quot;],&quot;render&quot;:[0,null]}],[0,{&quot;id&quot;:[0,&quot;the-tough-love-architecture-guide/2-refactoring-a-bad-design-a-step-by-step-example.mdx&quot;],&quot;data&quot;:[0,{&quot;author&quot;:[0,&quot;Quinn&quot;],&quot;collection&quot;:[0,&quot;The Tough Love Architecture Guide&quot;],&quot;chapter&quot;:[0,2],&quot;title&quot;:[0,&quot;Refactoring a Bad Design: A Step-by-Step Example&quot;],&quot;shortname&quot;:[0,&quot;Bad Design&quot;],&quot;date&quot;:[3,&quot;2025-09-21T00:00:00.000Z&quot;],&quot;tags&quot;:[1,[[0,&quot;Software Design Patterns&quot;]]],&quot;metaTags&quot;:[1,[[0,&quot;Refactoring Java Code&quot;],[0,&quot;Clean Code Practices&quot;],[0,&quot;Software Architecture&quot;],[0,&quot;UserManager Class Example&quot;],[0,&quot;Technical Debt Management&quot;],[0,&quot;Java Unit Testing&quot;],[0,&quot;Mocking in Java (Mockito)&quot;],[0,&quot;Code Maintainability&quot;],[0,&quot;Incremental Refactoring&quot;],[0,&quot;Testable Code Design&quot;],[0,&quot;Object-Oriented Design Principles&quot;],[0,&quot;Single Responsibility Principle (SRP)&quot;]]],&quot;difficulty&quot;:[0,&quot;Beginner&quot;],&quot;readTime&quot;:[0,&quot;10 min&quot;],&quot;image&quot;:[0,{&quot;src&quot;:[0,&quot;/assets/BannerRefactoringBadDesign.CtFcZgfN.png&quot;],&quot;width&quot;:[0,1988],&quot;height&quot;:[0,1500],&quot;format&quot;:[0,&quot;png&quot;]}],&quot;alt&quot;:[0,&quot;Programmer behinde a computer&quot;],&quot;description&quot;:[0,&quot;Learn how to refactor an overgrown Java class using incremental steps, abstractions, and unit testing.&quot;]}],&quot;body&quot;:[0,&quot;Let&#39;s be honest: most projects don&#39;t start with a bad design. Over time, requirements change or new ones get added. Perhaps we have a tight deadline to meet, or maybe we&#39;re just being lazy, but often we will just hack the new requirements into the original design. We just tell ourselves that we&#39;ll refactor this later, but of course, we never do. Imagine a scenario where a seemingly minor piece of unrefactored code caused a system outage. This can result in thousands of dollars in lost revenue within a matter of hours. Such real-world setbacks underscore the critical importance of timely refactoring and set the stage for understanding the need to manage technical debt responsibly.\n\nA few deadlines later, and that “*temporary*” architecture has roots so deep that nobody wants to touch it. The code works..., but it&#39;s very fragile, hard to test, and impossible to extend without breaking something.\n\nIn this article, I will present a small example of a single class that started with good intentions but over time has grown into a monster that only a few of us dare tame. You will be able to translate the techniques I use to tame the beast to your real-life projects.\n\n## A bad design - (Setting the scene)\n\nLet me introduce you to our scene: the UserManager class.\n\nRight now, this class does a bit of everything:\n\n- Creating user\n- Saving them to the database\n- Sending welcome emails\n- Logging user actions\n\n```java\npublic class UserManager {\n    private Database database;\n    private EmailService emailService;\n    private Logger logger;\n\n    public UserManager(Database database, EmailService emailService, Logger logger) {\n        this.database = database;\n        this.emailService = emailService;\n        this.logger = logger;\n    }\n\n    public void createUser(String name, String email) {\n        // Save user to database\n        database.save(new User(name, email));\n\n        // Send welcome email\n        emailService.send(email, \&quot;Welcome to our app!\&quot;);\n\n        // Log the action\n        logger.log(\&quot;User created: {}\&quot;, name);\n    }\n\n    public void deleteUser(String email) {\n        database.delete(email);\n        logger.log(\&quot;User deleted: {}\&quot;, email);\n    }\n}\n\n```\n\nInitially, this class was created simply for storing users in a database. Even though you might initially think this class looks fine. It has become a sleeping monster; this class has too many responsibilities, is tightly coupled, and is hard to test. Now, let&#39;s break down the steps needed to start and refactor this.\n\n## Step 1 - Identify the problem\n\nMany developers will see some \&quot;Messy\&quot; code and think, \&quot;I need to rewrite this.\&quot; However, let me explain why this could be dangerous. Bad code can still contain a significant amount of business logic, undocumented hacks, and edge cases. For instance, there might be a seemingly redundant line of code that checks if a user&#39;s name is exactly 13 characters long. Although it may seem unusual, it could be an essential edge case for handling inputs from a specific legacy system that incorrectly handles overflow. If you simply rewrite the code, there is a significant chance you will lose the hidden knowledge buried inside the existing codebase.\n\nInstead of immediately rewriting the code, you can better ask yourself the following questions:\n\n- ***What exactly is wrong?***\n- ***Why is it wrong?***\n\nIf we answer these questions for our class, it comes down to the problem that the class has too many responsibilities (user creation, persistence, logging, and email sending). This is incorrect because the class has too many responsibilities, creating the risk that changing one thing will break another.\n\nRefactoring this class isn&#39;t just about style. It&#39;s about concerns related to testability and tight coupling.\n\n## Step 2 - Choose a better solution\n\nLet&#39;s not be like most developers and skip this part. But instead of just starting and rewriting the code, trying to hammer out a better solution, ask these three questions first:\n\n- *What role should this class or component actually play?*\n- *Which responsibility should it keep and which should it rewrite?*\n- *What are the most important constraints right now? (testability, performance, maintainability)*\n\nIn our case, the **UserManager** is overwhelmed with various responsibilities, including persistence, notifications, and logging. We need to shift the role of our class from “doing everything” to an orchestrator.\n\nIt means the **UserManager** class should just coordinate the workflow. However, it should not be aware of how each specific activity is implemented and executed. We need to create specific classes for each task (**UserRepository, EmailNotifier**).\n\nWhen we actually try to find a better solution, we&#39;re not just cleaning up the code; we&#39;re also redefining the architecture around the identified problem. We&#39;re not worried about choosing the coolest pattern, but we actually try to find a good solution.\n\n## Step 3 - Create an implementation plan\n\nNow, for this step, we need some real discipline. We identified the problem and found a solution to fix it. What is left but deleting this class and writing it again right!? With this approach, we risk losing working code, introducing new bugs, or even reintroducing the same design problems.\n\nInstead, let&#39;s take a safer approach; think *incremental refactoring.* We make small and safe changes one at a time, which we can test individually. This approach will give us a better chance of retaining all functionality.\n\nThis is a simple playbook you can follow once ready to implement your solution:\n\n1. **Introduce abstraction early.** Try to define your interfaces and abstract classes before implementing them. This approach will help you determine if your predefined contracts are sensible without having to implement them. For our piece of code, we need to create the interfaces ***UserRepository** and **EmailNotifier.***\n2. **Start with one responsibility.** Don&#39;t take out everything at once. For example, in the **UserManager** class, it would make sense to first extract the logic for the **UserRepository** while keeping the rest of the code intact.\n3. **Strangle old code.** Don&#39;t delete existing methods straight away. Let the abstraction take over piece by piece. Only remove the old code once you&#39;re confident that you haven&#39;t broken anything and have covered all the expected behaviours.\n4. **Test as you go.** After adding the abstraction, write unit tests for it. Verify your implementation and ensure that your refactoring hasn&#39;t broken anything.\n5. **Keep the class working at every stage.** Even when you&#39;re in the middle of refactoring, your code should still work. If you follow this approach, it will be easy to identify when and where you could have made a possible mistake.\n\nThe primary concept of this playbook is straightforward: each step should be reversible. If something fails, you can rollback that step instead of needing to do a massive rewrite and spend a lot of time refactoring.\n\n## Step 4 - Implement the changes\n\nWe have finally arrived at the fun part, and we can start refactoring. Let&#39;s refactor our **UserManager** class using the playbook defined in step 3.\n\n### Step 4.1 Introduce the abstraction\n\nLet&#39;s start by introducing some abstraction to the UserManager. Our class does not need to know how the underlying implementation works. We will create two interfaces: one for the EmailManager and one for the UserRepository. The heaviest dependency is the UserRepository, so let&#39;s start removing the direct coupling between the UserManager and the UserRepository.\n\nThe UserRepository interface will have two methods: one to save a user and one to delete a user from the database. Our UserRepository will look like this:\n\n```java\npublic interface UserRepository {\n    void save(User user);\n    void deleteById(String emailAddress);\n}\n```\n\nNext, we need to extract the email sending logic. We will follow the same approach where the UserManager class does not need to know the underlying implementation. Our EmailNotifier interface will have one method that allows us to send a welcome email.\n\n```java\npublic interface EmailNotifier {\n    void sendWelcomeEmail(String emailAddress);\n}\n```\n\n### Step 4.2 Extract the persistence logic\n\nNow that we have defined our interfaces, let&#39;s write an implementation. We will implement the persistence logic in the UserRepository, like this:\n\n```java\npublic class UserRepositoryImpl implements UserRepository {\n    private final Database database;\n\n    public UserRepositoryImpl(Database database) {\n        this.database = database;\n    }\n\n    @Override\n    public void save(User user) {\n        database.save(user);\n    }\n\n    @Override\n    public void deleteById(String emailAddress) {\n        database.delete(emailAdress);\n    }\n}\n```\n\n### Step 4.3 Extract the notification logic\n\nLastly, we need to implement our second interface: the EmailNotifier. Our implementation will look like this:\n\n```java\npublic class EmailNotifierImpl implements EmailNotifier {\n    private final EmailService emailService;\n\n    public EmailNotifierImpl(EmailService emailService) {\n        this.emailService = emailService;\n    }\n\n    @Override\n    public void sendWelcomeEmail(String emailAdress) {\n        emailService.send(emailAdress, \&quot;Welcome to our app!\&quot;);\n    }\n}\n```\n\n### Step 4.4. Update UserManager to orchestration\n\nNow, let&#39;s add these interfaces to the UserManager class.\n\n```java\npublic class UserManager {\n    private final UserRepository userRepository;\n    private final EmailNotifier emailNotifier;\n    private final Logger logger;\n\n    public UserManager(UserRepository userRepository, EmailNotifier emailNotifier, Logger logger) {\n        this.userRepository = userRepository;\n        this.emailNotifier = emailNotifier;\n        this.logger = logger;\n    }\n\n    public void createUser(String name, String email) {\n        userRepository.save(new User(name, email));\n        emailNotifier.sendWelcomeEmail(email);\n        logger.log(\&quot;User created: {}\&quot;, name);\n    }\n\n    public void deleteUser(String emailAddress) {\n        userRepository.deleteById(emailAddress);\n        logger.log(\&quot;User deleted: {}\&quot;, emailAddress);\n    }\n}\n```\n\n## Step 4.5. Unit tests\n\nTo ensure the robustness and functionality after our refactoring, it is crucial to implement unit tests consistently. Our primary goal is to verify key functionality, such as user management, and confirm that these aspects function without errors. We begin by writing unit tests for each of our interfaces and the UserManager. This involves verifying the core operations of saving and deleting users, ensuring data integrity, and operational reliability.\n\n```java\nclass UserRepositoryTests {\n    private UserRepository userRepo;\n    private Database database;\n\t\n    @BeforeEach\n    void init() {\n        database = mock(Database.class);\n        userRepo = new UserRepositoryImpl(database);\n    }\n\t\n    @Test\n    void testSaveUser() {\n        User user = new User(\&quot;testUser\&quot;, \&quot;testUser@mail.com\&quot;);\n        userRepo.save(user);\n    \n        verify(database, times(1)).save(user);\n    }\n\t\n    @Test\n    void testDeleteById() {\n        String email = \&quot;testUser@mail.com\&quot;;\n        userRepo.deleteById(email);\n    \n        verify(database, times(1)).delete(email);\n    }\n}\n```\n\nNext, we need to verify the EmailNotifier. For this interface, we need to check if we can successfully send a welcome email.\n\n```java\nclass EmailNotifierTests {\n    private EmailNotifier emailNotifier;\n    private EmailService emailService;\n\n    @BeforeEach\n    void init() {\n        emailService = mock(EmailService.class);\n        emailNotifier = new EmailNotifierImpl(emailService);\n    }\n\n    @Test\n    void testSendWelcomeEmail() {\n        String email = \&quot;testUser@mail.com\&quot;;\n        emailNotifier.sendWelcomeEmail(email);\n    \n        verify(emailService, times(1)).send(email, \&quot;Welcome to our app!\&quot;);\n    }\n}\n```\n\nThe final part we need to verify is the UserManager, where we bring it all together. For our UserManager unit tests, we should focus on verifying collaboration, ensuring it effectively delegates tasks to the appropriate interfaces, such as UserRepository and EmailNotifier. Instead of checking internal state changes, we should utilise mocks for these components. This approach will allow us to assert that the interfaces were indeed called, indicating successful orchestration.\n\n```java\nclass UserManagerTests {\n    private UserManager userManager;\n    private UserRepository userRepository;\n    private EmailNotifier emailNotifier;\n    private Logger logger;\n\n    @BeforeEach\n    void init() {\n        userRepository = mock(UserRepository.class);\n        emailNotifier = mock(EmailNotifier.class);\n        logger = mock(Logger.class);\n        \n        userManager = new UserManager(userRepository, emailNotifier, logger);\n    }\n\n    @Test\n    void testCreateUser() {\n        userManager.createUser(\&quot;testUser\&quot;, \&quot;testUser@mail.com\&quot;);\n        \n        verify(userRepository, times(1)).save(any(User.class));\n        verify(emailNotifier, times(1)).sendWelcomeEmail(\&quot;testUser@mail.com\&quot;);\n        verify(logger, times(1)).log(\&quot;User created: {}\&quot;, \&quot;testUser\&quot;);\n    }\n\n    @Test\n    void testDeleteUser() {\n        userManager.deleteUser(\&quot;testUser@mail.com\&quot;);\n        \n        verify(userRepository, times(1)).deleteById(\&quot;testUser@mail.com\&quot;);\n        verify(logger, times(1)).log(\&quot;User deleted: {}\&quot;, \&quot;testUser@mail.com\&quot;);\n    }\n}\n```\n\n## Refactoring is About Purpose, Not Perfection\n\nRefactoring isn&#39;t about making code look pretty. It&#39;s about making the design better fit the problem. In our original **UserManager** class, the code worked, but it was brittle and hard to maintain. By separating the functionality, introducing abstraction, and refactoring in safe steps, we made it flexible, testable, and ready for future maintenance. Next time your face badly designed code, remember:\n\n- Identify the problem before you touch code.\n- Select a more suitable direction based on the constraints.\n- Break the refactoring down into safe, reversible steps.\n\nSmall, deliberate changes beat a massive rewrite every time. To put this into practice, I challenge you: identify one overgrown class in your codebase today and apply Step 1—Identify the problem. This initial step can pave the way for meaningful refactoring and tangible improvements in your projects.&quot;],&quot;filePath&quot;:[0,&quot;src/content/posts/the-tough-love-architecture-guide/2-refactoring-a-bad-design-a-step-by-step-example.mdx&quot;],&quot;assetImports&quot;:[1,[[0,&quot;./assets/BannerRefactoringBadDesign.png&quot;]]],&quot;digest&quot;:[0,&quot;7b2086829739bbf0&quot;],&quot;deferredRender&quot;:[0,true],&quot;collection&quot;:[0,&quot;posts&quot;],&quot;slug&quot;:[0,&quot;the-tough-love-architecture-guide/2-refactoring-a-bad-design-a-step-by-step-example&quot;],&quot;render&quot;:[0,null]}],[0,{&quot;id&quot;:[0,&quot;the-tough-love-architecture-guide/3-what-actually-works-in-high-performance systems.mdx&quot;],&quot;data&quot;:[0,{&quot;author&quot;:[0,&quot;Quinn&quot;],&quot;collection&quot;:[0,&quot;The Tough Love Architecture Guide&quot;],&quot;chapter&quot;:[0,3],&quot;title&quot;:[0,&quot;Design Patterns for Performance: What Actually Works in High-Performance Systems&quot;],&quot;shortname&quot;:[0,&quot;Performance&quot;],&quot;date&quot;:[3,&quot;2025-10-26T00:00:00.000Z&quot;],&quot;tags&quot;:[1,[[0,&quot;Software Design Patterns&quot;]]],&quot;metaTags&quot;:[1,[[0,&quot;high performance systems&quot;],[0,&quot;high frequency trading architecture&quot;],[0,&quot;software design patterns&quot;],[0,&quot;concurrency design patterns&quot;],[0,&quot;reactor pattern&quot;],[0,&quot;actor model concurrency&quot;],[0,&quot;fan out fan in pattern&quot;],[0,&quot;cache-aside pattern&quot;],[0,&quot;sharding pattern&quot;],[0,&quot;zero-copy io&quot;],[0,&quot;memory-mapped files&quot;],[0,&quot;circuit breaker pattern&quot;],[0,&quot;bulkhead pattern&quot;],[0,&quot;load shedding pattern&quot;],[0,&quot;fault tolerant systems&quot;],[0,&quot;low latency architecture&quot;],[0,&quot;scalable system design&quot;],[0,&quot;io bound optimization&quot;],[0,&quot;concurrent programming patterns&quot;],[0,&quot;resilient software architecture&quot;],[0,&quot;performance optimization techniques&quot;],[0,&quot;system bottleneck analysis&quot;],[0,&quot;distributed systems design&quot;],[0,&quot;maintainable high performance code&quot;],[0,&quot;real time trading systems&quot;]]],&quot;difficulty&quot;:[0,&quot;Beginner&quot;],&quot;readTime&quot;:[0,&quot;7 min&quot;],&quot;image&quot;:[0,{&quot;src&quot;:[0,&quot;/assets/BannerHighPerformance.psXMTq8-.jpg&quot;],&quot;width&quot;:[0,3959],&quot;height&quot;:[0,2880],&quot;format&quot;:[0,&quot;jpg&quot;]}],&quot;alt&quot;:[0,&quot;Speedometer&quot;],&quot;description&quot;:[0,&quot;Learn how to use proven design patterns to build high-performance and low-latency systems. Explore the Reactor pattern, Actor model, Fan-out/Fan-in, Cache-Aside, Sharding, and resilience patterns like Circuit Breaker, Bulkhead, and Load Shedding. Improve speed, scalability, and maintainability in complex architectures.&quot;]}],&quot;body&quot;:[0,&quot;You might think to yourself that we don’t need design patterns when building high-frequency trading systems. This might be true for fun hobby projects, but in the real world, it will lead to a codebase that is hard to maintain and prone to subtle bugs like race conditions and deadlocks. Engineers often face challenges such as these when concurrent processes inadvertently interfere with each other. Debugging and resolving such issues can be time-consuming and complex. By using the right design patterns, we can maintain a readable codebase while mitigating these issues and still achieving the required performance.\n\nIn this post, I will present several different patterns that can be utilized for high-performance systems. With these patterns, we will reduce latency and utilize resources more efficiently, such as CPU, memory, and I/O. For a better understanding of computer resources, you can read an [introduction to computer architecture](https://www.biosconfessions.com/posts/introduction-computer-architecture/). To choose the right pattern, it is crucial to understand the specific bottlenecks of your system. For instance, if your system&#39;s primary challenge is I/O-bound operations, the Reactor pattern can be beneficial as it efficiently handles multiple concurrent requests. On the other hand, if the bottleneck is computational, patterns focusing on concurrency, like the Actor model, might be more suitable. Thus, determining whether you are optimizing the code for compute, data, networking, or concurrency is the key to selecting the most effective design pattern.\n\n## Why patterns matter for high-performance systems\n\nDesign patterns enforce structure and best practices, allowing for better code quality and maintainability. Even in high-performance systems, it&#39;s still important to have maintainable and quality code. When building a system optimized for speed, complexity, and readability can quickly spiral out of control. Luckily, there are also patterns that enable us to reason about and build quality, maintainable code. By combining the right patterns, we can build a high-performance system and keep some sanity in our code.\n\n## Concurrency and I/O patterns\n\nLet&#39;s first discuss patterns for Concurrency and I/O. These patterns will help us to structure multi-threaded and asynchronous code. We will discuss three popular patterns used in industry to solve these issues.\n\n### Reactor pattern\n\nThe reactor pattern is an event-driven design with a single-threaded event loop that demultiplexes I/O events and dispatches them to handlers. By using non-blocking I/O, a reactor can handle many concurrent I/O-bound requests with minimal threads and low latency. This pattern is widely used in high-performance servers and networking frameworks because it avoids the overhead of blocking threads or one-thread-per-connection models.\n\n### Actor model\n\nThis pattern treats each concurrent entity as an *actor* with its own private state, processing incoming messages one at a time. Actors communicate only via asynchronous message passing, eliminating the need for locks or shared-memory synchronization. Actors are extremely lightweight (far lighter than OS threads) and can be spawned in large numbers, allowing millions of actors to run concurrently. This leads to low-latency, high-throughput processing, as each actor handles its tasks independently.\n\n### Fan out / Fan in\n\nThe Fan out / Fan in pattern distributes workloads to multiple parallel workers (“fan-out”) and then aggregates their results (“fan-in”). A large computation can be split into many subtasks that run concurrently on multiple threads or machines; once all tasks complete, their partial results are combined. This pattern efficiently scales out computation across multicore CPUs or distributed systems. By parallelizing independent work, it can drastically reduce total processing time.\n\n## Data Access and Memory Optimization\n\nWhen writing high-performance systems, it&#39;s important to efficiently handle reading, writing, and managing data. This could be handling data from a database, a file, or a remote API. In this section, we will discuss patterns that help us separate data logic from business logic. Making data operations consistent and reusable, and supporting multiple data sources without rewriting core logic.\n\n### Cache-Aside pattern\n\nThe cash-Aside pattern lets an application explicitly check an external cache before the primary data store. On a cache miss, it loads the data from the datastore and populates the cache. This lazy-loading strategy means frequently accessed data is served from fast memory rather than slower databases. As a result, repeated reads of the same data have much lower latency, and overall throughput improves, since the database sees fewer queries.\n\n### Sharding pattern\n\nThe Sharing pattern enables the horizontal partitioning of a dataset across multiple database instances (shards) to improve performance. By splitting data (for example, by key range or hash) into separate shards, each shard handles only a subset of the workload, reducing contention and enabling parallel queries. Sharding boosts throughput and also enhances availability: a failure or maintenance on one shard affects only that partition, not the entire dataset.\n\n### Zero-Copy and Memory-Mapped files\n\nThe Zero-Copy and Memory-Mapped file pattern uses techniques to eliminate extra data copying between the user space and kernel. Zero-copy I/O lets devices transfer data directly between kernel and user memory without CPU intervention. Memory-mapped files (mmap) puts the content into the process’s address space, so after the initial mapping, reads and writes go straight to RAM without an extra copy or system calls. In effect, the file data becomes part of memory, dramatically speeding up file and network I/O for large transfers.\n\n## Resilience and Stability\n\nAny high-performance system should be resilient and fault-tolerant. For high-performance systems to be useful, we need to make sure they&#39;re consistent and predictable under high workloads. When the system is fast, when everything is perfect, but it crashes in the real world, it is not truly high performance. Therefore, in this section, we will discuss some patterns that can help to have a stable and reliable system while still being high-performance.\n\n### Circuit breaker\n\nThe circuit breaker pattern wraps calls to an external service and trips (opens) if failures exceed a threshold. When open, calls fail immediately instead of waiting on timeouts or retry loops. This prevents resource exhaustion (threads, connections) from constantly retrying a dead service, giving the system time to recover. In short, a circuit breaker preserves stability by failing fast on unhealthy dependencies.\n\n### Bulkhead pattern\n\nWith the bulkhead pattern, we can isolate components or consumers into separate pools so that a failure in one does not bring down others. Like compartments in a ship, this means partitioning services or resources (for example, with dedicated thread pools or separate processes). If one partition fails or overloads, it does not deplete shared resources, and the rest of the system can continue operating. Bulkheads confine failures, preventing cascading outages across the entire system\n\n### Load sheading\n\nThe load-shading pattern intentionally drops or delays lower-priority requests when the load is too high. Rather than letting queues grow and latencies spike to the point of collapse, the system sheds excess work to stay responsive. For example, a server might reject additional requests once CPU or memory utilization crosses a threshold. This trade-off sacrifices some non-critical throughput to guarantee that high-priority tasks still meet latency targets.\n\n## Next steps\n\nThe right design patterns are a powerful tool for building high-performance systems in a maintainable way. When used correctly, these patterns will make our code more maintainable, scalable, and improve code quality. In practice, we first need to identify our system&#39;s bottlenecks before choosing the right pattern. Once you know these bottlenecks, you can apply the right pattern and address them. For example, choose the reactor pattern if your application has I/O heavy services, or integrate cash-aside and sharding to speed up data access. As you apply these patterns, continuously monitor the effects of the changes. Watch the latency and throughput, and adjust the time-out and load-shedding thresholds as needed. With careful testing and incremental adoption, you can dramatically improve performance while preserving code quality and maintainability.&quot;],&quot;filePath&quot;:[0,&quot;src/content/posts/the-tough-love-architecture-guide/3-what-actually-works-in-high-performance systems.mdx&quot;],&quot;assetImports&quot;:[1,[[0,&quot;./assets/BannerHighPerformance.jpg&quot;]]],&quot;digest&quot;:[0,&quot;d88b5ccf1d64fce5&quot;],&quot;deferredRender&quot;:[0,true],&quot;collection&quot;:[0,&quot;posts&quot;],&quot;slug&quot;:[0,&quot;the-tough-love-architecture-guide/3-what-actually-works-in-high-performance-systems&quot;],&quot;render&quot;:[0,null]}]]]}" ssr client="only" opts="{&quot;name&quot;:&quot;SearchModal&quot;,&quot;value&quot;:true}"></astro-island> <div data-astro-transition-persist="find-me-on-the-other-side" id="cc-container"> <script type="module" src="/assets/CookieConsent.astro_astro_type_script_index_0_lang.BGS9yL8D.js"></script> <script>
                // Restore the `show--consent` class if it was present before the page swap
                document.addEventListener(
                    "astro:before-preparation",
                    (event) => {
                        const htmlClassName =
                            window.document.documentElement.className;
                        const consentClassPresent = htmlClassName.includes(
                            "show--consent",
                        )
                            ? true
                            : false;
                        window._showConsentClass = consentClassPresent;
                    },
                );

                document.addEventListener("astro:before-swap", (event) => {
                    const showConsent = window._showConsentClass
                        ? ` show--consent`
                        : "";
                    event.newDocument.documentElement.className += showConsent;
                });
            </script> </div> </body> </html>