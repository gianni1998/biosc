<!DOCTYPE html><html lang="en"> <head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><link rel="icon" type="image/svg+xml" href="/favicon.ico"><link rel="canonical" href="https://www.biosconfessions.com/posts/"><meta name="generator" content="Astro v5.16.0"><!-- Google tag (gtag.js) --><script async src="https://www.googletagmanager.com/gtag/js?id=G-E96HPDSNG8">
        </script><script>
            window.dataLayer = window.dataLayer || [];
            window.gtag = function gtag(){ window.dataLayer.push(arguments); };

            window.gtag("js", new Date());
            window.gtag("consent", "default", {
                ad_storage: "denied",
                ad_user_data: "denied",
                ad_personalization: "denied",
                analytics_storage: "denied",
            });

            window.gtag("config", "G-E96HPDSNG8");
        </script><!-- Global Metadata --><title>Posts | BIOS Confessions</title><meta name="author" content="Quinn &#38; Gianni"><meta name="title" content="Posts | BIOS Confessions"><meta name="description" content="Clear, structured explanations of core CS topics, from fundamentals to advanced principles. Learn for free, at your own pace."><meta name="keywords" content><link rel="sitemap" href="/sitemap-index.xml"><link rel="alternate" type="application/rss+xml" title="Posts | BIOS Confessions" href="https://www.biosconfessions.com/rss.xml"><!-- Open Graph / Facebook --><meta property="og:title" content="Posts | BIOS Confessions"><meta property="og:description" content="Clear, structured explanations of core CS topics, from fundamentals to advanced principles. Learn for free, at your own pace."><meta property="og:type" content="website"><meta property="og:url" content="https://www.biosconfessions.com/posts/"><meta property="og:image" content="https://www.biosconfessions.com/assets/blog-placeholder.jpg"><!-- Twitter --><meta property="twitter:title" content="Posts | BIOS Confessions"><meta property="twitter:description" content="Clear, structured explanations of core CS topics, from fundamentals to advanced principles. Learn for free, at your own pace."><meta property="twitter:url" content="https://www.biosconfessions.com/posts/"><meta property="twitter:image" content="https://www.biosconfessions.com/assets/blog-placeholder.jpg"><meta property="twitter:card" content="summary_large_image"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/katex.min.css"><link rel="stylesheet" href="/assets/index.JAidztOc.css"></head> <body class="bg-silicon-100 scroll-smooth flex flex-col min-h-screen">  <header id="header" class="py-3" role="banner"> <div class="mx-auto max-w-6xl px-4 sm:px-6 lg:px-8 py-1 w-full">  <nav class="flex flex-wrap lg:grid lg:grid-cols-12 basis-full items-center" aria-label="Primary navigation"> <!-- Logo --> <div class="lg:col-span-3 flex items-center"> <a href="/" class="flex-none rounded-xl text-2xl inline-block font-bold focus-visible:outline focus-visible:outline-2 focus-visible:outline-offset-2 focus-visible:outline-gray-400" aria-label="BIOS Confessions homepage">
BIOS Confessions
</a> </div> <!-- Button Group --> <div class="flex items-center gap-x-1 lg:gap-x-2 ms-auto py-1 lg:ps-6 lg:order-3 lg:col-span-3"> <!-- Search Button --> <button type="button" id="search-button" class="size-9.5 relative flex justify-center items-center rounded-xl bg-silicon-50 border border-silicon-200 text-black hover:bg-silicon-0 focus:outline-hidden focus:bg-silicon-0 disabled:opacity-50 disabled:pointer-events-none" aria-label="Open search"> <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="2.5" stroke="currentColor" class="size-4" data-slot="icon" aria-hidden="true"> <path stroke-linecap="round" stroke-linejoin="round" d="m21 21-5.197-5.197m0 0A7.5 7.5 0 1 0 5.196 5.196a7.5 7.5 0 0 0 10.607 10.607Z"></path> </svg> </button> <!-- Mobile Menu Toggle --> <div class="lg:hidden"> <button type="button" id="collapse-button" class="size-9.5 flex justify-center items-center text-sm font-semibold rounded-xl bg-silicon-50 border border-silicon-200 text-black hover:bg-silicon-0 focus:outline-hidden focus:bg-silicon-0 disabled:opacity-50 disabled:pointer-events-none" aria-expanded="false" aria-controls="primary-menu" aria-label="Toggle navigation"> <!-- Hamburger Icon --> <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" stroke="currentColor" class="size-5" data-slot="icon" aria-hidden="true"> <line x1="3" x2="21" y1="6" y2="6"></line> <line x1="3" x2="21" y1="12" y2="12"></line> <line x1="3" x2="21" y1="18" y2="18"></line> </svg> <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" stroke="currentColor" class="hidden size-5" data-slot="icon" aria-hidden="true"> <path d="M18 6 6 18"></path> <path d="m6 6 12 12"></path> </svg> </button> </div> </div> <!-- Collapsible Navigation --> <div id="collapse" class="hidden overflow-hidden transition-all duration-300 basis-full grow lg:block lg:w-auto lg:basis-auto lg:order-2 lg:col-span-6" role="region" aria-label="Main menu" aria-hidden="true"> <ul id="primary-menu" class="flex flex-col gap-y-4 gap-x-0 mt-5 lg:flex-row lg:justify-center lg:items-center lg:gap-y-0 lg:gap-x-7 lg:mt-0" role="menubar"> <li role="none"> <a href="/" role="menuitem" class="inline-block text-black focus-visible:outline focus-visible:outline-2 focus-visible:outline-offset-2 focus-visible:outline-gray-400 hover:text-gray-600 focus:text-gray-600"> Home </a> </li><li role="none"> <a href="#" role="menuitem" class="inline-block text-black focus-visible:outline focus-visible:outline-2 focus-visible:outline-offset-2 focus-visible:outline-gray-400 relative focus-visible:outline before:absolute before:bottom-0.5 before:start-0 before:-z-1 before:w-full before:h-1 before:bg-blue-600"> Posts </a> </li><li role="none"> <a href="/about" role="menuitem" class="inline-block text-black focus-visible:outline focus-visible:outline-2 focus-visible:outline-offset-2 focus-visible:outline-gray-400 hover:text-gray-600 focus:text-gray-600"> Hello World </a> </li> </ul> </div> </nav>  </div> </header> <script type="module">document.addEventListener("DOMContentLoaded",()=>{const e=document.querySelector("#collapse-button"),t=document.querySelector("#collapse");if(!e||!t)return;const[n,d]=e.querySelectorAll("svg");e.addEventListener("click",()=>{const o=e.getAttribute("aria-expanded")==="true";e.setAttribute("aria-expanded",String(!o)),t.classList.toggle("hidden"),n.classList.toggle("hidden"),d.classList.toggle("hidden")}),document.querySelector("#search-button")?.addEventListener("click",()=>{window.dispatchEvent(new Event("openModal"))})});</script> <a href="#main" aria-label="Skip to Main content" aria-disabled="false" tabindex="0" class="sr-only focus:not-sr-only focus:absolute focus:top-2 focus:left-2 focus:py-3 focus:px-6 text-silicon-50 hover:text-blue-600 bg-blue-600 hover:bg-transparent border-2 border-blue-600 rounded-xl font-medium py-3 px-6 transition duration-200 false">  
Skip to Main content
  </a> <main id="main" class="shrink-0" role="main" tabindex="-1"> <section id="title" class="mt-20" aria-labelledby="title-heading"> <div class="mx-auto max-w-6xl px-4 sm:px-6 lg:px-8 py-1 w-full">  <div class="text-center"> <h1 id="title-heading" class="font-bold text-3xl sm:text-4xl mb-3"> Posts </h1> <p class="text-gray-600 text-lg">All available posts:</p> </div>  </div> </section>  <section id="posts" class="mb-20 mt-5" aria-labelledby="posts-heading"> <div class="mx-auto max-w-6xl px-4 sm:px-6 lg:px-8 py-1 w-full">  <h2 id="posts-heading" class="sr-only">Post list</h2> <div class="grid sm:grid-cols-2 md:grid-cols-3 lg:grid-cols-4 gap-6"> <article class="group flex flex-1 flex-col focus:outline-hidden" role="listitem"> <a href="/posts/beyond-the-cpu-io-buses-multicore-systems-and-modern-computer-architecture" class="flex flex-col h-full rounded-xl" aria-labelledby="post-title-beyond-the-cpu-io-buses-multicore-systems-and-modern-computer-architecture"> <div class="relative pt-[50%] sm:pt-[70%] rounded-xl overflow-hidden mb-3 shadow"> <img src="/assets/computer-architecture-transistor-to-system-guide.BpaNqm1a_Z178T5a.webp" alt="Cover image for the blog series &#34;From Transistor to System: A Friendly Guide to Computer Architecture,&#34; showing various computer components in a cheerful, cartoon style" decoding="async" loading="eager" fetchpriority="auto" width="1024" height="1024" class="size-full absolute top-0 start-0 rounded-xl object-cover group-hover:scale-105 group-focus:scale-105 transition-transform duration-500 ease-in-out"> </div> <div class="sm:px-3 mb-2"> <div class="flex items-center gap-2 mb-1"> <time datetime="December 28, 2025" class="text-gray-500 text-xs inline-block"> December 28, 2025 </time> <span class="bg-yellow-200 text-yellow-800 text-xs font-medium px-2.5 py-0.5 rounded-full"> Intermediate </span> </div> <h3 id="post-title-beyond-the-cpu-io-buses-multicore-systems-and-modern-computer-architecture" class="text-base font-semibold text-gray-900 group-hover:text-gray-600"> Beyond the CPU: I/O, Buses, Multicore Systems, and Modern Computer Architecture </h3> <p class="text-gray-600 text-sm line-clamp-3"> Learn how modern computers work beyond the CPU. This chapter explores I/O systems, buses, interrupts, DMA, multicore processors, GPUs, and how all components cooperate in a complete computer system. </p> </div> <div class="sm:px-3 mt-auto inline-flex items-center gap-x-1 text-sm text-blue-600 decoration-2 group-hover:underline group-focus:underline font-medium">
Read more
<svg xmlns="http://www.w3.org/2000/svg" fill="currentColor" viewBox="0 0 20 20" class="size-5" data-slot="icon" aria-hidden="true"> <path d="M8.22 5.22a.75.75 0 0 1 1.06 0l4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.75.75 0 0 1-1.06-1.06L11.94 10 8.22 6.28a.75.75 0 0 1 0-1.06Z" clip-rule="evenodd" fill-rule="evenodd"></path> </svg> </div> </a> </article><article class="group flex flex-1 flex-col focus:outline-hidden" role="listitem"> <a href="/posts/tranching-in-collateralized-debt-senior-vs-mezzanine-vs-equity-explained" class="flex flex-col h-full rounded-xl" aria-labelledby="post-title-tranching-in-collateralized-debt-senior-vs-mezzanine-vs-equity-explained"> <div class="relative pt-[50%] sm:pt-[70%] rounded-xl overflow-hidden mb-3 shadow"> <img src="/assets/tranching-in-collaterized-debt.h8tTybnR_Z17XDzs.webp" alt="Illustration explaining how loans and bonds work, including interest, repayment, and default risk" decoding="async" loading="eager" fetchpriority="auto" width="1584" height="672" class="size-full absolute top-0 start-0 rounded-xl object-cover group-hover:scale-105 group-focus:scale-105 transition-transform duration-500 ease-in-out"> </div> <div class="sm:px-3 mb-2"> <div class="flex items-center gap-2 mb-1"> <time datetime="December 21, 2025" class="text-gray-500 text-xs inline-block"> December 21, 2025 </time> <span class="bg-yellow-200 text-yellow-800 text-xs font-medium px-2.5 py-0.5 rounded-full"> Intermediate </span> </div> <h3 id="post-title-tranching-in-collateralized-debt-senior-vs-mezzanine-vs-equity-explained" class="text-base font-semibold text-gray-900 group-hover:text-gray-600"> Tranching in Collateralized Debt: Senior vs Mezzanine vs Equity Explained </h3> <p class="text-gray-600 text-sm line-clamp-3"> An in-depth introduction to collateralized debt obligations (CDOs), explaining tranching, credit risk redistribution, and how senior, mezzanine, and junior tranches shape risk and return using analytical examples and simulations. </p> </div> <div class="sm:px-3 mt-auto inline-flex items-center gap-x-1 text-sm text-blue-600 decoration-2 group-hover:underline group-focus:underline font-medium">
Read more
<svg xmlns="http://www.w3.org/2000/svg" fill="currentColor" viewBox="0 0 20 20" class="size-5" data-slot="icon" aria-hidden="true"> <path d="M8.22 5.22a.75.75 0 0 1 1.06 0l4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.75.75 0 0 1-1.06-1.06L11.94 10 8.22 6.28a.75.75 0 0 1 0-1.06Z" clip-rule="evenodd" fill-rule="evenodd"></path> </svg> </div> </a> </article><article class="group flex flex-1 flex-col focus:outline-hidden" role="listitem"> <a href="/posts/inside-the-cpu-how-instructions-are-fetched-decoded-and-executed" class="flex flex-col h-full rounded-xl" aria-labelledby="post-title-inside-the-cpu-how-instructions-are-fetched-decoded-and-executed"> <div class="relative pt-[50%] sm:pt-[70%] rounded-xl overflow-hidden mb-3 shadow"> <img src="/assets/computer-architecture-transistor-to-system-guide.BpaNqm1a_Z178T5a.webp" alt="Cover image for the blog series &#34;From Transistor to System: A Friendly Guide to Computer Architecture,&#34; showing various computer components in a cheerful, cartoon style" decoding="async" loading="eager" fetchpriority="auto" width="1024" height="1024" class="size-full absolute top-0 start-0 rounded-xl object-cover group-hover:scale-105 group-focus:scale-105 transition-transform duration-500 ease-in-out"> </div> <div class="sm:px-3 mb-2"> <div class="flex items-center gap-2 mb-1"> <time datetime="December 14, 2025" class="text-gray-500 text-xs inline-block"> December 14, 2025 </time> <span class="bg-yellow-200 text-yellow-800 text-xs font-medium px-2.5 py-0.5 rounded-full"> Intermediate </span> </div> <h3 id="post-title-inside-the-cpu-how-instructions-are-fetched-decoded-and-executed" class="text-base font-semibold text-gray-900 group-hover:text-gray-600"> Inside the CPU: How Instructions Are Fetched, Decoded, and Executed </h3> <p class="text-gray-600 text-sm line-clamp-3"> Learn how a CPU actually runs programs by coordinating registers, the ALU, and the control unit. This chapter explains the fetch–decode–execute instruction cycle with clear examples and practical insights into modern computer architecture. </p> </div> <div class="sm:px-3 mt-auto inline-flex items-center gap-x-1 text-sm text-blue-600 decoration-2 group-hover:underline group-focus:underline font-medium">
Read more
<svg xmlns="http://www.w3.org/2000/svg" fill="currentColor" viewBox="0 0 20 20" class="size-5" data-slot="icon" aria-hidden="true"> <path d="M8.22 5.22a.75.75 0 0 1 1.06 0l4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.75.75 0 0 1-1.06-1.06L11.94 10 8.22 6.28a.75.75 0 0 1 0-1.06Z" clip-rule="evenodd" fill-rule="evenodd"></path> </svg> </div> </a> </article><article class="group flex flex-1 flex-col focus:outline-hidden" role="listitem"> <a href="/posts/loans-and-bonds-explained-how-borrowing-interest-and-default-risk-really-work" class="flex flex-col h-full rounded-xl" aria-labelledby="post-title-loans-and-bonds-explained-how-borrowing-interest-and-default-risk-really-work"> <div class="relative pt-[50%] sm:pt-[70%] rounded-xl overflow-hidden mb-3 shadow"> <img src="/assets/loans-and-bonds-explained.cwsEEMkV_2g0xIG.webp" alt="Illustration explaining how loans and bonds work, including interest, repayment, and default risk" decoding="async" loading="eager" fetchpriority="auto" width="1344" height="768" class="size-full absolute top-0 start-0 rounded-xl object-cover group-hover:scale-105 group-focus:scale-105 transition-transform duration-500 ease-in-out"> </div> <div class="sm:px-3 mb-2"> <div class="flex items-center gap-2 mb-1"> <time datetime="December 7, 2025" class="text-gray-500 text-xs inline-block"> December 7, 2025 </time> <span class="bg-yellow-200 text-yellow-800 text-xs font-medium px-2.5 py-0.5 rounded-full"> Intermediate </span> </div> <h3 id="post-title-loans-and-bonds-explained-how-borrowing-interest-and-default-risk-really-work" class="text-base font-semibold text-gray-900 group-hover:text-gray-600"> Loans and Bonds Explained: How Borrowing, Interest, and Default Risk Really Work </h3> <p class="text-gray-600 text-sm line-clamp-3"> A clear introduction to how loans work, how lenders price interest, and how these concepts extend to bonds, coupon rates, and default risk—complete with formulas and simulations. </p> </div> <div class="sm:px-3 mt-auto inline-flex items-center gap-x-1 text-sm text-blue-600 decoration-2 group-hover:underline group-focus:underline font-medium">
Read more
<svg xmlns="http://www.w3.org/2000/svg" fill="currentColor" viewBox="0 0 20 20" class="size-5" data-slot="icon" aria-hidden="true"> <path d="M8.22 5.22a.75.75 0 0 1 1.06 0l4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.75.75 0 0 1-1.06-1.06L11.94 10 8.22 6.28a.75.75 0 0 1 0-1.06Z" clip-rule="evenodd" fill-rule="evenodd"></path> </svg> </div> </a> </article><article class="group flex flex-1 flex-col focus:outline-hidden" role="listitem"> <a href="/posts/memory-in-computer-architecture-registers-cache-ram--storage-explained" class="flex flex-col h-full rounded-xl" aria-labelledby="post-title-memory-in-computer-architecture-registers-cache-ram--storage-explained"> <div class="relative pt-[50%] sm:pt-[70%] rounded-xl overflow-hidden mb-3 shadow"> <img src="/assets/computer-architecture-transistor-to-system-guide.BpaNqm1a_Z178T5a.webp" alt="Cover image for the blog series &#34;From Transistor to System: A Friendly Guide to Computer Architecture,&#34; showing various computer components in a cheerful, cartoon style" decoding="async" loading="eager" fetchpriority="auto" width="1024" height="1024" class="size-full absolute top-0 start-0 rounded-xl object-cover group-hover:scale-105 group-focus:scale-105 transition-transform duration-500 ease-in-out"> </div> <div class="sm:px-3 mb-2"> <div class="flex items-center gap-2 mb-1"> <time datetime="November 30, 2025" class="text-gray-500 text-xs inline-block"> November 30, 2025 </time> <span class="bg-yellow-200 text-yellow-800 text-xs font-medium px-2.5 py-0.5 rounded-full"> Intermediate </span> </div> <h3 id="post-title-memory-in-computer-architecture-registers-cache-ram--storage-explained" class="text-base font-semibold text-gray-900 group-hover:text-gray-600"> Memory in Computer Architecture: Registers, Cache, RAM &amp; Storage Explained </h3> <p class="text-gray-600 text-sm line-clamp-3"> Detailed guide to how computer memory works, from registers and CPU caches to RAM, storage, memory addressing, paging, and the full memory hierarchy. Learn how modern systems manage data at every level. </p> </div> <div class="sm:px-3 mt-auto inline-flex items-center gap-x-1 text-sm text-blue-600 decoration-2 group-hover:underline group-focus:underline font-medium">
Read more
<svg xmlns="http://www.w3.org/2000/svg" fill="currentColor" viewBox="0 0 20 20" class="size-5" data-slot="icon" aria-hidden="true"> <path d="M8.22 5.22a.75.75 0 0 1 1.06 0l4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.75.75 0 0 1-1.06-1.06L11.94 10 8.22 6.28a.75.75 0 0 1 0-1.06Z" clip-rule="evenodd" fill-rule="evenodd"></path> </svg> </div> </a> </article><article class="group flex flex-1 flex-col focus:outline-hidden" role="listitem"> <a href="/posts/the-art-of-losing-slowly-how-to-manage-risk-variance-and-decisions-under-uncertainty" class="flex flex-col h-full rounded-xl" aria-labelledby="post-title-the-art-of-losing-slowly-how-to-manage-risk-variance-and-decisions-under-uncertainty"> <div class="relative pt-[50%] sm:pt-[70%] rounded-xl overflow-hidden mb-3 shadow"> <img src="/assets/banner-art-of-losing-slowely.DBSc2GqA_ZJwy46.webp" alt="Banner for The Art of Losing Slowly" decoding="async" loading="eager" fetchpriority="auto" width="1584" height="672" class="size-full absolute top-0 start-0 rounded-xl object-cover group-hover:scale-105 group-focus:scale-105 transition-transform duration-500 ease-in-out"> </div> <div class="sm:px-3 mb-2"> <div class="flex items-center gap-2 mb-1"> <time datetime="November 23, 2025" class="text-gray-500 text-xs inline-block"> November 23, 2025 </time> <span class="bg-yellow-200 text-yellow-800 text-xs font-medium px-2.5 py-0.5 rounded-full"> Intermediate </span> </div> <h3 id="post-title-the-art-of-losing-slowly-how-to-manage-risk-variance-and-decisions-under-uncertainty" class="text-base font-semibold text-gray-900 group-hover:text-gray-600"> The Art of Losing Slowly: How to Manage Risk, Variance and Decisions Under Uncertainty </h3> <p class="text-gray-600 text-sm line-clamp-3"> Learn how to manage risk, leverage variance, and make better decisions under uncertainty. A practical guide to thoughtful losses, expected value, and long-term thinking. </p> </div> <div class="sm:px-3 mt-auto inline-flex items-center gap-x-1 text-sm text-blue-600 decoration-2 group-hover:underline group-focus:underline font-medium">
Read more
<svg xmlns="http://www.w3.org/2000/svg" fill="currentColor" viewBox="0 0 20 20" class="size-5" data-slot="icon" aria-hidden="true"> <path d="M8.22 5.22a.75.75 0 0 1 1.06 0l4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.75.75 0 0 1-1.06-1.06L11.94 10 8.22 6.28a.75.75 0 0 1 0-1.06Z" clip-rule="evenodd" fill-rule="evenodd"></path> </svg> </div> </a> </article><article class="group flex flex-1 flex-col focus:outline-hidden" role="listitem"> <a href="/posts/how-the-control-unit-makes-the-cpu-work-signals-microcode-and-decoding" class="flex flex-col h-full rounded-xl" aria-labelledby="post-title-how-the-control-unit-makes-the-cpu-work-signals-microcode-and-decoding"> <div class="relative pt-[50%] sm:pt-[70%] rounded-xl overflow-hidden mb-3 shadow"> <img src="/assets/computer-architecture-transistor-to-system-guide.BpaNqm1a_Z178T5a.webp" alt="Cover image for the blog series &#34;From Transistor to System: A Friendly Guide to Computer Architecture,&#34; showing various computer components in a cheerful, cartoon style" decoding="async" loading="eager" fetchpriority="auto" width="1024" height="1024" class="size-full absolute top-0 start-0 rounded-xl object-cover group-hover:scale-105 group-focus:scale-105 transition-transform duration-500 ease-in-out"> </div> <div class="sm:px-3 mb-2"> <div class="flex items-center gap-2 mb-1"> <time datetime="November 16, 2025" class="text-gray-500 text-xs inline-block"> November 16, 2025 </time> <span class="bg-yellow-200 text-yellow-800 text-xs font-medium px-2.5 py-0.5 rounded-full"> Intermediate </span> </div> <h3 id="post-title-how-the-control-unit-makes-the-cpu-work-signals-microcode-and-decoding" class="text-base font-semibold text-gray-900 group-hover:text-gray-600"> How the Control Unit Makes the CPU Work: Signals, Microcode, and Decoding </h3> <p class="text-gray-600 text-sm line-clamp-3"> Understand how the CPU Control Unit fetches, decodes, and executes instructions. Learn the differences between hardwired and microprogrammed control with clear examples. </p> </div> <div class="sm:px-3 mt-auto inline-flex items-center gap-x-1 text-sm text-blue-600 decoration-2 group-hover:underline group-focus:underline font-medium">
Read more
<svg xmlns="http://www.w3.org/2000/svg" fill="currentColor" viewBox="0 0 20 20" class="size-5" data-slot="icon" aria-hidden="true"> <path d="M8.22 5.22a.75.75 0 0 1 1.06 0l4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.75.75 0 0 1-1.06-1.06L11.94 10 8.22 6.28a.75.75 0 0 1 0-1.06Z" clip-rule="evenodd" fill-rule="evenodd"></path> </svg> </div> </a> </article><article class="group flex flex-1 flex-col focus:outline-hidden" role="listitem"> <a href="/posts/finding-p-values-and-false-hope--intro-to-quantitative-finance" class="flex flex-col h-full rounded-xl" aria-labelledby="post-title-finding-p-values-and-false-hope--intro-to-quantitative-finance"> <div class="relative pt-[50%] sm:pt-[70%] rounded-xl overflow-hidden mb-3 shadow"> <img src="/assets/banner-p-values-and-false-hope.BbDvJEO1_Z2q0e9e.webp" alt="Banner for the Introduction" decoding="async" loading="eager" fetchpriority="auto" width="1024" height="1024" class="size-full absolute top-0 start-0 rounded-xl object-cover group-hover:scale-105 group-focus:scale-105 transition-transform duration-500 ease-in-out"> </div> <div class="sm:px-3 mb-2"> <div class="flex items-center gap-2 mb-1"> <time datetime="November 9, 2025" class="text-gray-500 text-xs inline-block"> November 9, 2025 </time> <span class="bg-yellow-200 text-yellow-800 text-xs font-medium px-2.5 py-0.5 rounded-full"> Intermediate </span> </div> <h3 id="post-title-finding-p-values-and-false-hope--intro-to-quantitative-finance" class="text-base font-semibold text-gray-900 group-hover:text-gray-600"> Finding P Values and False Hope — Intro to Quantitative Finance </h3> <p class="text-gray-600 text-sm line-clamp-3"> Discover how mathematics, statistics, and Python come together to explain and predict financial market behavior. In this introduction to quantitative finance, explore core concepts like interest rates, compounding, risk management, and bond pricing through practical, code-driven examples. </p> </div> <div class="sm:px-3 mt-auto inline-flex items-center gap-x-1 text-sm text-blue-600 decoration-2 group-hover:underline group-focus:underline font-medium">
Read more
<svg xmlns="http://www.w3.org/2000/svg" fill="currentColor" viewBox="0 0 20 20" class="size-5" data-slot="icon" aria-hidden="true"> <path d="M8.22 5.22a.75.75 0 0 1 1.06 0l4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.75.75 0 0 1-1.06-1.06L11.94 10 8.22 6.28a.75.75 0 0 1 0-1.06Z" clip-rule="evenodd" fill-rule="evenodd"></path> </svg> </div> </a> </article><article class="group flex flex-1 flex-col focus:outline-hidden" role="listitem"> <a href="/posts/understanding-the-alu-arithmetic-logic-and-control-signals-explained" class="flex flex-col h-full rounded-xl" aria-labelledby="post-title-understanding-the-alu-arithmetic-logic-and-control-signals-explained"> <div class="relative pt-[50%] sm:pt-[70%] rounded-xl overflow-hidden mb-3 shadow"> <img src="/assets/computer-architecture-transistor-to-system-guide.BpaNqm1a_Z178T5a.webp" alt="Cover image for the blog series &#34;From Transistor to System: A Friendly Guide to Computer Architecture,&#34; showing various computer components in a cheerful, cartoon style" decoding="async" loading="lazy" fetchpriority="auto" width="1024" height="1024" class="size-full absolute top-0 start-0 rounded-xl object-cover group-hover:scale-105 group-focus:scale-105 transition-transform duration-500 ease-in-out"> </div> <div class="sm:px-3 mb-2"> <div class="flex items-center gap-2 mb-1"> <time datetime="November 2, 2025" class="text-gray-500 text-xs inline-block"> November 2, 2025 </time> <span class="bg-yellow-200 text-yellow-800 text-xs font-medium px-2.5 py-0.5 rounded-full"> Intermediate </span> </div> <h3 id="post-title-understanding-the-alu-arithmetic-logic-and-control-signals-explained" class="text-base font-semibold text-gray-900 group-hover:text-gray-600"> Understanding the ALU: Arithmetic, Logic, and Control Signals Explained </h3> <p class="text-gray-600 text-sm line-clamp-3"> Discover how the ALU enables a CPU to perform arithmetic and logic operations using adders, subtractors, logic gates, and control signals. </p> </div> <div class="sm:px-3 mt-auto inline-flex items-center gap-x-1 text-sm text-blue-600 decoration-2 group-hover:underline group-focus:underline font-medium">
Read more
<svg xmlns="http://www.w3.org/2000/svg" fill="currentColor" viewBox="0 0 20 20" class="size-5" data-slot="icon" aria-hidden="true"> <path d="M8.22 5.22a.75.75 0 0 1 1.06 0l4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.75.75 0 0 1-1.06-1.06L11.94 10 8.22 6.28a.75.75 0 0 1 0-1.06Z" clip-rule="evenodd" fill-rule="evenodd"></path> </svg> </div> </a> </article><article class="group flex flex-1 flex-col focus:outline-hidden" role="listitem"> <a href="/posts/design-patterns-for-performance-what-actually-works-in-high-performance-systems" class="flex flex-col h-full rounded-xl" aria-labelledby="post-title-design-patterns-for-performance-what-actually-works-in-high-performance-systems"> <div class="relative pt-[50%] sm:pt-[70%] rounded-xl overflow-hidden mb-3 shadow"> <img src="/assets/BannerHighPerformance.psXMTq8-_1zqBuk.webp" alt="Speedometer" decoding="async" loading="lazy" fetchpriority="auto" width="3959" height="2880" class="size-full absolute top-0 start-0 rounded-xl object-cover group-hover:scale-105 group-focus:scale-105 transition-transform duration-500 ease-in-out"> </div> <div class="sm:px-3 mb-2"> <div class="flex items-center gap-2 mb-1"> <time datetime="October 26, 2025" class="text-gray-500 text-xs inline-block"> October 26, 2025 </time> <span class="bg-green-200 text-green-800 text-xs font-medium px-2.5 py-0.5 rounded-full"> Beginner </span> </div> <h3 id="post-title-design-patterns-for-performance-what-actually-works-in-high-performance-systems" class="text-base font-semibold text-gray-900 group-hover:text-gray-600"> Design Patterns for Performance: What Actually Works in High-Performance Systems </h3> <p class="text-gray-600 text-sm line-clamp-3"> Learn how to use proven design patterns to build high-performance and low-latency systems. Explore the Reactor pattern, Actor model, Fan-out/Fan-in, Cache-Aside, Sharding, and resilience patterns like Circuit Breaker, Bulkhead, and Load Shedding. Improve speed, scalability, and maintainability in complex architectures. </p> </div> <div class="sm:px-3 mt-auto inline-flex items-center gap-x-1 text-sm text-blue-600 decoration-2 group-hover:underline group-focus:underline font-medium">
Read more
<svg xmlns="http://www.w3.org/2000/svg" fill="currentColor" viewBox="0 0 20 20" class="size-5" data-slot="icon" aria-hidden="true"> <path d="M8.22 5.22a.75.75 0 0 1 1.06 0l4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.75.75 0 0 1-1.06-1.06L11.94 10 8.22 6.28a.75.75 0 0 1 0-1.06Z" clip-rule="evenodd" fill-rule="evenodd"></path> </svg> </div> </a> </article><article class="group flex flex-1 flex-col focus:outline-hidden" role="listitem"> <a href="/posts/hello-world-in-x86-assembly-step-by-step-guide" class="flex flex-col h-full rounded-xl" aria-labelledby="post-title-hello-world-in-x86-assembly-step-by-step-guide"> <div class="relative pt-[50%] sm:pt-[70%] rounded-xl overflow-hidden mb-3 shadow"> <img src="/assets/whale-behind-a-desk-with-containers.DX4KWUkX_Z1PDsaQ.webp" alt="Whale behind a desk with containers" decoding="async" loading="lazy" fetchpriority="auto" width="1024" height="1024" class="size-full absolute top-0 start-0 rounded-xl object-cover group-hover:scale-105 group-focus:scale-105 transition-transform duration-500 ease-in-out"> </div> <div class="sm:px-3 mb-2"> <div class="flex items-center gap-2 mb-1"> <time datetime="October 19, 2025" class="text-gray-500 text-xs inline-block"> October 19, 2025 </time> <span class="bg-yellow-200 text-yellow-800 text-xs font-medium px-2.5 py-0.5 rounded-full"> Intermediate </span> </div> <h3 id="post-title-hello-world-in-x86-assembly-step-by-step-guide" class="text-base font-semibold text-gray-900 group-hover:text-gray-600"> Hello World in x86 Assembly: Step-by-Step Guide </h3> <p class="text-gray-600 text-sm line-clamp-3"> Learn how to write and run a classic “Hello, World!” program in pure x86 assembly, step by step, using Docker for a clean and portable setup. </p> </div> <div class="sm:px-3 mt-auto inline-flex items-center gap-x-1 text-sm text-blue-600 decoration-2 group-hover:underline group-focus:underline font-medium">
Read more
<svg xmlns="http://www.w3.org/2000/svg" fill="currentColor" viewBox="0 0 20 20" class="size-5" data-slot="icon" aria-hidden="true"> <path d="M8.22 5.22a.75.75 0 0 1 1.06 0l4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.75.75 0 0 1-1.06-1.06L11.94 10 8.22 6.28a.75.75 0 0 1 0-1.06Z" clip-rule="evenodd" fill-rule="evenodd"></path> </svg> </div> </a> </article><article class="group flex flex-1 flex-col focus:outline-hidden" role="listitem"> <a href="/posts/refactoring-a-bad-design-a-step-by-step-example" class="flex flex-col h-full rounded-xl" aria-labelledby="post-title-refactoring-a-bad-design-a-step-by-step-example"> <div class="relative pt-[50%] sm:pt-[70%] rounded-xl overflow-hidden mb-3 shadow"> <img src="/assets/BannerRefactoringBadDesign.CtFcZgfN_ZedRWR.webp" alt="Programmer behinde a computer" decoding="async" loading="lazy" fetchpriority="auto" width="1988" height="1500" class="size-full absolute top-0 start-0 rounded-xl object-cover group-hover:scale-105 group-focus:scale-105 transition-transform duration-500 ease-in-out"> </div> <div class="sm:px-3 mb-2"> <div class="flex items-center gap-2 mb-1"> <time datetime="September 21, 2025" class="text-gray-500 text-xs inline-block"> September 21, 2025 </time> <span class="bg-green-200 text-green-800 text-xs font-medium px-2.5 py-0.5 rounded-full"> Beginner </span> </div> <h3 id="post-title-refactoring-a-bad-design-a-step-by-step-example" class="text-base font-semibold text-gray-900 group-hover:text-gray-600"> Refactoring a Bad Design: A Step-by-Step Example </h3> <p class="text-gray-600 text-sm line-clamp-3"> Learn how to refactor an overgrown Java class using incremental steps, abstractions, and unit testing. </p> </div> <div class="sm:px-3 mt-auto inline-flex items-center gap-x-1 text-sm text-blue-600 decoration-2 group-hover:underline group-focus:underline font-medium">
Read more
<svg xmlns="http://www.w3.org/2000/svg" fill="currentColor" viewBox="0 0 20 20" class="size-5" data-slot="icon" aria-hidden="true"> <path d="M8.22 5.22a.75.75 0 0 1 1.06 0l4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.75.75 0 0 1-1.06-1.06L11.94 10 8.22 6.28a.75.75 0 0 1 0-1.06Z" clip-rule="evenodd" fill-rule="evenodd"></path> </svg> </div> </a> </article> </div>  </div> </section> <section id="pagination"> <div class="mx-auto max-w-6xl px-4 sm:px-6 lg:px-8 py-1 w-full">  <div class="flex items-center justify-between"> <div class="flex flex-1 justify-between sm:hidden"> <a href="/posts" aria-label="Previous" aria-disabled="true" tabindex="-1" class="relative inline-flex items-center rounded-md border bg-silicon-50 hover:bg-silicon-0 border-gray-300 px-4 py-2 text-sm font-medium text-gray-700 opacity-50 pointer-events-none cursor-not-allowed"> 
Previous
 </a> <a href="/posts/2" aria-label="Next" aria-disabled="false" tabindex="0" class="relative inline-flex items-center rounded-md border bg-silicon-50 hover:bg-silicon-0 border-gray-300 px-4 py-2 text-sm font-medium text-gray-700 false"> 
Next
 </a> </div> <div class="hidden sm:flex sm:flex-1 sm:items-center sm:justify-between"> <div> <p class="text-sm text-gray-700">
Showing
<span class="font-medium">1</span>
-
<span class="font-medium">12</span>
of
<span class="font-medium">16</span>
results
</p> </div> <div> <nav aria-label="pagination" class="isolate inline-flex -space-x-px rounded-md shadow-xs"> <a href="/posts" aria-label="Previous" aria-disabled="true" tabindex="-1" class="relative inline-flex items-center rounded-l-md px-2 py-2 text-gray-700 inset-ring inset-ring-silicon-200 hover:bg-silicon-50 focus:z-20 focus:outline-offset-0 opacity-50 pointer-events-none cursor-not-allowed">  <span class="sr-only">Previous</span> <svg xmlns="http://www.w3.org/2000/svg" fill="currentColor" viewBox="0 0 20 20" class="size-5" data-slot="icon" aria-hidden="true"> <path d="M11.78 5.22a.75.75 0 0 1 0 1.06L8.06 10l3.72 3.72a.75.75 0 1 1-1.06 1.06l-4.25-4.25a.75.75 0 0 1 0-1.06l4.25-4.25a.75.75 0 0 1 1.06 0Z" clip-rule="evenodd" fill-rule="evenodd"></path> </svg>  </a> <a href="/posts" aria-label="Page 1" aria-disabled="true" tabindex="-1" class="relative inline-flex items-center px-4 py-2 text-sm font-semibold focus:z-20 z-10 bg-blue-600 text-white focus-visible:outline-2 focus-visible:outline-offset-2 focus-visible:outline-blue-600 opacity-50 pointer-events-none cursor-not-allowed"> 1 </a><a href="/posts/2" aria-label="Page 2" aria-disabled="false" tabindex="0" class="relative inline-flex items-center px-4 py-2 text-sm font-semibold focus:z-20 text-gray-900 inset-ring inset-ring-silicon-200 hover:bg-silicon-50 focus:outline-offset-0 false"> 2 </a> <a href="/posts/2" aria-label="Next" aria-disabled="false" tabindex="0" class="relative inline-flex items-center rounded-r-md px-2 py-2 text-gray-700 inset-ring inset-ring-silicon-200 hover:bg-silicon-50 focus:z-20 focus:outline-offset-0 false">  <span class="sr-only">Next</span> <svg xmlns="http://www.w3.org/2000/svg" fill="currentColor" viewBox="0 0 20 20" class="size-5" data-slot="icon" aria-hidden="true"> <path d="M8.22 5.22a.75.75 0 0 1 1.06 0l4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.75.75 0 0 1-1.06-1.06L11.94 10 8.22 6.28a.75.75 0 0 1 0-1.06Z" clip-rule="evenodd" fill-rule="evenodd"></path> </svg>  </a> </nav> </div> </div> </div>  </div> </section>  </main> <footer id="footer" class="mt-auto text-gray-600" role="contentinfo"> <div class="mx-auto max-w-6xl px-4 sm:px-6 lg:px-8 py-1 w-full">   <div class="flex flex-col sm:flex-row justify-between gap-4 py-6"> <!-- Site description --> <section aria-labelledby="footer-about" class="sm:max-w-2/5"> <h2 id="footer-about" class="font-bold text-gray-700 mb-2">
BIOS Confessions
</h2> <p class="text-sm text-gray-500">
Our mission is to help curious minds grow by learning,
                    experimenting, and sharing knowledge in the world of
                    computer science.
</p> </section> <!-- Navigation --> <nav aria-labelledby="footer-navigation"> <h2 id="footer-navigation" class="font-bold text-gray-700">
Navigation
</h2> <ul class="mt-3 space-y-3 text-sm" role="list"> <li> <a href="/" class="inline-flex gap-x-2 text-gray-500 hover:text-gray-800 focus-visible:outline focus-visible:outline-2 focus-visible:outline-offset-2 focus-visible:outline-gray-400"> Home </a> </li><li> <a href="/posts" class="inline-flex gap-x-2 text-gray-500 hover:text-gray-800 focus-visible:outline focus-visible:outline-2 focus-visible:outline-offset-2 focus-visible:outline-gray-400"> Posts </a> </li><li> <a href="/about" class="inline-flex gap-x-2 text-gray-500 hover:text-gray-800 focus-visible:outline focus-visible:outline-2 focus-visible:outline-offset-2 focus-visible:outline-gray-400"> About </a> </li><li> <a href="/search" class="inline-flex gap-x-2 text-gray-500 hover:text-gray-800 focus-visible:outline focus-visible:outline-2 focus-visible:outline-offset-2 focus-visible:outline-gray-400"> Search </a> </li><li> <a href="/tags" class="inline-flex gap-x-2 text-gray-500 hover:text-gray-800 focus-visible:outline focus-visible:outline-2 focus-visible:outline-offset-2 focus-visible:outline-gray-400"> Tags </a> </li><li> <a href="/collections" class="inline-flex gap-x-2 text-gray-500 hover:text-gray-800 focus-visible:outline focus-visible:outline-2 focus-visible:outline-offset-2 focus-visible:outline-gray-400"> Collections </a> </li> </ul> </nav> <!-- Contact --> <section aria-labelledby="footer-contact"> <h2 id="footer-contact" class="font-bold text-gray-700 mb-2">
Contact
</h2> <a href="mailto:biosconfessions@gmail.com" class="text-sm text-gray-500 hover:text-gray-800 focus-visible:outline focus-visible:outline-2 focus-visible:outline-offset-2 focus-visible:outline-gray-400">
biosconfessions@gmail.com
</a> </section> </div>  <div class="border-t border-silicon-200 py-6"> <div class="flex flex-col sm:flex-row justify-center sm:justify-between items-center gap-4"> <p class="text-xs text-gray-600">
&copy; 2025 BIOS Confessions.
</p> <div class="flex gap-4"> <a href="/privacy-statement" class="text-xs text-gray-500 underline hover:text-gray-800 hover:decoration-2 focus-visible:outline focus-visible:outline-2 focus-visible:outline-offset-2 focus-visible:outline-gray-400">
Privacy Statement
</a> <button type="button" class="text-xs text-gray-500 underline hover:text-gray-800 hover:decoration-2 focus-visible:outline focus-visible:outline-2 focus-visible:outline-offset-2 focus-visible:outline-gray-400" data-cc="show-preferencesModal">
Cookie Settings
</button> </div> </div> </div>  </div> </footer>  <style>astro-island,astro-slot,astro-static-slot{display:contents}</style><script>(()=>{var e=async t=>{await(await t())()};(self.Astro||(self.Astro={})).only=e;window.dispatchEvent(new Event("astro:only"));})();</script><script>(()=>{var A=Object.defineProperty;var g=(i,o,a)=>o in i?A(i,o,{enumerable:!0,configurable:!0,writable:!0,value:a}):i[o]=a;var d=(i,o,a)=>g(i,typeof o!="symbol"?o+"":o,a);{let i={0:t=>m(t),1:t=>a(t),2:t=>new RegExp(t),3:t=>new Date(t),4:t=>new Map(a(t)),5:t=>new Set(a(t)),6:t=>BigInt(t),7:t=>new URL(t),8:t=>new Uint8Array(t),9:t=>new Uint16Array(t),10:t=>new Uint32Array(t),11:t=>1/0*t},o=t=>{let[l,e]=t;return l in i?i[l](e):void 0},a=t=>t.map(o),m=t=>typeof t!="object"||t===null?t:Object.fromEntries(Object.entries(t).map(([l,e])=>[l,o(e)]));class y extends HTMLElement{constructor(){super(...arguments);d(this,"Component");d(this,"hydrator");d(this,"hydrate",async()=>{var b;if(!this.hydrator||!this.isConnected)return;let e=(b=this.parentElement)==null?void 0:b.closest("astro-island[ssr]");if(e){e.addEventListener("astro:hydrate",this.hydrate,{once:!0});return}let c=this.querySelectorAll("astro-slot"),n={},h=this.querySelectorAll("template[data-astro-template]");for(let r of h){let s=r.closest(this.tagName);s!=null&&s.isSameNode(this)&&(n[r.getAttribute("data-astro-template")||"default"]=r.innerHTML,r.remove())}for(let r of c){let s=r.closest(this.tagName);s!=null&&s.isSameNode(this)&&(n[r.getAttribute("name")||"default"]=r.innerHTML)}let p;try{p=this.hasAttribute("props")?m(JSON.parse(this.getAttribute("props"))):{}}catch(r){let s=this.getAttribute("component-url")||"<unknown>",v=this.getAttribute("component-export");throw v&&(s+=` (export ${v})`),console.error(`[hydrate] Error parsing props for component ${s}`,this.getAttribute("props"),r),r}let u;await this.hydrator(this)(this.Component,p,n,{client:this.getAttribute("client")}),this.removeAttribute("ssr"),this.dispatchEvent(new CustomEvent("astro:hydrate"))});d(this,"unmount",()=>{this.isConnected||this.dispatchEvent(new CustomEvent("astro:unmount"))})}disconnectedCallback(){document.removeEventListener("astro:after-swap",this.unmount),document.addEventListener("astro:after-swap",this.unmount,{once:!0})}connectedCallback(){if(!this.hasAttribute("await-children")||document.readyState==="interactive"||document.readyState==="complete")this.childrenConnectedCallback();else{let e=()=>{document.removeEventListener("DOMContentLoaded",e),c.disconnect(),this.childrenConnectedCallback()},c=new MutationObserver(()=>{var n;((n=this.lastChild)==null?void 0:n.nodeType)===Node.COMMENT_NODE&&this.lastChild.nodeValue==="astro:end"&&(this.lastChild.remove(),e())});c.observe(this,{childList:!0}),document.addEventListener("DOMContentLoaded",e)}}async childrenConnectedCallback(){let e=this.getAttribute("before-hydration-url");e&&await import(e),this.start()}async start(){let e=JSON.parse(this.getAttribute("opts")),c=this.getAttribute("client");if(Astro[c]===void 0){window.addEventListener(`astro:${c}`,()=>this.start(),{once:!0});return}try{await Astro[c](async()=>{let n=this.getAttribute("renderer-url"),[h,{default:p}]=await Promise.all([import(this.getAttribute("component-url")),n?import(n):()=>()=>{}]),u=this.getAttribute("component-export")||"default";if(!u.includes("."))this.Component=h[u];else{this.Component=h;for(let f of u.split("."))this.Component=this.Component[f]}return this.hydrator=p,this.hydrate},e,this)}catch(n){console.error(`[astro-island] Error hydrating ${this.getAttribute("component-url")}`,n)}}attributeChangedCallback(){this.hydrate()}}d(y,"observedAttributes",["props"]),customElements.get("astro-island")||customElements.define("astro-island",y)}})();</script><astro-island uid="2r0e7E" component-url="/assets/SearchModal.CYCcBlwq.js" component-export="default" renderer-url="/assets/client.BfPWZUkF.js" props="{&quot;posts&quot;:[1,[[0,{&quot;id&quot;:[0,&quot;finding-p-values-and-false-hope/0-introduction.mdx&quot;],&quot;data&quot;:[0,{&quot;author&quot;:[0,&quot;Quinn&quot;],&quot;collection&quot;:[0,&quot;Finding P values and false hope&quot;],&quot;chapter&quot;:[0,0],&quot;title&quot;:[0,&quot;Finding P Values and False Hope — Intro to Quantitative Finance&quot;],&quot;shortname&quot;:[0,&quot;Intro&quot;],&quot;date&quot;:[3,&quot;2025-11-09T00:00:00.000Z&quot;],&quot;tags&quot;:[1,[[0,&quot;Featured&quot;],[0,&quot;Data Science&quot;]]],&quot;metaTags&quot;:[1,[[0,&quot;Quantitative Finance&quot;],[0,&quot;Python&quot;],[0,&quot;Statistics&quot;],[0,&quot;Financial Modeling&quot;],[0,&quot;quantitative finance tutorial&quot;],[0,&quot;Python for finance&quot;],[0,&quot;financial mathematics&quot;],[0,&quot;risk management&quot;],[0,&quot;data science in finance&quot;],[0,&quot;option pricing models&quot;],[0,&quot;bond valuation&quot;],[0,&quot;p values in finance&quot;],[0,&quot;statistics and programming&quot;]]],&quot;difficulty&quot;:[0,&quot;Intermediate&quot;],&quot;readTime&quot;:[0,&quot;2 min&quot;],&quot;image&quot;:[0,{&quot;src&quot;:[0,&quot;/assets/banner-p-values-and-false-hope.BbDvJEO1.png&quot;],&quot;width&quot;:[0,1024],&quot;height&quot;:[0,1024],&quot;format&quot;:[0,&quot;png&quot;]}],&quot;alt&quot;:[0,&quot;Banner for the Introduction&quot;],&quot;description&quot;:[0,&quot;Discover how mathematics, statistics, and Python come together to explain and predict financial market behavior. In this introduction to quantitative finance, explore core concepts like interest rates, compounding, risk management, and bond pricing through practical, code-driven examples.&quot;]}],&quot;body&quot;:[0,&quot;Welcome to this series, where we’ll explore how mathematics, statistics, and programming come together to understand —and sometimes predict —the movements of financial markets. Whether you&#39;re a curious learner or data enthusiast, this series will explore some essential quantitative finance concepts with practical Python examples.\r\n\r\nWe start this series by understanding some fundamentals of financial mathematics, including interest rates, compounding, and present value. We will discuss risk management—how to measure and mitigate financial uncertainty —and show how to implement some risk management tools.\r\n\r\nIn this series, we will also learn about bond pricing, understand dynamic stock price fluctuations, explore different models for option pricing, and much more.\r\n\r\nEach post in the series will combine clear financial intuition with Python-based implementations, helping you move from theory to practical application. By the end, you’ll have a solid foundation in both the quantitative concepts that drive modern finance and the computational tools used to bring them to life.&quot;],&quot;filePath&quot;:[0,&quot;src/content/posts/finding-p-values-and-false-hope/0-introduction.mdx&quot;],&quot;assetImports&quot;:[1,[[0,&quot;./assets/banner-p-values-and-false-hope.png&quot;]]],&quot;digest&quot;:[0,&quot;bc4f89d612f57a84&quot;],&quot;deferredRender&quot;:[0,true],&quot;collection&quot;:[0,&quot;posts&quot;],&quot;slug&quot;:[0,&quot;finding-p-values-and-false-hope/0-introduction&quot;],&quot;render&quot;:[0,null]}],[0,{&quot;id&quot;:[0,&quot;finding-p-values-and-false-hope/1-losing.mdx&quot;],&quot;data&quot;:[0,{&quot;author&quot;:[0,&quot;Quinn&quot;],&quot;collection&quot;:[0,&quot;Finding P values and false hope&quot;],&quot;chapter&quot;:[0,1],&quot;title&quot;:[0,&quot;The Art of Losing Slowly: How to Manage Risk, Variance and Decisions Under Uncertainty&quot;],&quot;shortname&quot;:[0,&quot;Losing&quot;],&quot;date&quot;:[3,&quot;2025-11-23T00:00:00.000Z&quot;],&quot;tags&quot;:[1,[[0,&quot;Data Science&quot;]]],&quot;metaTags&quot;:[1,[[0,&quot;risk management&quot;],[0,&quot;decision making under uncertainty&quot;],[0,&quot;expected value&quot;],[0,&quot;variance in finance&quot;],[0,&quot;diversification&quot;],[0,&quot;risk averse decision making&quot;],[0,&quot;financial uncertainty&quot;],[0,&quot;data science decision-making&quot;],[0,&quot;probability and outcomes&quot;]]],&quot;difficulty&quot;:[0,&quot;Intermediate&quot;],&quot;readTime&quot;:[0,&quot;5 min&quot;],&quot;image&quot;:[0,{&quot;src&quot;:[0,&quot;/assets/banner-art-of-losing-slowely.DBSc2GqA.png&quot;],&quot;width&quot;:[0,1584],&quot;height&quot;:[0,672],&quot;format&quot;:[0,&quot;png&quot;]}],&quot;alt&quot;:[0,&quot;Banner for The Art of Losing Slowly&quot;],&quot;description&quot;:[0,&quot;Learn how to manage risk, leverage variance, and make better decisions under uncertainty. A practical guide to thoughtful losses, expected value, and long-term thinking.&quot;]}],&quot;body&quot;:[0,&quot;In a world obsessed with winning, few stop to consider the quiet art of losing. Not making reckless decisions, but instead being deliberate, patient, and purposeful. Managing risk and making decisions under uncertainty isn’t about avoiding loss; it’s about controlling its space, size, and impact. Success often belongs not to those who never fall, but to those who learn to fall well, who can endure small, calculated setbacks while keeping the bigger picture intact.\r\n\r\nLearning to “*lose slowly*” means embracing uncertainty without panic, balancing conviction with adaptability, and knowing when to press forward and when to hold back. It&#39;s playing the long game when the short term feels chaotic. By learning to lose slowly, we will be able to separate sustainable progress from mere luck.\r\n\r\n# Understanding Risk\r\n\r\nRisk is woven into almost every decision we make. We take it when we cross the street, start a new job, or trust someone’s word. Most of the time, we manage it intuitively, weighing outcomes, reading context, and adjusting as we go. Every day life trains us to navigate uncertainty, but it can create a dangerous illusion of being too comfortable with risk and of underestimating it.\r\n\r\nIn financial decisions, those illusions often break down. Even highly educated people who hold strong opinions about financial markets and financial risk struggle with it. The 2008-2009 financial crisis is a clear example of how financial risk was underestimated. It&#39;s important for us to have a deep enough understanding to manage the risk we can live with.\r\n\r\nLet&#39;s explore an example of risk evaluation in a financial decision involving gambling. Imagine this: you pay **€1** to draw a single card from a standard deck. If you pull the **ace of spades**, you win **€50**; otherwise, you get nothing. Would you take the bet?\r\n\r\nMost people would since it feels like a small risk for a high reward. But let&#39;s change the game. Would you play the banker? So now you get **€1** if no **ace of spades** is drawn, but you lose **€49** if an ace is drawn.\r\n\r\nWe can make this game more fun by upping the stake by ***x100***. Most of us would probably hesitate to lose **€4900** just to gain **€100**. This just feels like a bad deal, even though the odds are the same as with the lower amounts. We can calculate the expected value of this bet as:\r\n\r\n$$\r\nE(\\text{Bet}) = \\frac{1}{52}(-€4900) + \\frac{51}{52}(€100) = \\frac{100}{26} \\text{ or about €4}\r\n$$\r\n\r\nSo the bet still has a positive outcome, but what if we split it into 50 even smaller bets? With each round, we risk losing **€98** and have a chance to gain **€2**. Our maximum possible loss is still **€4900,** and the maximum possible gain is still **€100**. Did you notice what happened when we changed the game like this? The probability of us losing everything just changed to almost zero (about **10^-86**), while the probability of obtaining the maximum gain is (**51/52)^50 = 37.87%**.  \r\n\r\nWhat changed? Not the expected outcome—what stayed the same—but the variance did change. Variance captures how spread out the possible outcomes are, and it turns out to be a powerful way to distinguish a good from a bad bet.\r\n\r\nThe essence of variance is dividing a single large, risky bet into many smaller, uncorrelated ones. In finance, diversification transforms uncertainty into something manageable. It’s why investors might prefer to hold a **1%** stake in **100** **mortgages** than a **100% stake in one.** The total exposure is the same, but the risk behaviour is completely different. This is a great example of managing risk by leveraging variance. \r\n\r\n# Making decisions under uncertainty\r\n\r\nEvery meaningful decision we make lives in the space between what we know and what we can only guess. Whether we’re allocating capital or choosing when to exit a trade, uncertainty is the constant backdrop. Yet decisions must still be made. Good decision-making under uncertainty is not only about the probability of an event, but also about the consequences if it occurs. A rare event with a large impact can matter far more than a frequent one with small effects. However, in practice, this can be very difficult, since there are an infinite number of possible outcomes for certain events. For simplicity, let&#39;s imagine we have an event with a finite number of possibilities. Imagine we have a company that runs online ads. We need to decide whether to place the ad online. Based on historical data, we know the probability and outcome of each decision we can make:   \r\n\r\n| **Decsion** | **Probablity** | **Outcome** |\r\n| --- | --- | --- |\r\n| *Place the ads* | 20% | Customer buys → **€5 profit** |\r\n|  | 30% | Customer does not buy → **€1 loss** |\r\n| *Do not place the ads* | 50% | Customer shows interest but doesn’t buy → **€0 profit** |\r\n\r\nThere are several ways to evaluate the risk and the actions we should take. Let&#39;s discuss two simple methods to understand the principle of decision-making. The first one is the expected value decision. With this decision, we will calculate the expected value of each outcome with this formula:\r\n\r\n$$\r\n\\text{EV(decision)} = \\sum (\\text{Probability of outcome} \\times \\text{Value of outcome})\r\n$$\r\n\r\nWe can easily automate this decision-making process with Python. By defining the possible outcomes and their probabilities for each decision, the script will compute the expected value and compare your options programmatically.\r\n\r\n```python\r\ndef expected_value(outcomes):\r\n    \&quot;\&quot;\&quot;\r\n    outcomes: list of (probability, payoff) pairs.\r\n    \&quot;\&quot;\&quot;\r\n    return sum(p * v for p, v in outcomes)\r\n\r\ndef evaluate_decisions(decisions):\r\n    \&quot;\&quot;\&quot;\r\n    decisions: dict where key = decision name,\r\n               value = list of (probability, payoff) pairs.\r\n    \&quot;\&quot;\&quot;\r\n    results = {}\r\n    for name, outcomes in decisions.items():\r\n        results[name] = expected_value(outcomes)\r\n    return results\r\n\r\nif __name__ == \&quot;__main__\&quot;:\r\n    # All the options and their possible outcomes\r\n    decisions = {\r\n        \&quot;Place the ad\&quot;: [(0.2, 5), (0.3, -1)],\r\n        \&quot;Do not place the ad\&quot;: [(1, 0)],\r\n    }\r\n\r\n    ev_results = evaluate_decisions(decisions)\r\n    # Identify the best decision\r\n    best_decision = max(ev_results, key=ev_results.get)\r\n    print(f\&quot;Best decision under the Expected Value criterion: {best_decision}\&quot;)\r\n```\r\n\r\n**The script will give us this output:**\r\n\r\n```\r\nBest decision under the Expected Value criterion: Place the ad\r\n```\r\n\r\nSo we should place the ads based on the expected value decision. In general, we should make decisions based on expected value if the decision is made often enough for the law of large numbers to apply. The decision in our example is for every person who interacts with the ad. So in the end, we should make the most money by placing the ad.\r\n\r\nNot all decision makers will find this approach appropriate for this situation. A risk-averse decision maker will be more interested in minimising their loss. They will use the worst-case decision-making method. The decision based on the worst-case scenario should be made when it is a one-time occurrence and the worst-case scenario has a catastrophic effect. In this case, we should always cover the worst case. The worst-case scenario calculation does not account for the probability of an event. We simply look at what it would the worst possible outcome is.\r\n\r\nImagine we are going on holiday and you get the option to buy travel insurance. The total trip costs you **€5000**, and you can buy additional travel insurance for **€200**. So what could happen?\r\n\r\n| **Decision** | **Outcome** |\r\n| --- | --- |\r\n| *Buy Insurance* | Trip is fine → €200 loss |\r\n|  | Trip is canceled → €200 loss |\r\n| *Do NOT buy Insurance* | Trip is fine → €0 loss |\r\n|  | Trip is canceled → €5000 loss |\r\n\r\nThe worst thing that can happen is us losing **€5000** if we don&#39;t buy the insurance and the trip gets cancelled. Therefore, a risk-averse decision maker will choose to buy the insurance when going on the trip.\r\n\r\n# Closing thoughts\r\n\r\nLearning to **lose slowly** is not about avoiding failure; it’s about respecting uncertainty. It’s recognising that progress is rarely a straight line and that the cost of staying in the game is sometimes accepting small, intentional losses along the way.\r\n\r\nWe don’t control outcomes, but we *do* control our exposure: how much we risk, how often, and in what context. By diversifying, by sizing our decisions to our tolerance, and by keeping a long-term perspective even when the short term feels chaotic, we can build a path where setbacks are manageable rather than catastrophic.\r\n\r\nIn the end, winning isn’t about making the right decision every time. It’s about creating a system in which even the wrong decisions don’t break you.&quot;],&quot;filePath&quot;:[0,&quot;src/content/posts/finding-p-values-and-false-hope/1-losing.mdx&quot;],&quot;assetImports&quot;:[1,[[0,&quot;./assets/banner-art-of-losing-slowely.png&quot;]]],&quot;digest&quot;:[0,&quot;6735d352e6b0e670&quot;],&quot;deferredRender&quot;:[0,true],&quot;collection&quot;:[0,&quot;posts&quot;],&quot;slug&quot;:[0,&quot;finding-p-values-and-false-hope/1-losing&quot;],&quot;render&quot;:[0,null]}],[0,{&quot;id&quot;:[0,&quot;from-transistor-to-system-a-friendly-guide-to-computer-architecture/0-introduction.mdx&quot;],&quot;data&quot;:[0,{&quot;author&quot;:[0,&quot;Gianni&quot;],&quot;collection&quot;:[0,&quot;From Transistor to System: A Friendly Guide to Computer Architecture&quot;],&quot;chapter&quot;:[0,0],&quot;title&quot;:[0,&quot;Introduction: Computer Architecture&quot;],&quot;shortname&quot;:[0,&quot;Intro&quot;],&quot;date&quot;:[3,&quot;2025-09-03T00:00:00.000Z&quot;],&quot;tags&quot;:[1,[[0,&quot;Featured&quot;],[0,&quot;Computer Architecture&quot;],[0,&quot;Introduction&quot;]]],&quot;metaTags&quot;:[1,[[0,&quot;Computer architecture explained&quot;],[0,&quot;How computers work&quot;],[0,&quot;Understanding computer systems&quot;],[0,&quot;Digital logic&quot;]]],&quot;difficulty&quot;:[0,&quot;Intermediate&quot;],&quot;readTime&quot;:[0,&quot;1 min&quot;],&quot;image&quot;:[0,{&quot;src&quot;:[0,&quot;/assets/computer-architecture-transistor-to-system-guide.BpaNqm1a.png&quot;],&quot;width&quot;:[0,1024],&quot;height&quot;:[0,1024],&quot;format&quot;:[0,&quot;png&quot;]}],&quot;alt&quot;:[0,&quot;Cover image for the blog series \&quot;From Transistor to System: A Friendly Guide to Computer Architecture,\&quot; showing various computer components in a cheerful, cartoon style&quot;],&quot;description&quot;:[0,&quot;Introduction for From Transistor to System: A Friendly Guide to Computer Architecture&quot;]}],&quot;body&quot;:[0,&quot;Every click, tap, and swipe hides a story. Beneath the apps, screens, and machines you use every day lies a hidden world of circuits, instructions, and clever engineering. This series takes you on a bottom-up journey from bits and bytes, through memory, storage, and CPUs, to the input and output devices that bridge the digital and physical worlds. By the end, computers won&#39;t feel like mysterious black boxes, but like beautifully crafted, logical machines.&quot;],&quot;filePath&quot;:[0,&quot;src/content/posts/from-transistor-to-system-a-friendly-guide-to-computer-architecture/0-introduction.mdx&quot;],&quot;assetImports&quot;:[1,[[0,&quot;./assets/computer-architecture-transistor-to-system-guide.png&quot;]]],&quot;digest&quot;:[0,&quot;fd786af5555b918e&quot;],&quot;deferredRender&quot;:[0,true],&quot;collection&quot;:[0,&quot;posts&quot;],&quot;slug&quot;:[0,&quot;from-transistor-to-system-a-friendly-guide-to-computer-architecture/0-introduction&quot;],&quot;render&quot;:[0,null]}],[0,{&quot;id&quot;:[0,&quot;from-transistor-to-system-a-friendly-guide-to-computer-architecture/1-transistor.mdx&quot;],&quot;data&quot;:[0,{&quot;author&quot;:[0,&quot;Gianni&quot;],&quot;collection&quot;:[0,&quot;From Transistor to System: A Friendly Guide to Computer Architecture&quot;],&quot;chapter&quot;:[0,1],&quot;title&quot;:[0,&quot;Transistors: The Tiny Switch That Powers Modern Computers&quot;],&quot;shortname&quot;:[0,&quot;Transistor&quot;],&quot;date&quot;:[3,&quot;2025-09-07T00:00:00.000Z&quot;],&quot;tags&quot;:[1,[[0,&quot;Computer Architecture&quot;],[0,&quot;Electrical Engineering&quot;]]],&quot;metaTags&quot;:[1,[[0,&quot;Transistor basics&quot;],[0,&quot;Semiconductors&quot;],[0,&quot;Digital electronics&quot;],[0,&quot;Transistors&quot;],[0,&quot;MOSFET&quot;],[0,&quot;Silicon doping&quot;],[0,&quot;N-type doping&quot;],[0,&quot;P-type doping&quot;],[0,&quot;How transistors work&quot;],[0,&quot;What is a transistor&quot;]]],&quot;difficulty&quot;:[0,&quot;Intermediate&quot;],&quot;readTime&quot;:[0,&quot;5 min&quot;],&quot;image&quot;:[0,{&quot;src&quot;:[0,&quot;/assets/computer-architecture-transistor-to-system-guide.BpaNqm1a.png&quot;],&quot;width&quot;:[0,1024],&quot;height&quot;:[0,1024],&quot;format&quot;:[0,&quot;png&quot;]}],&quot;alt&quot;:[0,&quot;Cover image for the blog series \&quot;From Transistor to System: A Friendly Guide to Computer Architecture,\&quot; showing various computer components in a cheerful, cartoon style&quot;],&quot;description&quot;:[0,&quot;A beginner-friendly introduction to how transistors work, from electricity fundamentals to semiconductor doping, MOSFET operation, and the invention that shaped modern computers.&quot;]}],&quot;body&quot;:[0,&quot;In this chapter, we will uncover the details of the tiny switch at the heart of modern computing: the transistor. We start with an introduction to electricity, then dive into the details of the transistor. We finish with a brief history lesson.\n\n## Electricity Basics\n\nBefore we begin with transistors, here is a quick introduction to electricity concepts: voltage, current, and binary states. Feel free to skip this section if you are already familiar with them. In electricity, voltage is the pressure from a power source that pushes electric charges through the circuit. You can see it as a water hose; the higher the pressure, the harder the water wants to flow. Current is the flow or movement of electric charge. More current means more charges are moving through the wire per second, like the flow of water through a hose. Binary states are fairly simple. There are two states:\n\n- Off, no current or below a threshold.\n- On, current is flowing or above a threshold.\n\n## What Exactly Is a Transistor?\n\nLet&#39;s begin with a question, the answer to which is simple, but the specifics can become quite complicated: *What is a transistor?* At its core, a **transistor** is an electronic switch that regulates the flow of electrical current. When the switch is **on**, it represents a `1`. When it&#39;s **off**, it represents a `0`. This simple on/off behaviour is the foundation on which digital computing is built. Everything inside your computer, like images, sounds, and programs, can be reduced to tiny switches flipping between `0` and `1`.  They are essentially little bits of electric current. You may be asking whether this is the origin of the word “bits” in the context of digital computing. No, don&#39;t get confused; the abbreviation “bits” stands for “binary digits.”\n\n## Semiconductors\n\nUnlike the light switch on your wall, a **transistor** is microscopic, has no moving parts, and requires no human hand to operate. This is made possible by the physics of **semiconductors**. A semiconductor is a material whose electrical conductivity lies between that of an insulator and a conductor. To put it more simply, it conducts electricity better than something like plastic, but not as well as metals like copper. Silicon is one of these semiconducting materials, and the most important in modern electronics. Fun fact: about 28% of Earth&#39;s crust is silicon, so we&#39;re not running out anytime soon. Silicon atoms have four outer ([valence](https://en.wikipedia.org/wiki/Valence_electron)) electrons, allowing each atom to bond with four neighbours in a rigid, tetrahedral crystal structure. In pure silicon, nearly all electrons are locked in these bonds, so only a small fraction gains enough energy to move freely through the lattice. This limited number of mobile charges is what makes silicon a semiconductor. On its own, pure silicon isn&#39;t useful for building a transistor. Luckily for us, there is a process called **doping**. In doping, a small amount of impurity atoms (atoms of a different element) is injected, changing the electrical behaviour. There are two types of doping, N and P-type: \n\n- **N-type doping**: Atoms with three valence electrons (e.g. [boron](https://en.wikipedia.org/wiki/Boron)) are added. This creates “holes”, electron vacancies that behave like positive charge carriers.\n- **P-type doping**: Atoms with five valence electrons (e.g. [phosphorus](https://en.wikipedia.org/wiki/Phosphorus)) are added. The extra electron becomes free to move, creating an excess of negative charge carriers.\n\nTogether, N-type and P-type semiconductors form the foundation of transistors, and by combining them, we can create devices like the **MOSFET**, the tiny transistor at the heart of modern computing.\n\n![Examples of no, P-type, and N-type doping of silicon](assets/no-vs-p-vs-n-type-semiconductor-doping.jpg)\n\n## Meet the MOSFET&#39;s three players\n\nA common type of transistor used in digital circuits is the **MOSFET** (Metal-Oxide-Semiconductor Field-Effect Transistor). It has three electrical contacts:\n\n- Source (where current enters)\n- Drain (where the current exits)\n- Gate (which controls the flow)\n\nThe gate is separated from the semiconductor by a thin oxide layer, allowing it to control current without direct contact. At rest, electrons from the N-type regions naturally diffuse into the P-type region, filling holes and creating a **depletion region**. In this region, mobile charges are absent, forming a barrier that blocks current flow. This is the **off state** of the transistor. When a small positive voltage is applied to the gate, it attracts electrons toward the channel. This reduces the depletion region, allowing current to pass freely from source to drain. This is the **on state**, where the transistor acts as a closed switch. You can think of the gate like a **drawbridge**: when it&#39;s up, nothing can cross (off state). When it&#39;s lowered with a voltage, it creates a path across the channel, letting current flow (on state). However, the MOSFET wasn&#39;t always there.\n\n&gt; If you like a more visual explanation, I highly recommend watching [this](https://youtu.be/IcrBqCFLHIY?si=-onKV_bj28ybzD6Z) YouTube video by [Veritasium](https://www.youtube.com/@veritasium)\n\n![Example of a MOSFET circuit](assets/mosfet-transistor-layout.jpg)\n\n## In The Beginning\n\nIt is hard to imagine, but before transistors were a thing, early computers relied on **vacuum tubes**. Glass tubes which looked a lot like light bulbs. As the name suggests, it uses vacuums to control the flow of electrical current. The vacuum inside the tube removes all materials, even air, that could conduct electricity. The story begins on **16 November 1904,** when British electrical engineer and physicist Sir John Ambrose Fleming patented the first vacuum tube. By **1939**, they were being demonstrated for computation, and in **1946**, the famous [**ENIAC**](https://en.wikipedia.org/wiki/ENIAC) computer was built with more than **17,000 tubes**. It was ground-breaking, but also fragile. Vacuum tubes often burned out, and when one failed, it could take 15 minutes to locate and two days to replace. Not ideal if you ask me. On the upside, it made electronic computing possible for the first time in history. The next leap came in **1947**, when **John Bardeen, Walter Brattain, and William Shockley** at AT&amp;T&#39;s Bell Labs invented the first working **transistor**. Smaller, faster, and more reliable than vacuum tubes. Then, between **1955 and 1960**, Bell Labs revolutionised and invented the **MOSFET**. This design became the backbone of microchips, and it still powers every smartphone, laptop, and server in use today.&quot;],&quot;filePath&quot;:[0,&quot;src/content/posts/from-transistor-to-system-a-friendly-guide-to-computer-architecture/1-transistor.mdx&quot;],&quot;assetImports&quot;:[1,[[0,&quot;./assets/computer-architecture-transistor-to-system-guide.png&quot;]]],&quot;digest&quot;:[0,&quot;db398b9b49ffb2b3&quot;],&quot;deferredRender&quot;:[0,true],&quot;collection&quot;:[0,&quot;posts&quot;],&quot;slug&quot;:[0,&quot;from-transistor-to-system-a-friendly-guide-to-computer-architecture/1-transistor&quot;],&quot;render&quot;:[0,null]}],[0,{&quot;id&quot;:[0,&quot;from-transistor-to-system-a-friendly-guide-to-computer-architecture/2-logic.mdx&quot;],&quot;data&quot;:[0,{&quot;author&quot;:[0,&quot;Gianni&quot;],&quot;collection&quot;:[0,&quot;From Transistor to System: A Friendly Guide to Computer Architecture&quot;],&quot;chapter&quot;:[0,2],&quot;title&quot;:[0,&quot;Understanding Logic Gates: AND, OR, XOR, NAND, Adders, and Flip-Flops&quot;],&quot;shortname&quot;:[0,&quot;Logic&quot;],&quot;date&quot;:[3,&quot;2025-09-14T00:00:00.000Z&quot;],&quot;tags&quot;:[1,[[0,&quot;Computer Architecture&quot;],[0,&quot;Electrical Engineering&quot;],[0,&quot;Logic&quot;]]],&quot;metaTags&quot;:[1,[[0,&quot;Logic gates&quot;],[0,&quot;Combinational logic&quot;],[0,&quot;Sequential logic&quot;],[0,&quot;Half-adder&quot;],[0,&quot;Full-adder&quot;],[0,&quot;8-bit adder circuit&quot;],[0,&quot;XOR gate&quot;],[0,&quot;AND gate&quot;],[0,&quot;OR gate&quot;],[0,&quot;NOT gate&quot;],[0,&quot;Flip-flop&quot;],[0,&quot;Digital circuits&quot;],[0,&quot;Electronics tutorial&quot;],[0,&quot;Binary addition&quot;],[0,&quot;Digital logic design&quot;]]],&quot;difficulty&quot;:[0,&quot;Intermediate&quot;],&quot;readTime&quot;:[0,&quot;10 min&quot;],&quot;image&quot;:[0,{&quot;src&quot;:[0,&quot;/assets/computer-architecture-transistor-to-system-guide.BpaNqm1a.png&quot;],&quot;width&quot;:[0,1024],&quot;height&quot;:[0,1024],&quot;format&quot;:[0,&quot;png&quot;]}],&quot;alt&quot;:[0,&quot;Cover image for the blog series \&quot;From Transistor to System: A Friendly Guide to Computer Architecture,\&quot; showing various computer components in a cheerful, cartoon style&quot;],&quot;description&quot;:[0,&quot;Learn digital logic circuits: AND, OR, NOT, XOR gates, combinational circuits, half-adder, full-adder, 8-bit adder, and sequential logic with flip-flops.&quot;]}],&quot;body&quot;:[0,&quot;In this chapter, we&#39;ll see how simple switches can be combined into **logic gates**, the fundamental building blocks of digital circuits. Step by step, we&#39;ll explore the basic gates: **NOT, AND, OR**, and a few useful variations. Then we move on to how they can be wired together into larger circuits, known as **combinational logic**. Along the way, we&#39;ll build our first arithmetic circuits: starting with the **Half-Adder**, then extending it into a **Full-Adder**, and finally chaining them together to create an **8-bit adder**, capable of adding entire binary numbers. Finally, we&#39;ll wrap up with an introduction to **sequential logic**, where circuits gain memory and can remember past states.\n\n## From switches to logic gates\n\nAs we saw in the previous chapter, a transistor at its core acts like an electronic switch: it either allows current to flow (on) or prevents it from flowing (off). In the simple circuit shown below, an AA battery provides the power, the LED indicates the on/off states, a transistor controls the electric flow, and the resistors limit the current to protect the transistor and LED from damaging or even exploding (which can happen to the best of us). \n\n![Simple battery-powered circuit with a transistor and an LED in serial](assets/how-a-simple-switch-works-logic-circuit-animation.gif)\n\nBy looking at the circuit, you will notice that it is just an LED that turns on and off depending on the transistor&#39;s state. It may not look impressive, but here is the idea: by cleverly wiring transistors,  we can make them do more than switch a light on/off. We can make them process information. This is where **logic gates** come in. The very first one we&#39;ll explore is the **NOT gate**, followed by the **AND** and **OR** **gates**.\n\n### NOT Gate\n\nYou may wonder: What happens if we change how the LED is connected? Instead of wiring it directly to the transistor&#39;s output path, we place it on the transistor&#39;s collector side (the path to ground). Now something interesting happens: the circuit **flips the signal**. The output becomes the opposite of the input. This is called an **inverter**, or more commonly, a **NOT gate**.\n\n![Simple battery-powered circuit with a transistor and an LED in parallel](assets/how-an-not-gate-works-logic-circuit-animation.gif)\n\nWhen the transistor is **on**, current flows from the battery&#39;s positive side through the resistor and straight to its negative (ground) via the transistor. In this state, the transistor acts almost like a short circuit, providing a low-resistance path for the current to follow. A transistor isn&#39;t a perfect wire, and even when fully on, there is still a tiny “resistance” inside it. This tiny resistance causes a small [voltage drop](https://en.wikipedia.org/wiki/Voltage_drop) across the transistor. Most of the battery&#39;s voltage now falls across the first resistor and the transistor. Very little voltage is left for the LED, so it stays off. In digital circuits, this small leftover voltage is still seen as a logical **0 (low)**. When the transistor switches **off**, the path to ground vanishes. Current can now flow through the LED instead. The LED lights up, which we read as a logical **1 (high)**.\n\nIn logic and computer science, outputs for every possible input are often shown in a **truth table**. A truth table lists all input values (true or false) and the corresponding outputs. Below is the truth table for a NOT gate. In math, the output is often labelled as **Y**.\n\n| **Input (A)** | **Output (Y)** |\n| --- | --- |\n| 0 | 1 |\n| 1 | 0 |\n\n### AND Gate\n\nOf course, we are not limited to using just one transistor. By combining multiple, we can build circuits that only give an output under specific conditions. One of them is the **AND gate**. In the example below, we connect two transistors in series (one after the other) to create an AND gate. \nCurrent from the source must pass through both transistors before it can reach the output. In other words, the output will be high if and only if both inputs (A and B) are high. If either transistor is off, the path is broken, and no current reaches the output.\n\n![Animation of how an AND gate works](assets/how-an-and-gate-works-logic-circuit-animation.gif)\n\nHere follows the truth table for the AND gate:\n\n| **A** | **B** | **Y** |\n| --- | --- | --- |\n| 0 | 0 | 0 |\n| 1 | 0 | 0 |\n| 0 | 1 | 0 |\n| 1 | 1 | 1 |\n\n### OR Gate\n\nNow let&#39;s try wiring the transistors in **parallel** instead of in series. This gives us the **OR gate**. In this case, the current only needs one path or the other to reach the output to make it high, hence the name OR. \n\n![Animation of how an OR gate works](assets/how-an-or-gate-works-logic-circuit-animation.gif)\n\nHere is the truth table for the OR gate:\n\n| **A** | **B** | **Y** |\n| --- | --- | --- |\n| 0 | 0 | 0 |\n| 1 | 0 | 1 |\n| 0 | 1 | 1 |\n| 1 | 1 | 1 |\n\n### XOR Gate\n\nThere is one more gate that deserves special attention, and because we will need it later: the **XOR gate,** short for **exclusive OR**. This gate is like the regular OR gate, but with a twist. As we know from the previous section, with an OR, the output is high if one or both inputs are high. With the XOR, the output is only high if exactly one input is high. This behaviour makes XOR extremely useful, because it can act as a simple difference detector: output is 1 if the inputs are different, and 0 if they&#39;re the same. You&#39;ll see XOR pop up again in circuits that perform arithmetic, like adders.\n\nHere&#39;s the truth table for XOR:\n\n| **A** | **B** | **Y** |\n| --- | --- | --- |\n| 0 | 0 | 0 |\n| 1 | 0 | 1 |\n| 0 | 1 | 1 |\n| 1 | 1 | 0 |\n\n### NAND and NOR Gate\n\nBy combining the previous gates, we can create even more variations. For example, if we take the output of an AND gate and run it through a NOT gate, we get a **NAND gate** (short for NOT AND). Likewise, combining an OR with a NOT gives a **NOR gate** (NOT OR). NAND and NOR are called **universal gates** because you can combine them to perform any Boolean function and thus create any other type of logic gate (AND, OR, NOT, XOR, XNOR). \n\n## Combinational Logic\n\nSo far, we&#39;ve looked at the basic gates: NOT, AND, OR, and a few variations like XOR, NAND, and NOR. Each one flips, combines, or filters signals simply. The real magic begins when we **connect them**. By combining gates, we can create circuits that solve more interesting problems. These are called **combinational logic circuits**. The key feature of combinational logic is that the **output depends only on the current inputs**. These circuits are stateless. They don&#39;t remember what happened before, meaning that if you give the same inputs, you&#39;ll always get the same outputs. With enough combinational logic, we can create circuits that add, subtract, increment, and do much more. In fact, arithmetic operations in a computer all come down to cleverly arranging these simple logic gates.\n\nTo see combinational logic in action, let&#39;s build something practical: a circuit that can add two numbers together, the **Half-Adder**, a simple circuit that can add two binary bits together. Before we dive in, here&#39;s a quick overview of the most common gate symbols:\n\n![Overview of the most common gate symbols](assets/all-logic-gate-symbols.jpg)\n\nOkay, let&#39;s start small. Suppose we add two **1-bit numbers**, A and B. The result of this addition has two parts: the **sum** and the **carry**. The sum is the result of the addition, and the carry is like the overflowing bit, indicating that the result is greater than we can hold in the sum. For example:\n\n| A | B | Sum | Carry |\n| --- | --- | --- | --- |\n| 0 | 0 | 0 | 0 |\n| 1 | 0 | 1 | 0 |\n| 0 | 1 | 1 | 0 |\n| 1 | 1 | 0 | 1 |\n\nHere&#39;s the fun part: we can build this exact behaviour using only the gates we&#39;ve already learned! When we look at the table above, we can see that the sum is only 1 when either A or B is 1. This exactly matches the behaviour of an XOR. Now for the carry, it is only 1 when both A and B are 1. This is the behaviour of the AND gate. If we put that together, it will look something like this:\n\n![Animation of how a Half-Adder works](assets/how-a-half-adder-works-logic-circuit-animation.gif)\n\nThis little circuit is our first glimpse at how computers perform arithmetic operations. It&#39;s neat, but it has a limitation: it doesn&#39;t handle a carry input. In real arithmetic, numbers don&#39;t exist in isolation. When adding multi-bit numbers, each column might produce a carry that needs to be added to the next. This is where the bigger brother of the Half-Adders comes into play, the Full-Adder. A Full-Adder extends the Half-Adder by including a **carry-in** bit (C-in). Its outputs are the **sum** and a **carry-out** bit (C-out). How do we build one? Well, it&#39;s surprisingly easy! Here is how it works:\n\n1. Take **two Half-Adders**.\n2. Feed the sum from the first into one input of the second (together with C-in).\n3. Use an extra **OR gate** to combine the carry outputs from both Half-Adders.\n\nThe result is a Full-Adder!\n\n![Overview of a Full-Adder circuit](assets/full-adder-logic-circuit.jpg)\n\nNow, here&#39;s where it gets exciting: if we chain multiple Full-Adders together by feeding each carry-out into the next carry-in, we can add multi-bit numbers. For example, connecting 8 Full-Adders creates an **8-bit adder**, capable of adding two 8-bit numbers. The final carry-out then serves as an overflow signal if the result doesn&#39;t fit into 8 bits.\n\n![Overview of an 8-bit adder circuit](assets/8-bit-adder-logic-circuit-animation.gif)\n\n## Sequential Logic\n\nSo far, we&#39;ve only looked at combinational logic circuits, circuits whose output only depends on the current inputs. Change an input, and the output changes immediately. A computer needs more than just that. If you write a sentence and your computer instantly forgets the previous letter every time you press a new key, it would not be useful. It also needs **memory**. This is where **sequential logic** comes in. Sequential circuits combine logic gates with feedback loops so that the output doesn&#39;t just depend on the current inputs, but also on the circuit&#39;s **previous state**. In other words, they have memory.\n\nA simple example of sequential logic in action is a flip-flop, a tiny circuit that can store a single bit of information. The information is stored until a new input changes it. One of the simplest types is the SR flip-flop (Set-Reset flip-flop). It has two inputs:\n\n- **S (Set)**: tells the circuit to remember a `1`\n- **R (Reset)**: tells the circuit to remember a `0`\n\nAnd it has the outputs **Q** and **Q′**, which hold the stored value and its inverse.\n\n![Overview of an SR Flip-Flop circuit](assets/sr-flip-flop-logic-circuit.jpg)\n\nThe truth table looks like this:\n\n| **S (Set)** | **R (Reset)** | **Q (next state)** | **Q′ (next state)** | Notes |\n| --- | --- | --- | --- | --- |\n| 0 | 0 | No change (holds previous value) | Opposite of Q | Memory condition |\n| 0 | 1 | 0 | 1 | Reset state |\n| 1 | 0 | 1 | 0 | Set state |\n| 1 | 1 | Undefined (invalid) | Undefined (invalid) | Not allowed |\n\nNotice something new here: when **S = 0** and **R = 0**, the output doesn&#39;t change. The flip-flop remembers whatever it was holding before. That&#39;s memory in action. As you can see, this simple flip-flop has a flaw: the state where both S and R are 1 is undefined. Luckily, engineers have designed improved versions like the JK and D flip-flops that avoid the undefined state, making them more reliable building blocks for memory.&quot;],&quot;filePath&quot;:[0,&quot;src/content/posts/from-transistor-to-system-a-friendly-guide-to-computer-architecture/2-logic.mdx&quot;],&quot;assetImports&quot;:[1,[[0,&quot;./assets/computer-architecture-transistor-to-system-guide.png&quot;]]],&quot;digest&quot;:[0,&quot;15121eefd51f885e&quot;],&quot;deferredRender&quot;:[0,true],&quot;collection&quot;:[0,&quot;posts&quot;],&quot;slug&quot;:[0,&quot;from-transistor-to-system-a-friendly-guide-to-computer-architecture/2-logic&quot;],&quot;render&quot;:[0,null]}],[0,{&quot;id&quot;:[0,&quot;from-transistor-to-system-a-friendly-guide-to-computer-architecture/4-control-unit.mdx&quot;],&quot;data&quot;:[0,{&quot;author&quot;:[0,&quot;Gianni&quot;],&quot;collection&quot;:[0,&quot;From Transistor to System: A Friendly Guide to Computer Architecture&quot;],&quot;chapter&quot;:[0,4],&quot;title&quot;:[0,&quot;How the Control Unit Makes the CPU Work: Signals, Microcode, and Decoding&quot;],&quot;shortname&quot;:[0,&quot;Control Unit&quot;],&quot;date&quot;:[3,&quot;2025-11-16T00:00:00.000Z&quot;],&quot;tags&quot;:[1,[[0,&quot;Computer Architecture&quot;]]],&quot;metaTags&quot;:[1,[[0,&quot;control unit&quot;],[0,&quot;cpu control unit&quot;],[0,&quot;microprogrammed control&quot;],[0,&quot;hardwired control&quot;],[0,&quot;microcode&quot;],[0,&quot;fetch decode execute&quot;],[0,&quot;computer architecture basics&quot;]]],&quot;difficulty&quot;:[0,&quot;Intermediate&quot;],&quot;readTime&quot;:[0,&quot;7 min&quot;],&quot;image&quot;:[0,{&quot;src&quot;:[0,&quot;/assets/computer-architecture-transistor-to-system-guide.BpaNqm1a.png&quot;],&quot;width&quot;:[0,1024],&quot;height&quot;:[0,1024],&quot;format&quot;:[0,&quot;png&quot;]}],&quot;alt&quot;:[0,&quot;Cover image for the blog series \&quot;From Transistor to System: A Friendly Guide to Computer Architecture,\&quot; showing various computer components in a cheerful, cartoon style&quot;],&quot;description&quot;:[0,&quot;Understand how the CPU Control Unit fetches, decodes, and executes instructions. Learn the differences between hardwired and microprogrammed control with clear examples.&quot;]}],&quot;body&quot;:[0,&quot;In the previous chapter, we explored the **Arithmetic Logic Unit (ALU)**, the part of the CPU responsible for performing arithmetic and logic operations. We saw how it can add, subtract, compare, and make decisions depending on the **control signals** it receives. But this raises an important question: *where do those control signals come from?* That’s the job of the **Control Unit (CU),** the CPU’s internal **orchestrator**.\r\n\r\n## The Control Unit’s Role\r\n\r\nIf we think of the CPU as a small orchestra, the **ALU** would be the musician, performing the actual notes (the operations). The **Control Unit**, on the other hand, is the **conductor**, ensuring that every part of the CPU works in perfect timing.\r\n\r\nThe Control Unit doesn’t do the math itself, but it **directs** all the components that do. It tells the ALU when to add or subtract, instructs the registers when to store or load data, and coordinates with memory to fetch new instructions.\r\n\r\nIn short, the Control Unit:\r\n\r\n- **Fetches** instructions from memory\r\n- **Decodes** what those instructions mean\r\n- **Directs** the ALU, registers, and memory to carry them out\r\n- **Repeats** this cycle continuously\r\n\r\nThis ongoing rhythm is known as the **Fetch–Decode–Execute cycle**. We’ll explore this cycle step by step in **Chapter 6**, once we’ve seen how the rest of the CPU fits together.\r\n\r\n## Hardwired vs. Microprogrammed Control\r\n\r\nNot all Control Units are built the same way. Broadly speaking, there are two main design approaches:\r\n\r\n### 1. Hardwired Control\r\n\r\nIn a **hardwired control unit**, control signals are generated directly by fixed electronic circuits made up of logic gates, flip-flops, and decoders. Each instruction’s behaviour is physically built into the hardware wiring.\r\n\r\n- **Pros:**\r\n    - Speedy (no intermediate steps).\r\n    - Efficient for simple instruction sets.\r\n- **Cons:**\r\n    - It is difficult to modify, as changing the instruction set requires redesigning the hardware.\r\n    - Complex to build for large CPUs with many instructions.\r\n\r\nThis approach is common in small or specialised processors (like microcontrollers), where performance and simplicity matter more than flexibility.\r\n\r\n### 2. Microprogrammed Control\r\n\r\nIn contrast, a **microprogrammed control unit** works more like a tiny interpreter.\r\n\r\nInstead of using fixed wiring, it stores small **microinstructions** in a special memory area called the **control store**. Each microinstruction tells the CPU which control signals to activate during one small step of an operation.\r\n\r\nSo when the CPU executes a normal instruction (like `ADD A, B`), the Control Unit actually runs a short **microprogram,** a sequence of low-level steps that cause the ALU, registers, and buses to act in the right order.\r\n\r\n- **Pros:**\r\n    - Easier to modify or extend (you can change the microcode instead of the hardware).\r\n    - Ideal for complex instruction sets (like in older CISC CPUs).\r\n- **Cons:**\r\n    - Slightly slower than hardwired designs, since each instruction is interpreted internally.\r\n\r\nModern CPUs often blend both approaches; some parts are hardwired for speed, while others use microcode for flexibility. x86 processors (like those from Intel and AMD) are a perfect example of a **hybrid** design:\r\n\r\n- **Simple instructions** such as `ADD`, `SUB`, `AND`, or `MOV` are usually handled by **hardwired control**.\r\n    \r\n    These can be executed in just a few fast steps, so wiring them directly into hardware keeps performance high.\r\n    \r\n- **Complex instructions**, like `REP MOVSB` (which copies an entire block of memory) or older instructions that are kept for backwards compatibility are handled using **microcode**.\r\n    \r\n    Internally, the CPU breaks these complicated instructions into a sequence of simpler micro-operations and runs them like a tiny program.\r\n    \r\n\r\nThis way, the CPU gets the **speed** of hardwired control for the common operations, and the **flexibility** of microcode for everything else, without needing to redesign the hardware every time the instruction set changes.\r\n\r\n## How Instructions Are Decoded\r\n\r\nEvery program you run, from a web browser to a video game, ultimately boils down to a long list of machine instructions. Each instruction is just a binary number. The Control Unit must interpret that number to decide what to do.\r\n\r\nLet’s look at a simplified example. Suppose we have an 8-bit CPU where each instruction is one byte (8 bits):\r\n\r\n```bash\r\nInstruction: 0100 1010\r\n```\r\n\r\nThe Control Unit might divide this instruction into parts like this:\r\n\r\n| **Bits** | **Meaning** |\r\n| --- | --- |\r\n| 0100 | Operation code (Opcode) → tells the CPU what to do |\r\n| 1010 | Operand → tells the CPU which register or memory address to use |\r\n\r\nWhen the Control Unit reads this instruction, it **decodes** the opcode (`0100`) to determine which control signals to activate.\r\n\r\nFor example, opcode `0100` might mean “ADD,” while `0101` could mean “SUBTRACT.”\r\n\r\nIt then sends the appropriate signals:\r\n\r\n- Enable the ALU’s “add” circuit.\r\n- Load inputs from registers A and B\r\n- Store the result back into register A\r\n\r\nAll of this happens automatically, step by step, as the CPU clock ticks.\r\n\r\n## Timing and Coordination\r\n\r\nComputers work in rhythm. Every operation, from fetching data to performing arithmetic, happens in sync with the **clock**. The clock doesn’t measure time like a wall clock; instead, it provides a steady beat that synchronises all internal actions.\r\n\r\nOn each clock pulse, the Control Unit advances the CPU to its next step: reading an instruction, setting up the ALU, or writing a result back to memory. This precise timing ensures that signals don’t collide and that every operation occurs exactly when it should.&quot;],&quot;filePath&quot;:[0,&quot;src/content/posts/from-transistor-to-system-a-friendly-guide-to-computer-architecture/4-control-unit.mdx&quot;],&quot;assetImports&quot;:[1,[[0,&quot;./assets/computer-architecture-transistor-to-system-guide.png&quot;]]],&quot;digest&quot;:[0,&quot;211441aea3e28356&quot;],&quot;deferredRender&quot;:[0,true],&quot;collection&quot;:[0,&quot;posts&quot;],&quot;slug&quot;:[0,&quot;from-transistor-to-system-a-friendly-guide-to-computer-architecture/4-control-unit&quot;],&quot;render&quot;:[0,null]}],[0,{&quot;id&quot;:[0,&quot;from-transistor-to-system-a-friendly-guide-to-computer-architecture/3-alu.mdx&quot;],&quot;data&quot;:[0,{&quot;author&quot;:[0,&quot;Gianni&quot;],&quot;collection&quot;:[0,&quot;From Transistor to System: A Friendly Guide to Computer Architecture&quot;],&quot;chapter&quot;:[0,3],&quot;title&quot;:[0,&quot;Understanding the ALU: Arithmetic, Logic, and Control Signals Explained&quot;],&quot;shortname&quot;:[0,&quot;ALU&quot;],&quot;date&quot;:[3,&quot;2025-11-02T00:00:00.000Z&quot;],&quot;tags&quot;:[1,[[0,&quot;Computer Architecture&quot;],[0,&quot;Electrical Engineering&quot;],[0,&quot;Logic&quot;]]],&quot;metaTags&quot;:[1,[[0,&quot;Arithmetic Logic Unit&quot;],[0,&quot;ALU explained&quot;],[0,&quot;CPU architecture&quot;],[0,&quot;Digital logic&quot;],[0,&quot;Computer fundamentals&quot;],[0,&quot;Binary arithmetic&quot;],[0,&quot;Logic gates&quot;],[0,&quot;Adder and subtractor&quot;],[0,&quot;Multiplexer (MUX)&quot;],[0,&quot;Opcodes&quot;],[0,&quot;Control unit&quot;],[0,&quot;Computer engineering&quot;],[0,&quot;Digital electronics&quot;],[0,&quot;Building a 1-bit ALU&quot;],[0,&quot;How computers perform arithmetic&quot;]]],&quot;difficulty&quot;:[0,&quot;Intermediate&quot;],&quot;readTime&quot;:[0,&quot;14 min&quot;],&quot;image&quot;:[0,{&quot;src&quot;:[0,&quot;/assets/computer-architecture-transistor-to-system-guide.BpaNqm1a.png&quot;],&quot;width&quot;:[0,1024],&quot;height&quot;:[0,1024],&quot;format&quot;:[0,&quot;png&quot;]}],&quot;alt&quot;:[0,&quot;Cover image for the blog series \&quot;From Transistor to System: A Friendly Guide to Computer Architecture,\&quot; showing various computer components in a cheerful, cartoon style&quot;],&quot;description&quot;:[0,&quot;Discover how the ALU enables a CPU to perform arithmetic and logic operations using adders, subtractors, logic gates, and control signals.&quot;]}],&quot;body&quot;:[0,&quot;In the previous chapter, we constructed circuits that could add numbers together, starting from a simple **Half-Adder** and progressing to an **8-bit Adder**. That was our first glimpse into how arithmetic happens inside a computer. But adders are just the beginning. Computers need a dedicated component to perform not only arithmetic but also logical decisions. This is where the **Arithmetic Logic Unit**, or **ALU**, comes in.\n\n## Arithmetic… what?\n\nAs mentioned earlier, the 8-bit adder was our first look at how arithmetic works inside a computer. However, a computer needs to do much more than add two numbers. With some clever circuitry, we can extend our 8-bit adder to create an 8-bit Subtractor. If we fix the B input of both the adder and subtractor to 00000001, we effectively create an incrementer and a decrementer, respectively.\n\nInside the CPU, all these circuits live together inside a special component called the **Arithmetic Logic Unit (ALU)**. Whenever your computer needs to perform arithmetic operations or make logical decisions, the ALU is the one doing the work. You can think of it as the calculator at the heart of the processor, but one that also understands logic.\n\nAt its core, an ALU is a circuit that takes **inputs**, performs an **operation**, and produces an **output**. The inputs usually come from CPU registers, and the operation performed depends on what the program instructs. The result is then sent back to a register or to memory for later use.\n\nWhat makes the ALU powerful is its **flexibility**. The same hardware can perform many different tasks depending on the **control signals** it receives. Depending on the control signals it receives, the ALU might add two numbers one moment, compare them the next, or even shift bits left or right.\n\nModern ALUs are often divided into two main parts:\n\n- **Arithmetic Unit (AU):** Handles mathematical operations such as addition, subtraction, multiplication, and division.\n- **Logic Unit (LU):** Handles logical operations such as AND, OR, XOR, and NOT.\n\nSome CPUs take this even further, including separate arithmetic units for different types of data. For example, one unit might handle **fixed-point arithmetic** (integers), while another handles **floating-point arithmetic** (real numbers used in scientific or graphics calculations).\n\n## Arithmetic\n\nLet’s take a closer look at how the circuits inside the ALU perform arithmetic. We already know from the previous chapter how an 8-bit adder works, and how to build incrementers and decrementers from it. But we haven’t yet seen how a **subtractor** works. Let’s start there.\n\nJust like before, we begin small, with the **Half-Subtractor**. The Half-Subtractor is similar to the Half-Adder: it has two inputs and two outputs. However, unlike the Half-Adder, it includes a **NOT gate** before the AND gate.\n\nThe first output, referred to as the **Difference**, represents the result of subtracting B from A. The second output, the **Borrow**, indicates that when the digit being subtracted (B) is larger than the digit it’s subtracted from (A), we need to “borrow” from the next higher bit, just like in decimal subtraction.\n\nHere’s how that looks conceptually:\n\n![Animated schematic diagram of a Half-Subtractor](assets/how-a-half-subtractor-works-logic-circuit-animation.gif)\n\nThe truth table for a Half-Subtractor is as follows:\n\n| A | B | Difference | Borrow |\n| --- | --- | --- | --- |\n| 0 | 0 | 0 | 0 |\n| 1 | 0 | 1 | 0 |\n| 0 | 1 | 1 | 1 |\n| 1 | 1 | 0 | 0 |\n\nTo create the **Full-Subtractor**, we combine two Half-Subtractors. It has three inputs: **A**, **B**, and **B-in** (the borrow from a previous stage).\n\n- **A** and **B** connect to the first Half-Subtractor.\n- Its **Difference** output connects to the A input of the second Half-Subtractor, while **B-in** connects to its B input.\n- The two **Borrow** outputs are combined through an **OR gate** to produce a single **Borrow out (B-out)**.\n\nConnecting eight of these Full-Subtractors forms an **8-bit Subtractor**, which can handle multi-bit binary subtraction, just like the adder, but with borrowing instead of carrying.\n\n![Schematic diagram of Full-Subtractor](assets/full-subtractor-logic-circuit.jpg)\n\n## Logic\n\nArithmetic is only half the story; the other half is logic. The **Logic Unit** performs operations like **AND**, **OR**, **XOR**, and **NOT** directly on the binary bits of its inputs. Why does this matter? Because logic operations allow a computer to **make decisions**. For example, the ALU can compare two numbers to determine whether they are equal, greater, or less than. This information is critical for loops, conditional statements, and control flow in programs. Without logic operations, a computer could calculate, but it couldn’t **decide**.\n\n## Control Signals\n\nNow that we understand what the ALU does and how it works, one question remains: how does it know what operation to perform? The ALU doesn’t choose its operation on its own. Instead, it listens to instructions sent by the Control Unit in the form of binary codes known as opcodes (operation codes). Depending on the opcode, the ALU may perform addition, subtraction, comparison, or logical operations.\n\nHere’s an example of how different control signals might map to ALU operations:\n\n| **Opcode (Control Signal)** | **Operation** |\n| --- | --- |\n| 000 | ADD |\n| 001 | SUBTRACT |\n| 010 | AND |\n| 011 | OR |\n| 100 | XOR |\n| 101 | NOT |\n\nInside the ALU, a **multiplexer (MUX)** acts as a selector. You can think of a multiplexer as an electronic switch that selects one of many inputs and forwards it to a single output, based on control signals. Each operation (add, subtract, AND, and so on) is implemented as a separate circuit. All of them receive the same inputs and produce their results **in parallel**, but only one of these outputs is actually sent to the final result line. The MUX, controlled by the opcode, chooses which one.\n\nThis approach might seem inefficient at first; after all, why compute everything if you only need one result? But it makes the ALU incredibly fast. Since all operations are ready at once, the MUX can instantly select the required output without waiting for a circuit to “turn on.”\n\n## Building a Simple 1-bit ALU\n\nNow that we know how arithmetic and logic operations work, and how control signals tell the ALU what to do, let’s put everything together and build a simple **1-bit ALU**.\n\nA 1-bit ALU performs one operation on one pair of input bits (**A** and **B**) at a time. When we combine multiple 1-bit ALUs (usually eight, sixteen, or thirty-two of them), we get a multi-bit ALU capable of handling entire binary numbers. But just like before, we’ll start small.\n\n### The Idea\n\nOur ALU will have:\n\n- Two **inputs**: A and B\n- One **control signal**: to decide what operation to perform\n- One **output**: the result of that operation\n\nFor simplicity, let’s say our ALU only performs the following operations:\n\n| **Opcode** | **Operation** | **Description** |\n| --- | --- | --- |\n| 00 | AND | Logical AND between A and B |\n| 01 | OR | Logical OR between A and B |\n| 10 | XOR | Logical XOR between A and B |\n| 11 | ADD | Adds A and B (with carry out) |\n\nIn circuit form, we’ll have **four separate mini-circuits,** one for each operation. The outputs from all four will feed into a **multiplexer (MUX)**. The MUX then selects which output to send to the final result, based on the control signal.\n\n![Schematic of a simple 1 bit ALU](assets/1-bit-alu-logic-circuit.jpg)\n\n### How it works step-by-step\n\n1. **Inputs arrive:** Two bits, A and B, are fed into the ALU.\n2. **Each mini-circuit does its job:**\n    - The **AND gate** outputs `A AND B`.\n    - The **OR gate** outputs `A OR B`.\n    - The XOR gate outputs `A XOR B`.\n    - The **adder** calculates `A + B`.\n3. **Opcode is set:** The CPU sends a 2-bit control signal telling the ALU which operation to use.\n4. **MUX selects output:** The multiplexer chooses the correct result and passes it to the output line.\n\nHere’s an example of how it behaves:\n\n| **A** | **B** | **Control** | **Operation** | **Result** |\n| --- | --- | --- | --- | --- |\n| 0 | 1 | 00 | AND | 0 |\n| 0 | 1 | 01 | OR | 1 |\n| 1 | 1 | 10 | XOR | 0 |\n| 0 | 1 | 11 | ADD | 1 |\n\n## Summary\n\n- The **ALU** is the part of the CPU that performs both arithmetic and logic operations.\n- It consists of an **Arithmetic Unit (AU)** and a **Logic Unit (LU)**.\n- **Control signals** from the control unit tell the ALU which operation to perform.\n- A **multiplexer (MUX)** selects the correct operation result.\n\nIn the next chapter, we’ll meet the **Control Unit,** the “brain” of the CPU that tells the ALU and every other component exactly what to do and when to do it.&quot;],&quot;filePath&quot;:[0,&quot;src/content/posts/from-transistor-to-system-a-friendly-guide-to-computer-architecture/3-alu.mdx&quot;],&quot;assetImports&quot;:[1,[[0,&quot;./assets/computer-architecture-transistor-to-system-guide.png&quot;]]],&quot;digest&quot;:[0,&quot;05fc76b9e7da8890&quot;],&quot;deferredRender&quot;:[0,true],&quot;collection&quot;:[0,&quot;posts&quot;],&quot;slug&quot;:[0,&quot;from-transistor-to-system-a-friendly-guide-to-computer-architecture/3-alu&quot;],&quot;render&quot;:[0,null]}],[0,{&quot;id&quot;:[0,&quot;from-transistor-to-system-a-friendly-guide-to-computer-architecture/5-memory.mdx&quot;],&quot;data&quot;:[0,{&quot;author&quot;:[0,&quot;Gianni&quot;],&quot;collection&quot;:[0,&quot;From Transistor to System: A Friendly Guide to Computer Architecture&quot;],&quot;chapter&quot;:[0,5],&quot;title&quot;:[0,&quot;Memory in Computer Architecture: Registers, Cache, RAM &amp; Storage Explained&quot;],&quot;shortname&quot;:[0,&quot;Memory&quot;],&quot;date&quot;:[3,&quot;2025-11-30T00:00:00.000Z&quot;],&quot;tags&quot;:[1,[[0,&quot;Computer Architecture&quot;]]],&quot;metaTags&quot;:[1,[[0,&quot;computer memory explained&quot;],[0,&quot;registers cache ram storage&quot;],[0,&quot;memory hierarchy guide&quot;],[0,&quot;memory addressing tutorial&quot;],[0,&quot;virtual memory mmu paging&quot;],[0,&quot;cpu architecture memory&quot;],[0,&quot;intermediate computer architecture&quot;]]],&quot;difficulty&quot;:[0,&quot;Intermediate&quot;],&quot;readTime&quot;:[0,&quot;12 min&quot;],&quot;image&quot;:[0,{&quot;src&quot;:[0,&quot;/assets/computer-architecture-transistor-to-system-guide.BpaNqm1a.png&quot;],&quot;width&quot;:[0,1024],&quot;height&quot;:[0,1024],&quot;format&quot;:[0,&quot;png&quot;]}],&quot;alt&quot;:[0,&quot;Cover image for the blog series \&quot;From Transistor to System: A Friendly Guide to Computer Architecture,\&quot; showing various computer components in a cheerful, cartoon style&quot;],&quot;description&quot;:[0,&quot;Detailed guide to how computer memory works, from registers and CPU caches to RAM, storage, memory addressing, paging, and the full memory hierarchy. Learn how modern systems manage data at every level.&quot;]}],&quot;body&quot;:[0,&quot;In earlier chapters, we have seen how the CPU performs operations and how the Control Unit coordinates them. But a CPU alone can’t do much without a place to keep data and instructions. A running program needs numbers to add, addresses to jump to, and instructions to execute, and all of that must live somewhere, and that is memory. Not all memory is created equal. Different parts of the computer store data at different speeds and capacities, depending on how quickly the CPU needs to access it.\r\n\r\n## Registers, Cache, RAM, and Storage\r\n\r\nComputers use several different types of memory and storage. Although all of these hold data, they serve very different roles. You can imagine them as a series of “shelves” at different distances from the CPU. \r\n\r\n### Registers\r\n\r\nContinuing our shelf analogy from earlier, **registers are the shelves closest to the CPU,** so close in fact that they are part of the CPU itself. Registers are tiny, high-speed storage locations used to hold data while instructions are being executed. They store things like ALU inputs, memory addresses, counters, temporary results, and more.\r\n\r\nRegisters are extremely small, usually holding between 1 and 8 bytes depending on the CPU architecture. Likewise for the number of registers. Modern CPUs also include special, wider registers (SIMD registers) for processing many values at once, useful for multimedia and scientific computing. When we say a processor is “32-bit” or “64-bit,” we’re usually referring to the size of its **general-purpose registers,** the amount of data it can work with in a single operation.\r\n\r\nCommon Register Sizes\r\n\r\n- **8-bit registers:** Seen in older or simpler CPUs; hold a single byte.\r\n- **16-bit registers:** Used in early PCs and many microcontrollers.\r\n- **32-bit registers:** Common in older x86 CPUs and ARMv7 processors.\r\n- **64-bit registers:** Found in modern x86-64 and ARM64 CPUs; allow larger numbers and bigger memory addresses.\r\n\r\nCommon Types of Registers:\r\n\r\n- **Program Counter (PC) / Instruction Pointer (IP):** Holds the address of the next instruction to fetch.\r\n- **Instruction Register (IR):** Stores the instruction currently being decoded or executed.\r\n- **Address Registers:** Hold memory addresses used for load/store operations.\r\n- **Stack Pointer (SP):** Points to the top of the stack used for function calls and temporary data.\r\n- **Data Registers (DR):** Store data loaded from memory or I/O devices.\r\n- **Accumulator (ACC):** A special register used for arithmetic; historically very important, still present conceptually.\r\n- **General-Purpose Registers (GPRs):** Flexible registers used for calculations and data manipulation (R0, R1, …).\r\n- **Status / Flags Register (SR):** Stores condition bits (Zero, Carry, Overflow, etc.) that reflect the result of ALU operations.\r\n\r\n&gt; See [Hello World in x86 Assembly: Step-by-Step Guide](http://localhost:4321/posts/hello-world-in-x86-assembly-step-by-step-guide) if you want to play around with registers yourself.\r\n&gt; \r\n\r\n### Cache\r\n\r\nCPU cache sits just outside the core, but still very close. Cache is a small, extremely fast type of memory that stores data the CPU is likely to need in the near future. Its main purpose is to reduce the time the CPU spends waiting for data from slower main memory (RAM).\r\n\r\nThink of cache as a **“middle shelf”**: not as fast as registers, but much faster than RAM and far larger than the CPU’s limited registers.\r\n\r\nModern CPUs use several layers of cache:\r\n\r\n- **L1 Cache**: The smallest and fastest level, located inside each CPU core. Often split into separate instruction and data caches (L1i and L1d).\r\n- **L2 Cache**: Larger but slightly slower than L1. Still per-core.\r\n- **L3 Cache**: Much larger and slower than L1/L2, commonly shared across all CPU cores.\r\n\r\nThe deeper the level, the farther it is from the CPU core, and the slower it gets. However, even the slowest cache is far, *far* faster than RAM.\r\n\r\nCaches work using the principle of **locality**:\r\n\r\n- **Temporal locality** – if you use data once, you’ll probably use it again soon.\r\n- **Spatial locality** – if you use data at one address, nearby data is likely needed too.\r\n\r\nThe CPU automatically loads data into the cache based on these patterns, so the next time it needs that data, it&#39;s already nearby.\r\n\r\n### **RAM (Main Memory)**\r\n\r\nIf registers are the closest shelves and cache is the middle shelf, then **RAM** (Random Access Memory) is the large set of shelves farther away but still within quick reach. RAM stores the data and programs that the CPU is currently working on. It is much larger than cache, typically measured in gigabytes, but also much slower.\r\n\r\nWhen you open an application, load a file, or run code, the operating system places that data into RAM so the CPU can access it quickly. If data is not in RAM, the CPU would have to fetch it from storage, which is slower.\r\n\r\nRAM has several key characteristics:\r\n\r\n- **Volatile:** Its contents are lost when the computer powers off.\r\n- **Random access:** Any memory location can be accessed directly and in roughly the same amount of time.\r\n- **Shared resource:** All programs running on your system compete for space in RAM.\r\n- **Bigger but slower:** Tens of nanoseconds (50-100) to access data (compared to the cache’s sub-nanoseconds).\r\n\r\nBecause RAM is much slower than cache, the CPU relies heavily on caching to avoid waiting. A cache “miss” forces the CPU to fetch data from RAM, and this delay can hurt performance significantly.\r\n\r\nRAM exists in different forms and technologies:\r\n\r\n- **DRAM (Dynamic RAM):** The most common type. Needs to be refreshed constantly.\r\n- **SDRAM (Synchronous DRAM):** Works in sync with the CPU clock.\r\n- **DDR (Double Data Rate SDRAM):** Modern high-speed family of RAM (DDR3, DDR4, DDR5).\r\n\r\nYou don’t need to know the hardware details to understand its role: **RAM is the CPU’s working area**, holding the data and code currently in use.\r\n\r\n### Storage (HDD, SSD, and More)\r\n\r\nIf registers are the closest shelves and RAM is the workspace, then **storage** is the large warehouse where data is kept long-term. Storage is where your computer permanently keeps files, programs, photos, operating system data, and everything else, even when the power is off.\r\n\r\nStorage is **much slower** than RAM, but it is also **much larger**, typically measured in hundreds of gigabytes or even terabytes.\r\n\r\nCommon types of storage include:\r\n\r\n- **HDD (Hard Disk Drive):** Uses spinning disks and a moving read/write head. Much slower than SSDs but still common for large, inexpensive storage.\r\n- **SSD (Solid-State Drive):** Has no moving parts. Much faster than HDDs, vastly improving boot times, loading times, and responsiveness.\r\n- **NVMe SSD:** A newer type of SSD that connects directly to the CPU via PCIe, offering extremely high read/write speeds.\r\n\r\nStorage is **non-volatile**, meaning data remains even when the computer is turned off, unlike RAM.\r\n\r\nWhenever the system needs something that’s not in RAM, it loads it from storage. If RAM fills up, the operating system may even use the storage device as “overflow,” in a process called *paging* or *swapping*, though this is much slower.\r\n\r\nStorage isn’t designed for speed; it’s designed for **capacity and long-term permanence**.\r\n\r\n## How Memory Addressing Works\r\n\r\nSo far, we’ve discussed different types of memory and storage, but how does the CPU locate specific data within all that memory? This is where **memory addressing** comes in.\r\n\r\nEvery byte in RAM has a unique identifier, known as a **memory address**. You can think of RAM as a long row of tiny mailboxes, each with its own number starting from 0. When the CPU needs data, it provides the address of the mailbox where that data lives.\r\n\r\nFor example, if the CPU wants the byte stored at address `1000`, it sends the number `1000` across the **address bus**. RAM receives this address, looks it up, and returns the correct data byte.\r\n\r\n### **Addresses Are Just Numbers**\r\n\r\nMemory addresses are simply binary numbers. A CPU with:\r\n\r\n- **32-bit addressing** can theoretically access up to 2³² bytes (4 GB) of memory\r\n- **64-bit addressing** can (in theory) access 2⁶⁴ bytes, an enormous number, far beyond what modern computers actually install\r\n\r\nThis is one of the big reasons 64-bit CPUs became standard: they can address far more memory than 32-bit systems.\r\n\r\n### **Addressing Words, Not Just Bytes**\r\n\r\nWhile every byte has an address, the CPU often works with bigger chunks called **words**. The word size usually matches the CPU’s register size, which is why “32-bit” and “64-bit” processors get their names, so:\r\n\r\n- A 32-bit CPU uses 32-bit (4-byte) words\r\n- A 64-bit CPU uses 64-bit (8-byte) words\r\n\r\nEven though memory is byte-addressable, the CPU might fetch a whole word at once. This is because the CPU usually operates on full words at a time, not single bytes.\r\n\r\n### **Pointers and Addresses**\r\n\r\nWhen a program stores a memory address in a variable, that variable is called a **pointer**. Instead of holding actual data, it holds the *location* of data. You’ll encounter pointers in low-level programming (like C or assembly), and understanding memory addresses is key to using them correctly.\r\n\r\n### **Sequential Instructions**\r\n\r\nInstructions stored in memory also have addresses. The **Program Counter (PC)** holds the address of the next instruction, and the CPU increases it as it executes instructions sequentially, unless a jump or branch changes it.\r\n\r\n### **How the CPU Sends and Receives Addresses**\r\n\r\nThe CPU communicates with memory through two main channels:\r\n\r\n- **Address bus:** sends *where* the data is\r\n- **Data bus:** sends the actual data back and forth\r\n\r\nWhen the CPU wants to read memory:\r\n\r\n1. It places an address on the address bus\r\n2. Memory responds by putting the requested data on the data bus\r\n3. The CPU reads that data\r\n\r\nWhen writing, the CPU places both the address *and* the data on the appropriate buses.\r\n\r\n### **Virtual vs. Physical Memory**\r\n\r\nModern operating systems do **not** let programs access physical RAM directly. Instead, every program sees its own private world of memory called **virtual memory**. When you see an address in a debugger like `0x00400000`, that number is **not** the true physical RAM location. It is a *virtual address* that must be translated.\r\n\r\nThis translation is handled by a small hardware unit inside the CPU called the **Memory Management Unit (MMU)**.\r\n\r\nWhy have virtual memory at all? Virtual memory gives us:\r\n\r\n- **Protection:** One program cannot read or overwrite another program.\r\n- **Simplicity:** Each program sees a nice, clean, continuous block of memory.\r\n- **Flexibility:** Programs can use more memory than physically installed (thanks to paging).\r\n- **Sharing:** System libraries can be shared between programs without copying them.\r\n\r\n### How the Mapping Works\r\n\r\nTo avoid translating billions of individual bytes, the OS divides memory into fixed-size blocks called **pages,** with a typical size of **4 KB**. Both *virtual memory* and *physical memory* are divided into these 4 KB units.\r\n\r\nSo instead of mapping:\r\n\r\n```\r\nVirtual → Physical\r\nByte 14 → Byte 214920\r\nByte 15 → Byte 214921\r\nByte 16 → Byte 214922\r\n```\r\n\r\nThe system maps at page granularity:\r\n\r\n```\r\nVirtual Page #12 → Physical Page #203\r\nVirtual Page #13 → Physical Page #8\r\nVirtual Page #14 → (not in RAM — stored on disk)\r\n```\r\n\r\nEach program has its own **page table**, which is a big list that tells the MMU: “If the CPU accesses virtual page X, it actually lives at physical page Y.”\r\n\r\n### What the MMU Does on Every Memory Access\r\n\r\nEvery time the CPU touches memory (load, store, fetch instruction), the MMU:\r\n\r\n1. **Takes the virtual address**\r\n2. **Splits it into:**\r\n    - a *page number*\r\n    - an *offset* inside the page\r\n3. **Looks up the page number in the page table**\r\n4. **Finds the physical page number**\r\n5. **Recombines**\r\n    \r\n    physical page number + offset\r\n    \r\n    to form the final **physical address**\r\n    \r\n6. RAM is accessed normally using that physical address.\r\n\r\nThis happens billions of times per second and is completely invisible to software. Additionally, to make these translations faster, the CPU stores recently used mappings in a tiny cache called the **TLB (Translation Lookaside Buffer)**, so most address translations never require a full page-table lookup.\r\n\r\n### Translation Example\r\n\r\nVirtual address:\r\n\r\n```\r\n0x00403A10\r\n```\r\n\r\nBreak into:\r\n\r\n- **Virtual page number** = 0x00403\r\n- **Offset** = 0xA10 (the location inside that 4 KB page)\r\n\r\nMMU finds:\r\n\r\n```\r\nVirtual page number = 0x00403  \r\nOffset inside the page = 0xA10\r\n```\r\n\r\nFinal physical address:\r\n\r\n```\r\nPhysical Page 0x1A2C + offset 0xA10 = 0x1A2CA10\r\n```\r\n\r\nThe CPU now reads or writes that physical address.\r\n\r\n### **What If a Page Isn’t in RAM? (Page Faults)**\r\n\r\nIf the MMU sees that a virtual page isn’t currently loaded in RAM, the CPU triggers a **page fault**.\r\n\r\nThe OS then:\r\n\r\n1. Pauses the program\r\n2. Loads the page from storage (SSD) into RAM\r\n3. Updates the page table\r\n4. Resumes the program\r\n\r\nThis is how the system gives programs more “memory” than you physically have.\r\n\r\n## Memory Hierarchy\r\n\r\nNow that we’ve seen *how* memory works at a low level, we can look at how all these different types fit together into the overall structure of a computer’s memory system. All these different kinds of memory (registers, cache, RAM, storage) form what’s known as the **memory hierarchy**. Each level trades capacity for speed:\r\n\r\n1. **Registers**: Tiny, fastest, directly inside the CPU\r\n2. **L1/L2/L3 Cache**: Small, fast, close to the CPU\r\n3. **RAM**: Large, much slower\r\n4. **Storage (SSD/HDD)**: **H**uge, much slower\r\n5. **External storage/cloud**: **G**igantic capacity, extremely slow\r\n\r\nAs we move down the hierarchy:\r\n\r\n- **Speed decreases**\r\n- **Size increases**\r\n- **Cost per byte decreases**\r\n\r\nThe CPU always tries to work with data from the **highest** (fastest) level available. If the data isn’t there, it must fetch it from a slower level in a process called a **memory access**, which takes more time the further down the hierarchy it goes.\r\n\r\nThis hierarchy is the backbone of computer performance. It allows the CPU to operate at high speed without needing gigabytes of expensive, ultra-fast memory.\r\n\r\nMuch of computer architecture, from cache design to operating systems, exists to make this hierarchy feel as fast as possible to software.&quot;],&quot;filePath&quot;:[0,&quot;src/content/posts/from-transistor-to-system-a-friendly-guide-to-computer-architecture/5-memory.mdx&quot;],&quot;assetImports&quot;:[1,[[0,&quot;./assets/computer-architecture-transistor-to-system-guide.png&quot;]]],&quot;digest&quot;:[0,&quot;78917a14774bc4d7&quot;],&quot;deferredRender&quot;:[0,true],&quot;collection&quot;:[0,&quot;posts&quot;],&quot;slug&quot;:[0,&quot;from-transistor-to-system-a-friendly-guide-to-computer-architecture/5-memory&quot;],&quot;render&quot;:[0,null]}],[0,{&quot;id&quot;:[0,&quot;the-tough-love-architecture-guide/1-the-harsh-truth-about-your-design-pattern-choices.mdx&quot;],&quot;data&quot;:[0,{&quot;author&quot;:[0,&quot;Quinn&quot;],&quot;collection&quot;:[0,&quot;The Tough Love Architecture Guide&quot;],&quot;chapter&quot;:[0,1],&quot;title&quot;:[0,&quot;The Harsh Truth About Your Design Pattern Choices&quot;],&quot;shortname&quot;:[0,&quot;Truth&quot;],&quot;date&quot;:[3,&quot;2025-08-24T00:00:00.000Z&quot;],&quot;tags&quot;:[1,[[0,&quot;Software Design Patterns&quot;]]],&quot;metaTags&quot;:[1,[[0,&quot;Design pattern mistakes&quot;],[0,&quot;Choosing the right design pattern&quot;]]],&quot;difficulty&quot;:[0,&quot;Beginner&quot;],&quot;readTime&quot;:[0,&quot;5 min&quot;],&quot;image&quot;:[0,{&quot;src&quot;:[0,&quot;/assets/BannerTheHarshTruth.Dne4Iewa.jpg&quot;],&quot;width&quot;:[0,1920],&quot;height&quot;:[0,1600],&quot;format&quot;:[0,&quot;jpg&quot;],&quot;orientation&quot;:[0,1]}],&quot;alt&quot;:[0,&quot;Collection of computer windows&quot;],&quot;description&quot;:[0,&quot;Most developers misuse design patterns. Learn when to apply them, when to avoid them, and how to simplify your architecture for real-world projects.&quot;]}],&quot;body&quot;:[0,&quot;Imagine you&#39;re knees-deep in a project deadline, navigating through so many lines of messy code that resemble a spaghetti factory explosion. You&#39;ve probably been there: tempted to implement a clever design pattern you recently learned about, hoping it will be the magic bullet for all your coding woes. But here&#39;s a reality check: “most developers either misuse or don&#39;t know what they are doing with design patterns”. It&#39;s not because they&#39;re bad at coding, but they&#39;ve fallen into the trap I like to call ***Pattern worshiping.***\n\nIf you&#39;re the type of developer who finds themselves forcing a Pattern into a project that didn&#39;t need one, you&#39;re not alone, and this page is for you. By the end, you&#39;ll not only understand how to stop turning your architecture into a &#39;look what I have learned in school&#39; museum, but you&#39;ll discover how to save valuable time, reduce the introduction of bugs, and improve code review outcomes by choosing solutions that truly solve your problem.\n\n---\n\n## The myth of the “Perfect” Design Pattern\n\nLet me give you a quick reality check: THERE IS NO UNIVERSAL BEST PATTERN.\n\nThe right pattern in one project could be the wrong pattern in another. Yet, including myself at times, we developers often pick a pattern simply because a tutorial made it look sexy. This leads to bizarre overengineering, such as creating a simple object using a Builder, Factory, and Prototype pattern simply because the textbook made it look cool. Consider this: a startup once spent a month implementing an intricate Builder-Factory architecture, only to realize that it could be refactored in a single day using straightforward functions. This real-world example illustrates the potential pitfall of blindly applying complex patterns where simplicity would suffice.\n\nA pattern should never be your objective; it should only make your solution simpler, not more complex.\n\n---\n\n## Harsh Truth #1 - Patterns Are Tools, Not Goals\n\nHammers are a great tool when you have a bunch of nails, but they are awful when you try to fix a leaky pipe.\n\nDesign patterns are similar; they are tools that can be great for the right task. If you start a project and think, *“I want to use a singleton pattern,”* You are not addressing the underlying problem, but rather your desires\n\nA code base can quickly become overcomplicated when we use patterns that do not fit the task. Sometimes, a simple if statement will do a better job.\n\nBefore you begin implementing a new pattern, ask yourself these three questions:\n\n1. Does using a strategy pattern here reduce complexity, or are we simply rearranging it?\n2. Will the code be easier to maintain after implementing the pattern?\n3. Will future developers understand and appreciate the added complexity?\n\n---\n\n## Harsh Truth #2 - Ignoring Constraints will lead to wrong choices\n\nFor most of us, we are not writing code on supercomputers with unlimited memory, crazy performance, and super high concurrency. We work in a world where we are restricted by boundaries and constraints. When selecting a pattern, we must consider all our constraints, including the team&#39;s experience, deadlines, business requirements, and performance. To help ensure these constraints are at the forefront of consideration, here is a checklist of typical project limitations you should evaluate:\n\n- Memory availability\n- Latency requirements\n- Team skill levels\n- Project deadlines\n- Business needs\n- Performance targets\n- Scalability demands\n\nIf we ignore our constraint, we&#39;ll end up with mismatched solutions. The right pattern is the one that fits within our boundaries and doesn&#39;t violate our constraints.\n\n---\n\n## Harsh Truth #3 - You&#39;re Probably Copying, Not Designing\n\nThis one might be a bit awkward, but many developers don&#39;t apply patterns; they simply copy them. They find some pattern, copy it into their codebase, change some class name, and call it a solid architecture. The problem with this is that textbook examples all live in a perfect world where requirements never change and performance is someone else&#39;s problem. To truly embrace the creative process of design, ask yourself: &#39;Which parts of this pattern can we safely drop or modify while still achieving our goals?&#39; This mindset encourages adaptation rather than blind replication, allowing for solutions that are tailored to the specific challenges of your project.\n\nThe code we write will not live in that perfect world. This means we need to adapt and modify the pattern to make it fit within our domain. We need to tweak the pattern to ensure it operates within our boundaries and does not cross any constraints. Blindly copying a perfect example will fall apart when reality comes knocking.\n\n---\n\n## Patterns don&#39;t make you smart; good choices do\n\nA well-chosen pattern can make your code elegant and maintainable, but the wrong choice leads to unnecessary complexity. Choosing a pattern should always serve your problem, not overshadow it.\n\nThe harsh truth is: just knowing design patterns does not make you a good developer, but knowing when **not** to use them will bring you pretty close to being one.\n\nInstead of defaulting to whatever is trending, we can follow a simple framework. Next time you&#39;re faced with a problem, follow these five guidelines:\n\n1. **Define the problem clearly**\n2. **Identify constraints**\n3. **List candidate patterns**\n4. **Evaluate trade-offs**\n5. **prototype and test**\n\nSo next time, remember: your real goal isn&#39;t to use fancy patterns, but to solve the problem in front of you as directly as possible.&quot;],&quot;filePath&quot;:[0,&quot;src/content/posts/the-tough-love-architecture-guide/1-the-harsh-truth-about-your-design-pattern-choices.mdx&quot;],&quot;assetImports&quot;:[1,[[0,&quot;./assets/BannerTheHarshTruth.jpg&quot;]]],&quot;digest&quot;:[0,&quot;45d040f15b55ee69&quot;],&quot;deferredRender&quot;:[0,true],&quot;collection&quot;:[0,&quot;posts&quot;],&quot;slug&quot;:[0,&quot;the-tough-love-architecture-guide/1-the-harsh-truth-about-your-design-pattern-choices&quot;],&quot;render&quot;:[0,null]}],[0,{&quot;id&quot;:[0,&quot;the-tough-love-architecture-guide/2-refactoring-a-bad-design-a-step-by-step-example.mdx&quot;],&quot;data&quot;:[0,{&quot;author&quot;:[0,&quot;Quinn&quot;],&quot;collection&quot;:[0,&quot;The Tough Love Architecture Guide&quot;],&quot;chapter&quot;:[0,2],&quot;title&quot;:[0,&quot;Refactoring a Bad Design: A Step-by-Step Example&quot;],&quot;shortname&quot;:[0,&quot;Bad Design&quot;],&quot;date&quot;:[3,&quot;2025-09-21T00:00:00.000Z&quot;],&quot;tags&quot;:[1,[[0,&quot;Software Design Patterns&quot;]]],&quot;metaTags&quot;:[1,[[0,&quot;Refactoring Java Code&quot;],[0,&quot;Clean Code Practices&quot;],[0,&quot;Software Architecture&quot;],[0,&quot;UserManager Class Example&quot;],[0,&quot;Technical Debt Management&quot;],[0,&quot;Java Unit Testing&quot;],[0,&quot;Mocking in Java (Mockito)&quot;],[0,&quot;Code Maintainability&quot;],[0,&quot;Incremental Refactoring&quot;],[0,&quot;Testable Code Design&quot;],[0,&quot;Object-Oriented Design Principles&quot;],[0,&quot;Single Responsibility Principle (SRP)&quot;]]],&quot;difficulty&quot;:[0,&quot;Beginner&quot;],&quot;readTime&quot;:[0,&quot;10 min&quot;],&quot;image&quot;:[0,{&quot;src&quot;:[0,&quot;/assets/BannerRefactoringBadDesign.CtFcZgfN.png&quot;],&quot;width&quot;:[0,1988],&quot;height&quot;:[0,1500],&quot;format&quot;:[0,&quot;png&quot;]}],&quot;alt&quot;:[0,&quot;Programmer behinde a computer&quot;],&quot;description&quot;:[0,&quot;Learn how to refactor an overgrown Java class using incremental steps, abstractions, and unit testing.&quot;]}],&quot;body&quot;:[0,&quot;Let&#39;s be honest: most projects don&#39;t start with a bad design. Over time, requirements change or new ones get added. Perhaps we have a tight deadline to meet, or maybe we&#39;re just being lazy, but often we will just hack the new requirements into the original design. We just tell ourselves that we&#39;ll refactor this later, but of course, we never do. Imagine a scenario where a seemingly minor piece of unrefactored code caused a system outage. This can result in thousands of dollars in lost revenue within a matter of hours. Such real-world setbacks underscore the critical importance of timely refactoring and set the stage for understanding the need to manage technical debt responsibly.\n\nA few deadlines later, and that “*temporary*” architecture has roots so deep that nobody wants to touch it. The code works..., but it&#39;s very fragile, hard to test, and impossible to extend without breaking something.\n\nIn this article, I will present a small example of a single class that started with good intentions but over time has grown into a monster that only a few of us dare tame. You will be able to translate the techniques I use to tame the beast to your real-life projects.\n\n## A bad design - (Setting the scene)\n\nLet me introduce you to our scene: the UserManager class.\n\nRight now, this class does a bit of everything:\n\n- Creating user\n- Saving them to the database\n- Sending welcome emails\n- Logging user actions\n\n```java\npublic class UserManager {\n    private Database database;\n    private EmailService emailService;\n    private Logger logger;\n\n    public UserManager(Database database, EmailService emailService, Logger logger) {\n        this.database = database;\n        this.emailService = emailService;\n        this.logger = logger;\n    }\n\n    public void createUser(String name, String email) {\n        // Save user to database\n        database.save(new User(name, email));\n\n        // Send welcome email\n        emailService.send(email, \&quot;Welcome to our app!\&quot;);\n\n        // Log the action\n        logger.log(\&quot;User created: {}\&quot;, name);\n    }\n\n    public void deleteUser(String email) {\n        database.delete(email);\n        logger.log(\&quot;User deleted: {}\&quot;, email);\n    }\n}\n\n```\n\nInitially, this class was created simply for storing users in a database. Even though you might initially think this class looks fine. It has become a sleeping monster; this class has too many responsibilities, is tightly coupled, and is hard to test. Now, let&#39;s break down the steps needed to start and refactor this.\n\n## Step 1 - Identify the problem\n\nMany developers will see some \&quot;Messy\&quot; code and think, \&quot;I need to rewrite this.\&quot; However, let me explain why this could be dangerous. Bad code can still contain a significant amount of business logic, undocumented hacks, and edge cases. For instance, there might be a seemingly redundant line of code that checks if a user&#39;s name is exactly 13 characters long. Although it may seem unusual, it could be an essential edge case for handling inputs from a specific legacy system that incorrectly handles overflow. If you simply rewrite the code, there is a significant chance you will lose the hidden knowledge buried inside the existing codebase.\n\nInstead of immediately rewriting the code, you can better ask yourself the following questions:\n\n- ***What exactly is wrong?***\n- ***Why is it wrong?***\n\nIf we answer these questions for our class, it comes down to the problem that the class has too many responsibilities (user creation, persistence, logging, and email sending). This is incorrect because the class has too many responsibilities, creating the risk that changing one thing will break another.\n\nRefactoring this class isn&#39;t just about style. It&#39;s about concerns related to testability and tight coupling.\n\n## Step 2 - Choose a better solution\n\nLet&#39;s not be like most developers and skip this part. But instead of just starting and rewriting the code, trying to hammer out a better solution, ask these three questions first:\n\n- *What role should this class or component actually play?*\n- *Which responsibility should it keep and which should it rewrite?*\n- *What are the most important constraints right now? (testability, performance, maintainability)*\n\nIn our case, the **UserManager** is overwhelmed with various responsibilities, including persistence, notifications, and logging. We need to shift the role of our class from “doing everything” to an orchestrator.\n\nIt means the **UserManager** class should just coordinate the workflow. However, it should not be aware of how each specific activity is implemented and executed. We need to create specific classes for each task (**UserRepository, EmailNotifier**).\n\nWhen we actually try to find a better solution, we&#39;re not just cleaning up the code; we&#39;re also redefining the architecture around the identified problem. We&#39;re not worried about choosing the coolest pattern, but we actually try to find a good solution.\n\n## Step 3 - Create an implementation plan\n\nNow, for this step, we need some real discipline. We identified the problem and found a solution to fix it. What is left but deleting this class and writing it again right!? With this approach, we risk losing working code, introducing new bugs, or even reintroducing the same design problems.\n\nInstead, let&#39;s take a safer approach; think *incremental refactoring.* We make small and safe changes one at a time, which we can test individually. This approach will give us a better chance of retaining all functionality.\n\nThis is a simple playbook you can follow once ready to implement your solution:\n\n1. **Introduce abstraction early.** Try to define your interfaces and abstract classes before implementing them. This approach will help you determine if your predefined contracts are sensible without having to implement them. For our piece of code, we need to create the interfaces ***UserRepository** and **EmailNotifier.***\n2. **Start with one responsibility.** Don&#39;t take out everything at once. For example, in the **UserManager** class, it would make sense to first extract the logic for the **UserRepository** while keeping the rest of the code intact.\n3. **Strangle old code.** Don&#39;t delete existing methods straight away. Let the abstraction take over piece by piece. Only remove the old code once you&#39;re confident that you haven&#39;t broken anything and have covered all the expected behaviours.\n4. **Test as you go.** After adding the abstraction, write unit tests for it. Verify your implementation and ensure that your refactoring hasn&#39;t broken anything.\n5. **Keep the class working at every stage.** Even when you&#39;re in the middle of refactoring, your code should still work. If you follow this approach, it will be easy to identify when and where you could have made a possible mistake.\n\nThe primary concept of this playbook is straightforward: each step should be reversible. If something fails, you can rollback that step instead of needing to do a massive rewrite and spend a lot of time refactoring.\n\n## Step 4 - Implement the changes\n\nWe have finally arrived at the fun part, and we can start refactoring. Let&#39;s refactor our **UserManager** class using the playbook defined in step 3.\n\n### Step 4.1 Introduce the abstraction\n\nLet&#39;s start by introducing some abstraction to the UserManager. Our class does not need to know how the underlying implementation works. We will create two interfaces: one for the EmailManager and one for the UserRepository. The heaviest dependency is the UserRepository, so let&#39;s start removing the direct coupling between the UserManager and the UserRepository.\n\nThe UserRepository interface will have two methods: one to save a user and one to delete a user from the database. Our UserRepository will look like this:\n\n```java\npublic interface UserRepository {\n    void save(User user);\n    void deleteById(String emailAddress);\n}\n```\n\nNext, we need to extract the email sending logic. We will follow the same approach where the UserManager class does not need to know the underlying implementation. Our EmailNotifier interface will have one method that allows us to send a welcome email.\n\n```java\npublic interface EmailNotifier {\n    void sendWelcomeEmail(String emailAddress);\n}\n```\n\n### Step 4.2 Extract the persistence logic\n\nNow that we have defined our interfaces, let&#39;s write an implementation. We will implement the persistence logic in the UserRepository, like this:\n\n```java\npublic class UserRepositoryImpl implements UserRepository {\n    private final Database database;\n\n    public UserRepositoryImpl(Database database) {\n        this.database = database;\n    }\n\n    @Override\n    public void save(User user) {\n        database.save(user);\n    }\n\n    @Override\n    public void deleteById(String emailAddress) {\n        database.delete(emailAdress);\n    }\n}\n```\n\n### Step 4.3 Extract the notification logic\n\nLastly, we need to implement our second interface: the EmailNotifier. Our implementation will look like this:\n\n```java\npublic class EmailNotifierImpl implements EmailNotifier {\n    private final EmailService emailService;\n\n    public EmailNotifierImpl(EmailService emailService) {\n        this.emailService = emailService;\n    }\n\n    @Override\n    public void sendWelcomeEmail(String emailAdress) {\n        emailService.send(emailAdress, \&quot;Welcome to our app!\&quot;);\n    }\n}\n```\n\n### Step 4.4. Update UserManager to orchestration\n\nNow, let&#39;s add these interfaces to the UserManager class.\n\n```java\npublic class UserManager {\n    private final UserRepository userRepository;\n    private final EmailNotifier emailNotifier;\n    private final Logger logger;\n\n    public UserManager(UserRepository userRepository, EmailNotifier emailNotifier, Logger logger) {\n        this.userRepository = userRepository;\n        this.emailNotifier = emailNotifier;\n        this.logger = logger;\n    }\n\n    public void createUser(String name, String email) {\n        userRepository.save(new User(name, email));\n        emailNotifier.sendWelcomeEmail(email);\n        logger.log(\&quot;User created: {}\&quot;, name);\n    }\n\n    public void deleteUser(String emailAddress) {\n        userRepository.deleteById(emailAddress);\n        logger.log(\&quot;User deleted: {}\&quot;, emailAddress);\n    }\n}\n```\n\n## Step 4.5. Unit tests\n\nTo ensure the robustness and functionality after our refactoring, it is crucial to implement unit tests consistently. Our primary goal is to verify key functionality, such as user management, and confirm that these aspects function without errors. We begin by writing unit tests for each of our interfaces and the UserManager. This involves verifying the core operations of saving and deleting users, ensuring data integrity, and operational reliability.\n\n```java\nclass UserRepositoryTests {\n    private UserRepository userRepo;\n    private Database database;\n\t\n    @BeforeEach\n    void init() {\n        database = mock(Database.class);\n        userRepo = new UserRepositoryImpl(database);\n    }\n\t\n    @Test\n    void testSaveUser() {\n        User user = new User(\&quot;testUser\&quot;, \&quot;testUser@mail.com\&quot;);\n        userRepo.save(user);\n    \n        verify(database, times(1)).save(user);\n    }\n\t\n    @Test\n    void testDeleteById() {\n        String email = \&quot;testUser@mail.com\&quot;;\n        userRepo.deleteById(email);\n    \n        verify(database, times(1)).delete(email);\n    }\n}\n```\n\nNext, we need to verify the EmailNotifier. For this interface, we need to check if we can successfully send a welcome email.\n\n```java\nclass EmailNotifierTests {\n    private EmailNotifier emailNotifier;\n    private EmailService emailService;\n\n    @BeforeEach\n    void init() {\n        emailService = mock(EmailService.class);\n        emailNotifier = new EmailNotifierImpl(emailService);\n    }\n\n    @Test\n    void testSendWelcomeEmail() {\n        String email = \&quot;testUser@mail.com\&quot;;\n        emailNotifier.sendWelcomeEmail(email);\n    \n        verify(emailService, times(1)).send(email, \&quot;Welcome to our app!\&quot;);\n    }\n}\n```\n\nThe final part we need to verify is the UserManager, where we bring it all together. For our UserManager unit tests, we should focus on verifying collaboration, ensuring it effectively delegates tasks to the appropriate interfaces, such as UserRepository and EmailNotifier. Instead of checking internal state changes, we should utilise mocks for these components. This approach will allow us to assert that the interfaces were indeed called, indicating successful orchestration.\n\n```java\nclass UserManagerTests {\n    private UserManager userManager;\n    private UserRepository userRepository;\n    private EmailNotifier emailNotifier;\n    private Logger logger;\n\n    @BeforeEach\n    void init() {\n        userRepository = mock(UserRepository.class);\n        emailNotifier = mock(EmailNotifier.class);\n        logger = mock(Logger.class);\n        \n        userManager = new UserManager(userRepository, emailNotifier, logger);\n    }\n\n    @Test\n    void testCreateUser() {\n        userManager.createUser(\&quot;testUser\&quot;, \&quot;testUser@mail.com\&quot;);\n        \n        verify(userRepository, times(1)).save(any(User.class));\n        verify(emailNotifier, times(1)).sendWelcomeEmail(\&quot;testUser@mail.com\&quot;);\n        verify(logger, times(1)).log(\&quot;User created: {}\&quot;, \&quot;testUser\&quot;);\n    }\n\n    @Test\n    void testDeleteUser() {\n        userManager.deleteUser(\&quot;testUser@mail.com\&quot;);\n        \n        verify(userRepository, times(1)).deleteById(\&quot;testUser@mail.com\&quot;);\n        verify(logger, times(1)).log(\&quot;User deleted: {}\&quot;, \&quot;testUser@mail.com\&quot;);\n    }\n}\n```\n\n## Refactoring is About Purpose, Not Perfection\n\nRefactoring isn&#39;t about making code look pretty. It&#39;s about making the design better fit the problem. In our original **UserManager** class, the code worked, but it was brittle and hard to maintain. By separating the functionality, introducing abstraction, and refactoring in safe steps, we made it flexible, testable, and ready for future maintenance. Next time your face badly designed code, remember:\n\n- Identify the problem before you touch code.\n- Select a more suitable direction based on the constraints.\n- Break the refactoring down into safe, reversible steps.\n\nSmall, deliberate changes beat a massive rewrite every time. To put this into practice, I challenge you: identify one overgrown class in your codebase today and apply Step 1—Identify the problem. This initial step can pave the way for meaningful refactoring and tangible improvements in your projects.&quot;],&quot;filePath&quot;:[0,&quot;src/content/posts/the-tough-love-architecture-guide/2-refactoring-a-bad-design-a-step-by-step-example.mdx&quot;],&quot;assetImports&quot;:[1,[[0,&quot;./assets/BannerRefactoringBadDesign.png&quot;]]],&quot;digest&quot;:[0,&quot;7b2086829739bbf0&quot;],&quot;deferredRender&quot;:[0,true],&quot;collection&quot;:[0,&quot;posts&quot;],&quot;slug&quot;:[0,&quot;the-tough-love-architecture-guide/2-refactoring-a-bad-design-a-step-by-step-example&quot;],&quot;render&quot;:[0,null]}],[0,{&quot;id&quot;:[0,&quot;the-tough-love-architecture-guide/3-what-actually-works-in-high-performance systems.mdx&quot;],&quot;data&quot;:[0,{&quot;author&quot;:[0,&quot;Quinn&quot;],&quot;collection&quot;:[0,&quot;The Tough Love Architecture Guide&quot;],&quot;chapter&quot;:[0,3],&quot;title&quot;:[0,&quot;Design Patterns for Performance: What Actually Works in High-Performance Systems&quot;],&quot;shortname&quot;:[0,&quot;Performance&quot;],&quot;date&quot;:[3,&quot;2025-10-26T00:00:00.000Z&quot;],&quot;tags&quot;:[1,[[0,&quot;Software Design Patterns&quot;]]],&quot;metaTags&quot;:[1,[[0,&quot;high performance systems&quot;],[0,&quot;high frequency trading architecture&quot;],[0,&quot;software design patterns&quot;],[0,&quot;concurrency design patterns&quot;],[0,&quot;reactor pattern&quot;],[0,&quot;actor model concurrency&quot;],[0,&quot;fan out fan in pattern&quot;],[0,&quot;cache-aside pattern&quot;],[0,&quot;sharding pattern&quot;],[0,&quot;zero-copy io&quot;],[0,&quot;memory-mapped files&quot;],[0,&quot;circuit breaker pattern&quot;],[0,&quot;bulkhead pattern&quot;],[0,&quot;load shedding pattern&quot;],[0,&quot;fault tolerant systems&quot;],[0,&quot;low latency architecture&quot;],[0,&quot;scalable system design&quot;],[0,&quot;io bound optimization&quot;],[0,&quot;concurrent programming patterns&quot;],[0,&quot;resilient software architecture&quot;],[0,&quot;performance optimization techniques&quot;],[0,&quot;system bottleneck analysis&quot;],[0,&quot;distributed systems design&quot;],[0,&quot;maintainable high performance code&quot;],[0,&quot;real time trading systems&quot;]]],&quot;difficulty&quot;:[0,&quot;Beginner&quot;],&quot;readTime&quot;:[0,&quot;7 min&quot;],&quot;image&quot;:[0,{&quot;src&quot;:[0,&quot;/assets/BannerHighPerformance.psXMTq8-.jpg&quot;],&quot;width&quot;:[0,3959],&quot;height&quot;:[0,2880],&quot;format&quot;:[0,&quot;jpg&quot;]}],&quot;alt&quot;:[0,&quot;Speedometer&quot;],&quot;description&quot;:[0,&quot;Learn how to use proven design patterns to build high-performance and low-latency systems. Explore the Reactor pattern, Actor model, Fan-out/Fan-in, Cache-Aside, Sharding, and resilience patterns like Circuit Breaker, Bulkhead, and Load Shedding. Improve speed, scalability, and maintainability in complex architectures.&quot;]}],&quot;body&quot;:[0,&quot;You might think to yourself that we don’t need design patterns when building high-frequency trading systems. This might be true for fun hobby projects, but in the real world, it will lead to a codebase that is hard to maintain and prone to subtle bugs like race conditions and deadlocks. Engineers often face challenges such as these when concurrent processes inadvertently interfere with each other. Debugging and resolving such issues can be time-consuming and complex. By using the right design patterns, we can maintain a readable codebase while mitigating these issues and still achieving the required performance.\n\nIn this post, I will present several different patterns that can be utilized for high-performance systems. With these patterns, we will reduce latency and utilize resources more efficiently, such as CPU, memory, and I/O. For a better understanding of computer resources, you can read an [introduction to computer architecture](https://www.biosconfessions.com/posts/introduction-computer-architecture/). To choose the right pattern, it is crucial to understand the specific bottlenecks of your system. For instance, if your system&#39;s primary challenge is I/O-bound operations, the Reactor pattern can be beneficial as it efficiently handles multiple concurrent requests. On the other hand, if the bottleneck is computational, patterns focusing on concurrency, like the Actor model, might be more suitable. Thus, determining whether you are optimizing the code for compute, data, networking, or concurrency is the key to selecting the most effective design pattern.\n\n## Why patterns matter for high-performance systems\n\nDesign patterns enforce structure and best practices, allowing for better code quality and maintainability. Even in high-performance systems, it&#39;s still important to have maintainable and quality code. When building a system optimized for speed, complexity, and readability can quickly spiral out of control. Luckily, there are also patterns that enable us to reason about and build quality, maintainable code. By combining the right patterns, we can build a high-performance system and keep some sanity in our code.\n\n## Concurrency and I/O patterns\n\nLet&#39;s first discuss patterns for Concurrency and I/O. These patterns will help us to structure multi-threaded and asynchronous code. We will discuss three popular patterns used in industry to solve these issues.\n\n### Reactor pattern\n\nThe reactor pattern is an event-driven design with a single-threaded event loop that demultiplexes I/O events and dispatches them to handlers. By using non-blocking I/O, a reactor can handle many concurrent I/O-bound requests with minimal threads and low latency. This pattern is widely used in high-performance servers and networking frameworks because it avoids the overhead of blocking threads or one-thread-per-connection models.\n\n### Actor model\n\nThis pattern treats each concurrent entity as an *actor* with its own private state, processing incoming messages one at a time. Actors communicate only via asynchronous message passing, eliminating the need for locks or shared-memory synchronization. Actors are extremely lightweight (far lighter than OS threads) and can be spawned in large numbers, allowing millions of actors to run concurrently. This leads to low-latency, high-throughput processing, as each actor handles its tasks independently.\n\n### Fan out / Fan in\n\nThe Fan out / Fan in pattern distributes workloads to multiple parallel workers (“fan-out”) and then aggregates their results (“fan-in”). A large computation can be split into many subtasks that run concurrently on multiple threads or machines; once all tasks complete, their partial results are combined. This pattern efficiently scales out computation across multicore CPUs or distributed systems. By parallelizing independent work, it can drastically reduce total processing time.\n\n## Data Access and Memory Optimization\n\nWhen writing high-performance systems, it&#39;s important to efficiently handle reading, writing, and managing data. This could be handling data from a database, a file, or a remote API. In this section, we will discuss patterns that help us separate data logic from business logic. Making data operations consistent and reusable, and supporting multiple data sources without rewriting core logic.\n\n### Cache-Aside pattern\n\nThe cash-Aside pattern lets an application explicitly check an external cache before the primary data store. On a cache miss, it loads the data from the datastore and populates the cache. This lazy-loading strategy means frequently accessed data is served from fast memory rather than slower databases. As a result, repeated reads of the same data have much lower latency, and overall throughput improves, since the database sees fewer queries.\n\n### Sharding pattern\n\nThe Sharing pattern enables the horizontal partitioning of a dataset across multiple database instances (shards) to improve performance. By splitting data (for example, by key range or hash) into separate shards, each shard handles only a subset of the workload, reducing contention and enabling parallel queries. Sharding boosts throughput and also enhances availability: a failure or maintenance on one shard affects only that partition, not the entire dataset.\n\n### Zero-Copy and Memory-Mapped files\n\nThe Zero-Copy and Memory-Mapped file pattern uses techniques to eliminate extra data copying between the user space and kernel. Zero-copy I/O lets devices transfer data directly between kernel and user memory without CPU intervention. Memory-mapped files (mmap) puts the content into the process’s address space, so after the initial mapping, reads and writes go straight to RAM without an extra copy or system calls. In effect, the file data becomes part of memory, dramatically speeding up file and network I/O for large transfers.\n\n## Resilience and Stability\n\nAny high-performance system should be resilient and fault-tolerant. For high-performance systems to be useful, we need to make sure they&#39;re consistent and predictable under high workloads. When the system is fast, when everything is perfect, but it crashes in the real world, it is not truly high performance. Therefore, in this section, we will discuss some patterns that can help to have a stable and reliable system while still being high-performance.\n\n### Circuit breaker\n\nThe circuit breaker pattern wraps calls to an external service and trips (opens) if failures exceed a threshold. When open, calls fail immediately instead of waiting on timeouts or retry loops. This prevents resource exhaustion (threads, connections) from constantly retrying a dead service, giving the system time to recover. In short, a circuit breaker preserves stability by failing fast on unhealthy dependencies.\n\n### Bulkhead pattern\n\nWith the bulkhead pattern, we can isolate components or consumers into separate pools so that a failure in one does not bring down others. Like compartments in a ship, this means partitioning services or resources (for example, with dedicated thread pools or separate processes). If one partition fails or overloads, it does not deplete shared resources, and the rest of the system can continue operating. Bulkheads confine failures, preventing cascading outages across the entire system\n\n### Load sheading\n\nThe load-shading pattern intentionally drops or delays lower-priority requests when the load is too high. Rather than letting queues grow and latencies spike to the point of collapse, the system sheds excess work to stay responsive. For example, a server might reject additional requests once CPU or memory utilization crosses a threshold. This trade-off sacrifices some non-critical throughput to guarantee that high-priority tasks still meet latency targets.\n\n## Next steps\n\nThe right design patterns are a powerful tool for building high-performance systems in a maintainable way. When used correctly, these patterns will make our code more maintainable, scalable, and improve code quality. In practice, we first need to identify our system&#39;s bottlenecks before choosing the right pattern. Once you know these bottlenecks, you can apply the right pattern and address them. For example, choose the reactor pattern if your application has I/O heavy services, or integrate cash-aside and sharding to speed up data access. As you apply these patterns, continuously monitor the effects of the changes. Watch the latency and throughput, and adjust the time-out and load-shedding thresholds as needed. With careful testing and incremental adoption, you can dramatically improve performance while preserving code quality and maintainability.&quot;],&quot;filePath&quot;:[0,&quot;src/content/posts/the-tough-love-architecture-guide/3-what-actually-works-in-high-performance systems.mdx&quot;],&quot;assetImports&quot;:[1,[[0,&quot;./assets/BannerHighPerformance.jpg&quot;]]],&quot;digest&quot;:[0,&quot;d88b5ccf1d64fce5&quot;],&quot;deferredRender&quot;:[0,true],&quot;collection&quot;:[0,&quot;posts&quot;],&quot;slug&quot;:[0,&quot;the-tough-love-architecture-guide/3-what-actually-works-in-high-performance-systems&quot;],&quot;render&quot;:[0,null]}],[0,{&quot;id&quot;:[0,&quot;hello-world/hello-world-asm.mdx&quot;],&quot;data&quot;:[0,{&quot;author&quot;:[0,&quot;Gianni&quot;],&quot;title&quot;:[0,&quot;Hello World in x86 Assembly: Step-by-Step Guide&quot;],&quot;date&quot;:[3,&quot;2025-10-19T00:00:00.000Z&quot;],&quot;tags&quot;:[1,[[0,&quot;Programming&quot;]]],&quot;metaTags&quot;:[1,[[0,&quot;assembly tutorial&quot;],[0,&quot;x86 assembly&quot;],[0,&quot;nasm hello world&quot;],[0,&quot;linux assembly programming&quot;],[0,&quot;docker development environment&quot;],[0,&quot;low-level programming&quot;],[0,&quot;system calls tutorial&quot;],[0,&quot;assembly language basics&quot;],[0,&quot;learn assembly&quot;],[0,&quot;programming optimization&quot;],[0,&quot;hello world in assembly&quot;],[0,&quot;nasm guide&quot;],[0,&quot;docker for developers&quot;]]],&quot;difficulty&quot;:[0,&quot;Intermediate&quot;],&quot;readTime&quot;:[0,&quot;10 min&quot;],&quot;image&quot;:[0,{&quot;src&quot;:[0,&quot;/assets/whale-behind-a-desk-with-containers.DX4KWUkX.png&quot;],&quot;width&quot;:[0,1024],&quot;height&quot;:[0,1024],&quot;format&quot;:[0,&quot;png&quot;]}],&quot;alt&quot;:[0,&quot;Whale behind a desk with containers&quot;],&quot;description&quot;:[0,&quot;Learn how to write and run a classic “Hello, World!” program in pure x86 assembly, step by step, using Docker for a clean and portable setup.&quot;]}],&quot;body&quot;:[0,&quot;We’ve all seen the classic *“Hello, World!”* programs. But let’s be honest, you’re not a true Giga Chad until you’ve written one in **pure assembly**.\n\n## Why?\n\nYou might be asking yourself: *Why on earth would anyone learn assembly when high-level languages exist to make life easier?* The truth is, there are situations outside of programming a [space probe](https://science.nasa.gov/mission/voyager/frequently-asked-questions/) where assembly is still relevant. For example, imagine you’re working on a collision detection system for a self-driving car. In that scenario, every microsecond matters. You want to squeeze out every drop of performance to avoid disaster. Of course, this doesn’t mean writing the entire system in assembly. In practice, you’d only optimise the performance-critical parts, while leaving the rest in a higher-level language. And knowing how things work under the hood is always valuable\n\n## Environment\n\nBefore we start coding, we need to set up a proper environment. Let’s create a project directory. Throughout this tutorial, we’ll call it `hello-world-asm`.  To make sure our code runs anywhere (not just on my machine), we’ll use a Docker container with all the necessary tools for building and running assembly. If you don’t already have [Docker Desktop](https://www.docker.com/products/docker-desktop/) installed, go ahead and do that first. For your editor/IDE, feel free to use whatever you like; it doesn’t really matter. In this tutorial, I’ll be using [Visual Studio Code](https://code.visualstudio.com/Download), but it’s not a requirement.\n\n### Container\n\nInside your `hello-world-asm` directory, create a file named `Dockerfile`:\n\n```docker\nFROM ubuntu:latest\n\n# Build-time variable for noninteractive installs\nARG DEBIAN_FRONTEND=noninteractive\n\n# Install only the essentials for x86_64 assembly\nRUN apt update &amp;&amp; apt upgrade -y &amp;&amp; \\\n    apt install -y --no-install-recommends \\\n    build-essential \\\n    gdb \\\n    nasm &amp;&amp; \\\n    rm -rf /var/lib/apt/lists/*\n\n# Create non-root user \&quot;dev\&quot;\nRUN useradd -m -s /bin/bash dev &amp;&amp; \\\n    echo \&quot;dev ALL=(ALL) NOPASSWD: ALL\&quot; &gt;&gt; /etc/sudoers\n\nUSER dev\nWORKDIR /home/dev\n```\n\nLet’s break down what we just set up:\n\n- **Base image:** We start with `ubuntu:latest`, giving us a clean Linux environment.\n- **Non-interactive installs:** The `DEBIAN_FRONTEND=noninteractive` variable ensures `apt` doesn’t get stuck asking us questions.\n- **Install essentials:** We pull in just the tools we need for x86_64 assembly programming:\n    - `build-essential` → compiler, linker, common build tools (handy for your C/C++ projects too)\n    - `gdb` → the GNU Debugger, so we can step through our assembly code.\n    - `nasm` → the Netwide Assembler, the tool we use to assemble and link our `.asm` files.\n- **Non-root user:** We add a new user `dev`, so we don’t run everything as root (a good security practice).\n- **Working directory:** Finally, we set the container to drop us into `/home/dev`, which is where we’ll link our project directory to later.\n\n### Helper Script\n\nTyping Docker commands over and over can be a pain. To make life easier, let’s create a shell script to automate container management. Inside your `hello-world-asm` directory, create a file named `docker.sh` with the following content:\n\n```bash\n#!/bin/bash\n\nIMAGE_NAME=\&quot;dev-env\&quot;\nCONTAINER_NAME=\&quot;dev-env-container\&quot;\nCONTAINER_ENTRY=\&quot;/usr/bin/bash\&quot;\nWORK_DIR=\&quot;/home/dev/hello-world-asm\&quot;\n\nPROJECT_ROOT=\&quot;$(pwd)\&quot;\n\nfunction container_stop() {\n\tsudo docker stop $CONTAINER_NAME || echo \&quot;container already stopped\&quot;\n}\n\nfunction clean() {\n\tcontainer_stop\n\tsudo docker rm $CONTAINER_NAME || echo \&quot;container already removed\&quot;\n\tsudo docker image rm $IMAGE_NAME  || echo \&quot;image already removed\&quot;\n}\n\nfunction container_start() {\n\tif [ -z \&quot;$(sudo docker ps -a | grep $CONTAINER_NAME)\&quot; ]; then\n\t\techo \&quot;&gt;&gt; creating dev container\&quot;\n\n\t\tsudo docker run -w $WORK_DIR --hostname dev -it --name $CONTAINER_NAME \\\n\t\t\t--net=host \\\n\t\t\t--cap-add=SYS_PTRACE --security-opt seccomp=unconfined \\\n\t\t\t-v $PROJECT_ROOT:$WORK_DIR:z \\\n\t\t\t$IMAGE_NAME $CONTAINER_ENTRY\n\n\telse\n\t\techo \&quot;&gt;&gt; found existing dev container\&quot;\n\t\tsudo docker start $CONTAINER_NAME\n\t\tsudo docker exec -it $CONTAINER_NAME $CONTAINER_ENTRY\n\tfi\n}\n\nfunction image_build() {\n\tif [ -z \&quot;$(sudo docker images | grep $IMAGE_NAME)\&quot; ]; then\n\t\techo \&quot;&gt;&gt; building image: $IMAGE_NAME\&quot;\n\t\tsudo docker build -t $IMAGE_NAME ./\n\tfi\n}\n\nfunction print_usage() {\n\techo \&quot;Usage: ./docker.sh [container-start | container-stop | image-build | clean]\&quot;\n}\n\nfunction main() {\n\tif ! command -v docker &gt;/dev/null 2&gt;&amp;1; then\n\t\techo \&quot;Could not find docker. Please install it https://docs.docker.com/engine/install/\&quot;\n\t\texit 1\n\tfi\n\n\tcase \&quot;$1\&quot; in\n\t  container-start) container_start ;;\n\t  container-stop)  container_stop ;;\n\t  image-build)     image_build ;;\n\t  clean)           clean ;;\n\t  *)               print_usage ;;\n\tesac\n}\n\nmain $@\n```\n\nWhat this script does:\n\n- **`image-build`** Builds our Docker image from the `Dockerfile`.\n- **`container-start`** Starts a new container (or reuses an existing one) and drops you into a shell.\n- **`container-stop`** Stops the running container.\n- **`clean`** Removes the container and image, so you can start fresh.\n\nIn short, it hides the long Docker commands and gives you a simple interface.\n\n### First Run\n\nBefore we can use our container, we need to build the image. In your terminal (for Windows users, PowerShell works best), run:\n\n```bash\nsh docker.sh image-build   # Linux/macOS\nbash docker.sh image-build # Windows (PowerShell)\n```\n\nThen start the container with:\n\n```bash\nsh docker.sh container-start   # Linux/macOS\nbash docker.sh container-start # Windows (PowerShell)\n```\n\nThis will provide you with terminal access within your development environment. From here, we’re ready to write some assembly.\n\n## Assembly File Structure\n\nBefore we dive into coding, it’s important to understand how an assembly file is usually organized. Most assembly programs are divided into **sections**, each with a specific purpose. The exact details vary depending on the assembler and platform, but the structure is broadly similar everywhere.\n\nHere are the most common sections:\n\n- **`.data`** Holds variables and constants that are **initialised** when the program starts. For example, your “Hello, World!” string belongs here.\n- **`.bss`** Holds **uninitialised variables** (they start as zero by default). Think of this as a workspace where you can reserve space for data you’ll fill in later.\n- **`.text`** Contains the actual **instructions** of the program. This is where the CPU starts executing. The program’s entry point (often called `_start` on Linux or `main` in higher-level conventions) is defined in this section.\n\nA Simple Mental Model:\n\n- `.data` → “What I already know.”\n- `.bss` → “What I’ll figure out later.”\n- `.text` → “What I need to do.”\n\nFor our *Hello, World!* program, we only need two sections:\n\n- `.data` to store the message\n- `.text` to hold the instructions that display it\n\n## Writing Our First Assembly Program\n\nLet’s start building our first program! Inside your project directory, create a new file named `hello.asm`.\n\nThe first step is to set up the sections of our program. As we learned earlier, we’ll need:\n\n- a **`.data`** section for our message\n- a **`.text`** section for the instructions that display it.\n\nWe can declare these sections with the `section` keyword:\n\n```asm\nsection .data                           ; Create the data section\nsection .text                           ; Create the text section\n```\n\n### Adding Data\n\nOur program needs just two pieces of data:\n\n1. the **message** we want to print, and\n2. the **length** of that message.\n\nBecause this program is simple, we don’t need any dynamic memory management. We can store everything directly in the `.data` section. To define the message, we’ll use the assembler directive `db` (*define byte*). This instructs the assembler to allocate memory space and fill it with the values we provide. In this case, that’s the string `\&quot;Hello, World!\&quot;` followed by `0x0A`, which represents the newline character (`&#39;\\n&#39;`).\n\n```asm\n\nsection .data                           ; Create the data section\n    msg     db  \&quot;Hello, World!\&quot;, 0x0A   ; Our message plus a newline (0x0A = &#39;\\n&#39;)\n    \nsection .text                           ; Create the text section\n```\n\nNow we also need the **length of the message**. We can compute it automatically using the `equ` directive (*equate*). Unlike `db`, `equ` does not allocate memory. Instead, it defines a constant value that the assembler substitutes wherever the label is used. To get the length, we subtract the address of the beginning of the message (`msg`) from the current location counter (`$`). The symbol `$` always refers to the assembler’s current position, which in this case is right after the message we just defined.\n\n```asm\nsection .data                           ; Create the data section\n    msg     db  \&quot;Hello, World!\&quot;, 0x0A   ; Our message plus a newline (0x0A = &#39;\\n&#39;)\n    len     equ $ - msg                 ; Define a constant len with the message length\n    \nsection .text                           ; Create the text section\n```\n\n### Writing the Code\n\nNow that our data is defined, it’s time to write the actual instructions in the **`.text`** section. This is where the CPU will start executing our program. Every program needs an **entry point**, ****a place where execution begins. In Linux assembly, this is usually the label `_start`. We’ll declare it as a global symbol so the linker knows where to begin:\n\n```asm\nsection .data                           ; Create the data section\n    msg     db  \&quot;Hello, World!\&quot;, 0x0A   ; Our message plus a newline (0x0A = &#39;\\n&#39;)\n    len     equ $ - msg                 ; Define a constant len with the message length\n\nsection .text                           ; Create the text section\n    global _start                       ; Tell the linker the entry point is _start\n\n_start:                                 ; Entry point of our program\n```\n\nTo display text on the screen, we need to ask the operating system for help. In Linux, this is done using a **system call**. A system call is like raising your hand and asking the OS: “Hey, can you do this for me?” We’ll use the `write` system call, which has this signature:\n\n```c\nwrite(fd, buf, count)\n```\n\n- `fd` = file descriptor (1 means standard output, the terminal).\n- `buf` = address of the data to write (our `msg`).\n- `count` = number of bytes to write (our `len`).\n\nIn x86-64 Linux, [system calls](https://blog.rchapman.org/posts/Linux_System_Call_Table_for_x86_64/) are made by:\n\n1. putting the syscall number into the `rax` register,\n2. putting the arguments into registers (`rdi`, `rsi`, `rdx`, …), and\n3. executing the instruction `syscall`.\n\nThe syscall number for `write` is **1**.\n\nHere’s how we set up and call `write`:\n\n```asm\nmov     rax, 1                      ; Syscall number for write\nmov     rdi, 1                      ; File descriptor 1 = stdout\nmov     rsi, msg                    ; Address of the string\nmov     rdx, len                    ; Length of the string\nsyscall                             ; Invoke the system call\n```\n\nAfter printing the message, the program still needs to exit cleanly. That’s another syscall: `exit`.\n\n- The syscall number for `exit` is **60**.\n- Its only argument is the exit code (0 means success).\n\n```asm\nmov     rax, 60                     ; syscall number for exit\nxor     rdi, rdi                    ; exit code 0 (using xor to set rdi = 0)\nsyscall                             ; Invoke the system call\n```\n\nHere’s the full `hello.asm` so far:\n\n```asm\nsection .data                           ; Create the data section\n    msg     db  \&quot;Hello, World!\&quot;, 0x0A   ; Our message plus a newline (0x0A = &#39;\\n&#39;)\n    len     equ $ - msg                 ; Define a constant len with the message length\n\nsection .text                           ; Create the text section\n    global _start                       ; Tell the linker the entry point is _start\n\n_start:                                 ; Entry point of our program\n    ; write(fd1, msg, len)\n    mov     rax, 1                      ; Syscall number for write\n    mov     rdi, 1                      ; File descriptor 1 = stdout\n    mov     rsi, msg                    ; Address of the string\n    mov     rdx, len                    ; Length of the string\n    syscall                             ; Invoke the system call\n\n    ; exit(0)\n    mov     rax, 60                     ; syscall number for exit\n    xor     rdi, rdi                    ; exit code 0 (using xor to set rdi = 0)\n    syscall                             ; Invoke the system call\n```\n\n## Assembling, Linking, and Running\n\nWe’ve written our `hello.asm` file, now it’s time to bring it to life! The process has three steps:\n\n1. **Assemble:** convert the human-readable assembly into machine code (`.o` file).\n2. **Link:** package that machine code into a proper executable (`hello`).\n3. **Run:** execute it and see the magic happen.\n\n### Option 0: Use `make` (recommended)\n\nSince we installed `make` in our container, we can automate these steps with a **Makefile**. Inside your project folder, create a file named `Makefile`:\n\n```makefile\nall: hello\n\nhello: hello.o\n\tld hello.o -o hello\n\nhello.o: hello.asm\n\tnasm -f elf64 hello.asm -o hello.o\n\nclean:\n\trm -f hello hello.o\n```\n\nNow you can build your program with a single command:\n\n```bash\nmake\n```\n\nAnd when you want to clean up all build artefacts:\n\n```bash\nmake clean\n\n```\n\n### Step 1: Assemble\n\nManually, the first step is turning your source code into an **object file**:\n\n```bash\nnasm -f elf64 hello.asm -o hello.o\n```\n\n- `f elf64` → tells NASM to generate 64-bit ELF output (Linux’s standard format).\n- `hello.asm` → your assembly source file.\n- `o hello.o` → output file (`.o` = object file).\n\n### Step 2: Link\n\nNext, we use the GNU linker `ld` to create an **executable** from the object file:\n\n```bash\nld hello.o -o hello\n\n```\n\n- `hello.o` → the object file we just created.\n- `o hello` → the name of the final executable.\n\n### Step 3: Run\n\nNow execute your program:\n\n```bash\n./hello\n```\n\nYou should see:\n\n```\nHello, World!\n```\n\nCongratulations, you’ve just written, built, and executed your first **Hello World in pure x86 assembly**!&quot;],&quot;filePath&quot;:[0,&quot;src/content/posts/hello-world/hello-world-asm.mdx&quot;],&quot;assetImports&quot;:[1,[[0,&quot;./assets/whale-behind-a-desk-with-containers.png&quot;]]],&quot;digest&quot;:[0,&quot;2951034714e2f7e6&quot;],&quot;deferredRender&quot;:[0,true],&quot;collection&quot;:[0,&quot;posts&quot;],&quot;slug&quot;:[0,&quot;hello-world/hello-world-asm&quot;],&quot;render&quot;:[0,null]}],[0,{&quot;id&quot;:[0,&quot;finding-p-values-and-false-hope/2-loans.mdx&quot;],&quot;data&quot;:[0,{&quot;author&quot;:[0,&quot;Quinn&quot;],&quot;collection&quot;:[0,&quot;Finding P values and false hope&quot;],&quot;chapter&quot;:[0,2],&quot;title&quot;:[0,&quot;Loans and Bonds Explained: How Borrowing, Interest, and Default Risk Really Work&quot;],&quot;shortname&quot;:[0,&quot;Loans&quot;],&quot;date&quot;:[3,&quot;2025-12-07T00:00:00.000Z&quot;],&quot;tags&quot;:[1,[[0,&quot;Data Science&quot;]]],&quot;metaTags&quot;:[1,[[0,&quot;how loans work&quot;],[0,&quot;loan payment formula&quot;],[0,&quot;amortization explained&quot;],[0,&quot;bond pricing basics&quot;],[0,&quot;coupon rate calculation&quot;],[0,&quot;default risk modeling&quot;],[0,&quot;quant finance introduction&quot;],[0,&quot;loan vs bond explained&quot;]]],&quot;difficulty&quot;:[0,&quot;Intermediate&quot;],&quot;readTime&quot;:[0,&quot;12 min&quot;],&quot;image&quot;:[0,{&quot;src&quot;:[0,&quot;/assets/loans-and-bonds-explained.cwsEEMkV.png&quot;],&quot;width&quot;:[0,1344],&quot;height&quot;:[0,768],&quot;format&quot;:[0,&quot;png&quot;]}],&quot;alt&quot;:[0,&quot;Illustration explaining how loans and bonds work, including interest, repayment, and default risk&quot;],&quot;description&quot;:[0,&quot;A clear introduction to how loans work, how lenders price interest, and how these concepts extend to bonds, coupon rates, and default risk—complete with formulas and simulations.&quot;]}],&quot;body&quot;:[0,&quot;Imagine a young couple, Sara and Tom, who have been dreaming of owning their first home. With a small savings account and a lot of determination, they finally step into a bank to discuss a mortgage loan. This moment marks a significant turning point in their lives, as the financial leverage they gain through the loan will enable them to move into their dream house, a place where they will raise their family. Financial loans sit at the core of how modern economies work. Whether it&#39;s a family buying a house, a company expanding its operations, or the government funding a public project, loans provide the upfront capital needed to make things happen. Yet, while most people understand the idea of borrowing and paying back with interest, the broader mechanics behind loans and how they evolve into more complex financial instruments are far less understood. In this post, we will start breaking down what a loan really is and how lenders manage the risk of loaning money. From there, we will work towards understanding bonds, which can be seen as loans packaged, traded, and scaled for markets. By understanding these concepts, we are building the right mental framework to start working with more complicated financial instruments.\r\n\r\n# Loans\r\n\r\nIn its essence, a loan is pretty simple: we borrow some money and pay it back over time. We can analyze the repayment of the money pretty easily. For example, we take a mortgage of $€300,000$ and plan to repay it in $300$equal monthly payments with an interest rate of $0.5\\%$ per month.\r\n\r\nMost of us can probably quantify how much we need to pay each month by using our intuition. The lowerbound of our monthly payment would be $€300,000 * 0.5\\% = €1500$ since this is the amount we would pay each month in interest. The upper bound of our payment would be $€1500 + \\frac{€300,000}{300} = €2500$, since this would cover the entire loan, including interest compounded over the full amount.\r\n\r\nBut what if we can estimate the monthly share of the principal at $€1000$ plus an interest of $€750$. We can calculate this interest by dividing $€1500$ by 2 since the interest would vanish over time. With this, our monthly payment would be $€1750$. But is it fair to assume this as our monthly payment? Let&#39;s try to calculate it.\r\n\r\n```python\r\ndef loan_payment(X, r, N):\r\n    \&quot;\&quot;\&quot;\r\n    Compute the fixed payment amount A for a loan.\r\n    X: initial loan amount\r\n    r: interest rate per period (e.g., 0.05 for 5%)\r\n    N: number of payments\r\n    \&quot;\&quot;\&quot;\r\n    if r == 0:\r\n        return X / N\r\n    return X * (r * (1 + r)**N) / ((1 + r)**N - 1)\r\n\r\ndef simulate_loan(X, r, N):\r\n    \&quot;\&quot;\&quot;\r\n    Simulate the loan balance D_k using the difference equation.\r\n    \&quot;\&quot;\&quot;\r\n    A = loan_payment(X, r, N)\r\n    D = [X]  # D_0 = X\r\n\r\n    for k in range(N):\r\n        D_next = (1 + r) * D[-1] - A\r\n        D.append(D_next)\r\n\r\n    return A, D\r\n\r\ndef main():\r\n    # Parameters\r\n    X = 300000.0   # initial amount borrowed\r\n    annual_rate = 0.06\r\n    payments_per_year = 12\r\n    years = 5\r\n\r\n    # Convert to rate per period and number of periods\r\n    r = annual_rate / payments_per_year\r\n    N = payments_per_year * years\r\n\r\n    A, D = simulate_loan(X, r, N)\r\n\r\n    print(f\&quot;Loan amount (X): {X:,.2f}\&quot;)\r\n    print(f\&quot;Interest rate per period (r): {r:.6f}\&quot;)\r\n    print(f\&quot;Number of payments (N): {N}\&quot;)\r\n    print(f\&quot;Payment per period (A): {A:,.2f}\\n\&quot;)\r\n\r\n    print(\&quot;k\\tOutstanding Balance (D_k)\&quot;)\r\n    for k, balance in enumerate(D):\r\n        print(f\&quot;{k}\\t{balance:,.2f}\&quot;)\r\n\r\nif __name__ == \&quot;__main__\&quot;:\r\n    main()\r\n\r\n```\r\n\r\nThis will output:\r\n\r\n```java\r\nLoan amount (X): 300000.00\r\nInterest rate per period (r): 0.004167\r\nNumber of payments (N): 300\r\nPayment per period (A): 1753.77\r\n\r\nk    Outstanding Balance (D_k)\r\n0    300000.00\r\n1    299496.23\r\n2    298990.36\r\n3    298482.38\r\n4    297972.29\r\n....\r\n298  3485.74\r\n299  1746.49\r\n300  0.00\r\n```\r\n\r\nAccording to this script, our monthly payments would be €1753.77. We got to this amount by first establishing the value of $€X$ (the amount borrowed). We will pay this back by paying $€A$ at time $N + \\Delta T$ ***,*** then at time $N + 2 \\Delta T$, and so on, ******until we reach time $N \\Delta T$***,*** at which point we owe no money. Let $D_{k}$ be the amount we owe at the $K_{th}$ payment. We know that $D_{0} = €X$ and $D_{N} = 0$, so we need to solve a difference equation. So to summarize:\r\n\r\n| Symbol | Meaning | Units |\r\n| --- | --- | --- |\r\n| $D_{k}$  | amount we owe at the $K_{th}$ payment | Currency |\r\n| $A$  | Payment per period | Currency |\r\n| $N$ | Number of payments |  |\r\n| $\\Delta T$ | Time between payments | Time |\r\n| $r$ | Interest rate per period |  |\r\n| $N$ | Principal (amount borrowed at time *t*) | Currency |\r\n\r\nWe can look at what happens between two consecutive payments. At the start of period $k$ you owe $D_{k}$. So during the next time interval $\\Delta T$:\r\n\r\n- The loan accrues interest at rate $r$, so it grows to $D_k(1+r)$.\r\n- Then you make a payment $A$, reducing your balance.\r\n\r\nThus the amount owed after the next payment (just after $(k+1) \\Delta T$ ) is:\r\n\r\n$$\r\nD_{k+1} = (1+r) D_k - A\r\n$$\r\n\r\nNow we need to find a closed form for $D_k$ which is a non-homogeneous linear recurrence relation. We know the boundary conditions of our scenario. The initial condition is us owing the full loan at $D_0=X$, and the final condition is us owing noting after $N$ payments at $D_N=0$. Knowing this we can solve for $A$:\r\n\r\n$$\r\n0 = (1 + r)^N X - A \\frac{(1 + r)^{N}-1}{r} \r\n$$\r\n\r\nSo,\r\n\r\n$$\r\nA = X \\frac{r(1+r)^N}{(1+r)^N-1}\r\n$$\r\n\r\nGiven the fixed payment per period we will have completely repaid the loan of amount $X$ after $N$ equal payments. \r\n\r\n# Bonds\r\n\r\nIf loans are the backbone of personal and corporate finance, then bonds are their large-scale, institutional counterpart. While a loan typically involves direct agreements between a borrower and a lender, bonds take that same idea and expand it to the financial markets. In this section, we will explore what bonds are, how they function, and why they are so important for funding governments and corporations. Understanding bonds will be an important part of our ability to understand and build more complex quantitative financial models. \r\n\r\nSimply put, a bond is a loan that is sold to an investor. Bonds have many interesting quantitative features; for example, their values fluctuate with interest rates, and they often contain embedded options that allow them to be repaid or called back. Sometimes bonds are issued in a foreign currency to investors, introducing foreign exchange risk. While these are all interesting, the most important risk we need to determine is whether the lender can repay the borrowed money.  \r\n\r\nWe can start with unraffling a simple bond for which the borrower receives $€X$. In exchange, the borrower will repay $€X(1+c)$ at time $T$**,** where $c$ ****is the coupon rate and $T$ ****is ****the bond&#39;s term. An important question we should ask here is: what is a fair value for $c$? How much should we be compensated for borrowing our money? To find the value of $c$**,** we first need to know the risk-free rate **r**. The risk-free rate is the rate that theoretically entails no financial risk, meaning the borrower is certain to repay the loan. Think of the risk-free rate as the minimum expected return on your investment. When making any investment, our expected return should exceed the risk-free rate. If this is not the case, you can not justify the risk you are taking. In a perfect world, we could even say that a fair value for $c=r$.\r\n\r\nTo find a fair value for $c$**,** we need to quantify the bond default rate. A simple model assumes that at time $T$**,** the bond either defaults or is repaid in full. When the bond defaults, we assume the investor will lose some value $R$ of their entire investment. So, with probability $p$**,** the bondholder receives $RX(1+c)$ at time $T$, and with probability $1-p$**,** they receive $X(c+1)$ at time $T$. We can say a fair rate for **c is** when the investor, on average, gets back their principal, adjusted for the time value of money. The lender must also charge a large enough coupon so that they do no worse than lending at the risk-free rate. This can be computed as follows:\r\n\r\n$$\r\npRX(1+c)+(1-p)X(1+c) \\geq X(1+r)\r\n$$\r\n\r\nOr,\r\n\r\n$$\r\npR(1+c)+(1-p)(1+c) \\geq (1+r)\r\n$$\r\n\r\nOr even simpler:\r\n\r\n$$\r\nc_{fair} = \\frac{r+p(1-R)}{1-p(1-R)}\r\n$$\r\n\r\nGiven this formula, a lender will, on average, break even after accounting for the time value of money and the risk of default. But which investor will take this risk to just break even? Many investors will ask for a far greater coupon to justify their risk and increase the chance of making some money. The difference between the fair coupon and the actual coupon is often determined during negotiations between the lender and borrower. \r\n\r\nInstead of increasing the coupon, we can also reduce our risk by finding many different borrowers, each with an independent chance of defaulting. Let me give you a one-sentence roadmap of the upcoming simulation: we will explore how varying default outcomes across ten distinct loans affects our risk profile. Let&#39;s run a simple simulation to see how our risk changes. We will work with the following fixed parameters:\r\n\r\n| **Param** | **Value** |\r\n| --- | --- |\r\n| X | €1000 |\r\n| r | 3% |\r\n| p | 5% |\r\n| R | 0 |\r\n\r\n```python\r\nimport random\r\nimport math\r\n\r\ndef main():\r\n    trials = 100\r\n    num_loans = 10\r\n    X = 1000.0\r\n    r = 0.03\r\n    p = 0.05\r\n    R = 0.0\r\n\r\n    # Coupon rate\r\n    c = (r + p * (1 - R)) / (1 - p * (1 - R))\r\n\r\n    returns = []\r\n\r\n    for _ in range(trials):\r\n        portfolio_return = 0.0\r\n\r\n        for _ in range(num_loans):\r\n            defaults = random.random() &lt; p  # Bernoulli(p)\r\n\r\n            if defaults:\r\n                portfolio_return += 0.0\r\n            else:\r\n                portfolio_return += X * (1.0 + c)\r\n\r\n        total_initial = num_loans * X\r\n        yearly_return = (portfolio_return - total_initial) / total_initial\r\n        returns.append(yearly_return)\r\n\r\n    # Statistics\r\n    mean = sum(returns) / trials\r\n    best = max(returns)\r\n    worst = min(returns)\r\n\r\n    variance = sum((r - mean) ** 2 for r in returns) / trials\r\n    stddev = math.sqrt(variance)\r\n\r\n    # Output\r\n    print(f\&quot;Bond Portfolio Simulation Results after {trials} trials with coupon: {c * 100:.2f}%\&quot;)\r\n    print(\&quot;--------------------------------------------\&quot;)\r\n    print(f\&quot;Average return:      {mean * 100:.2f} %\&quot;)\r\n    print(f\&quot;Best-case return:    {best * 100:.2f} %\&quot;)\r\n    print(f\&quot;Worst-case return:   {worst * 100:.2f} %\&quot;)\r\n    print(f\&quot;Standard deviation:  {stddev * 100:.2f} %\&quot;)\r\n\r\nif __name__ == \&quot;__main__\&quot;:\r\n    main()\r\n```\r\n\r\nThis will output:\r\n\r\n```\r\nBond Portfolio Simulation Results after 100 trials with coupon: 8.42105%\r\n--------------------------------------------\r\nAverage return:      3.75895 %\r\nBest-case return:    8.42105 %\r\nWorst-case return:   -24.1053 %\r\nStandard deviation:  7.55143 %\r\n```\r\n\r\nFrom this result, we can see that, on average, our return exceeds the risk-free rate, but not by much. Considering that if we had one lender, our potential worst-case scenario would be 100% loss. Having 10 different lenders has changed this to a worst-case loss of only -24%. However, this setup invites us to reflect on additional risk-mitigation strategies. How might tools like collateral or credit default swaps provide extra layers of protection against worst-case outcomes? Incorporating such alternatives could further enhance our ability to manage financial risk and potentially reduce it.\r\n\r\n# Closing thoughts\r\n\r\nLoans and bonds may look like everyday financial tools, but beneath the surface, they are built on clear mathematical structures and carefully managed risk. By breaking down how a simple loan works, how payments are determined, and how interest shapes repayment over time, we lay the foundations for understanding larger, more complex financial instruments.\r\n\r\nBonds follow the same principle as a loan, but scale it to markets. Their pricing depends on many factors, some of which we discussed, such as credit risk, recovery assumptions, and exposure diversification across many borrowers. As the simulation showed, spreading risk across a portfolio of independent loans dramatically reduces the worst-case outcomes, illustrating why diversification is central to modern finance.\r\n\r\nUltimately, understanding loans and bonds gives us more than just the ability to calculate payments or yields. It builds the mental framework needed to navigate the financial system as a whole. With this foundation, we can start exploring some more complex financial instruments.&quot;],&quot;filePath&quot;:[0,&quot;src/content/posts/finding-p-values-and-false-hope/2-loans.mdx&quot;],&quot;assetImports&quot;:[1,[[0,&quot;./assets/loans-and-bonds-explained.png&quot;]]],&quot;digest&quot;:[0,&quot;ae7f9df24bfb0c6d&quot;],&quot;deferredRender&quot;:[0,true],&quot;collection&quot;:[0,&quot;posts&quot;],&quot;slug&quot;:[0,&quot;finding-p-values-and-false-hope/2-loans&quot;],&quot;render&quot;:[0,null]}],[0,{&quot;id&quot;:[0,&quot;from-transistor-to-system-a-friendly-guide-to-computer-architecture/6-cpu.mdx&quot;],&quot;data&quot;:[0,{&quot;author&quot;:[0,&quot;Gianni&quot;],&quot;collection&quot;:[0,&quot;From Transistor to System: A Friendly Guide to Computer Architecture&quot;],&quot;chapter&quot;:[0,6],&quot;title&quot;:[0,&quot;Inside the CPU: How Instructions Are Fetched, Decoded, and Executed&quot;],&quot;shortname&quot;:[0,&quot;CPU&quot;],&quot;date&quot;:[3,&quot;2025-12-14T00:00:00.000Z&quot;],&quot;tags&quot;:[1,[[0,&quot;Computer Architecture&quot;]]],&quot;metaTags&quot;:[1,[[0,&quot;CPU instruction cycle&quot;],[0,&quot;fetch decode execute explained&quot;],[0,&quot;how a CPU works&quot;],[0,&quot;computer architecture basics&quot;],[0,&quot;machine instruction execution&quot;]]],&quot;difficulty&quot;:[0,&quot;Intermediate&quot;],&quot;readTime&quot;:[0,&quot;8 min&quot;],&quot;image&quot;:[0,{&quot;src&quot;:[0,&quot;/assets/computer-architecture-transistor-to-system-guide.BpaNqm1a.png&quot;],&quot;width&quot;:[0,1024],&quot;height&quot;:[0,1024],&quot;format&quot;:[0,&quot;png&quot;]}],&quot;alt&quot;:[0,&quot;Cover image for the blog series \&quot;From Transistor to System: A Friendly Guide to Computer Architecture,\&quot; showing various computer components in a cheerful, cartoon style&quot;],&quot;description&quot;:[0,&quot;Learn how a CPU actually runs programs by coordinating registers, the ALU, and the control unit. This chapter explains the fetch–decode–execute instruction cycle with clear examples and practical insights into modern computer architecture.&quot;]}],&quot;body&quot;:[0,&quot;Up to now, we’ve looked at the main pieces of the CPU separately: the ALU, the control unit, and the registers.\r\n\r\nIn this chapter, we bring everything together and see how they actually cooperate to run a program.\r\nThis is where the CPU stops being a set of parts and becomes a machine that thinks in a very mechanical way.\r\n\r\n## Bringing it all together\r\n\r\nA CPU is essentially a loop: it constantly fetches instructions from memory, interprets them, and performs the required actions.\r\n\r\nHere’s how the major components play their roles:\r\n\r\n### Registers\r\n\r\nThese are tiny, ultra-fast storage slots inside the CPU. They hold:\r\n\r\n- the current instruction (IR)\r\n- the next instruction’s address (PC or IP)\r\n- operands for the ALU\r\n- results produced by the ALU\r\n- temporary values the control unit needs\r\n\r\n### ALU (Arithmetic Logic Unit)\r\n\r\nThe ALU performs mathematical operations (like addition or subtraction) and logical operations (like AND, OR, or comparison).\r\n\r\nIt does nothing on its own; it is activated only when the control unit tells it to.\r\n\r\n### Control Unit\r\n\r\nThis is the “orchestrator.” It:\r\n\r\n- reads machine instructions\r\n- decodes what they mean\r\n- activates the right circuits (ALU, registers, memory access paths)\r\n- manages timing so each step happens in the correct order\r\n\r\nYou can imagine it as the conductor of an orchestra. Without it, the ALU and registers just sit there with nothing to do.\r\n\r\nWhen all three work together, the CPU becomes a general-purpose engine that can run any program expressed in machine code.\r\n\r\n## The Instruction Cycle (Fetch → Decode → Execute)\r\n\r\nEvery CPU instruction follows the same high-level process called the **instruction cycle**:\r\n\r\n### 1. Fetch\r\n\r\nThe control unit loads the next instruction from memory into the **Instruction Register (IR)**.\r\n\r\n- The **Program Counter (PC)** holds the address of that instruction.\r\n- After fetching, the PC is incremented to point to the next one.\r\n\r\n### 2. Decode\r\n\r\nThe control unit examines the bits of the instruction to figure out:\r\n\r\n- What operation it represents (e.g., ADD, LOAD, JUMP)\r\n- Which registers are involved\r\n- Whether a memory address or an immediate value is needed\r\n- What signals must be sent to the ALU, registers, and buses\r\n\r\nThis is where microcode (if used) may step in to guide complex instructions.\r\n\r\n### 3. Execute\r\n\r\nThe CPU performs the required action.\r\n\r\nThis may involve:\r\n\r\n- doing arithmetic in the ALU\r\n- moving data between registers\r\n- loading from or storing to memory\r\n- updating flags in the status register\r\n- changing the PC (for jumps and branches)\r\n\r\nSome instructions also include a **write-back** phase, where the result is stored in the destination register.\r\n\r\nAfter execution finishes, the cycle repeats with the next instruction, billions of times per second.\r\n\r\n![The CPUs fetch decode execute store cycle ](assets/fetch-decode-execute-store-cycle.jpg)\r\n\r\n## Example Walkthrough: Executing a Simple Instruction\r\n\r\nLet’s break down a simple machine instruction:\r\n\r\n```nasm\r\nADD R1, R2, R3\r\n```\r\n\r\nMeaning: R1 = R2 + R3\r\n\r\nHere’s how the CPU performs it:\r\n\r\n### Step 1: Fetch\r\n\r\n1. The PC holds the address of the `ADD` instruction in memory.\r\n2. The control unit loads this instruction into the Instruction Register (IR).\r\n3. The PC increments to point to the next instruction.\r\n\r\n### Step 2: Decode\r\n\r\nThe control unit decodes the bits stored in IR:\r\n\r\n- operation → ADD\r\n- source registers → R2 and R3\r\n- destination register → R1\r\n- ALU operation needed → addition\r\n\r\nThe control unit now prepares the ALU and registers.\r\n\r\n### Step 3: Execute\r\n\r\n1. The values inside registers R2 and R3 are sent to the ALU’s input lines.\r\n2. The ALU performs the addition.\r\n3. The result is placed on the CPU’s internal data bus.\r\n4. The control unit writes the result into register R1.\r\n5. The ALU updates the flags register (Zero, Carry, Overflow, etc.) if needed.\r\n\r\n### Step 4: Continue\r\n\r\nThe CPU goes back to the fetch stage, now using the updated PC to load the next instruction.\r\n\r\nThis process repeats endlessly, carrying out a program step by step.\r\n\r\n### Why This Matters\r\n\r\nUnderstanding this cycle is key to comprehending how all software works, from a simple “Hello World” program to a complex video game or operating system.\r\n\r\nEverything a computer does boils down to:\r\n\r\n1. **Fetch** an instruction\r\n2. **Decode** it\r\n3. **Execute** it\r\n4. Repeat\r\n\r\nAnd inside that cycle, the ALU, registers, and control unit cooperate with precise timing to turn binary instructions into meaningful work.&quot;],&quot;filePath&quot;:[0,&quot;src/content/posts/from-transistor-to-system-a-friendly-guide-to-computer-architecture/6-cpu.mdx&quot;],&quot;assetImports&quot;:[1,[[0,&quot;./assets/computer-architecture-transistor-to-system-guide.png&quot;]]],&quot;digest&quot;:[0,&quot;a05c7c2621592109&quot;],&quot;deferredRender&quot;:[0,true],&quot;collection&quot;:[0,&quot;posts&quot;],&quot;slug&quot;:[0,&quot;from-transistor-to-system-a-friendly-guide-to-computer-architecture/6-cpu&quot;],&quot;render&quot;:[0,null]}],[0,{&quot;id&quot;:[0,&quot;finding-p-values-and-false-hope/3-tranching.mdx&quot;],&quot;data&quot;:[0,{&quot;author&quot;:[0,&quot;Quinn&quot;],&quot;collection&quot;:[0,&quot;Finding P values and false hope&quot;],&quot;chapter&quot;:[0,3],&quot;title&quot;:[0,&quot;Tranching in Collateralized Debt: Senior vs Mezzanine vs Equity Explained&quot;],&quot;shortname&quot;:[0,&quot;Tranching&quot;],&quot;date&quot;:[3,&quot;2025-12-21T00:00:00.000Z&quot;],&quot;tags&quot;:[1,[[0,&quot;Data Science&quot;]]],&quot;metaTags&quot;:[1,[[0,&quot;Collateralized Debt Obligations&quot;],[0,&quot;CDO tranching&quot;],[0,&quot;credit risk modeling&quot;],[0,&quot;financial simulations&quot;],[0,&quot;structured finance&quot;]]],&quot;difficulty&quot;:[0,&quot;Intermediate&quot;],&quot;readTime&quot;:[0,&quot;18 min&quot;],&quot;image&quot;:[0,{&quot;src&quot;:[0,&quot;/assets/tranching-in-collaterized-debt.h8tTybnR.png&quot;],&quot;width&quot;:[0,1584],&quot;height&quot;:[0,672],&quot;format&quot;:[0,&quot;png&quot;]}],&quot;alt&quot;:[0,&quot;Illustration explaining how loans and bonds work, including interest, repayment, and default risk&quot;],&quot;description&quot;:[0,&quot;An in-depth introduction to collateralized debt obligations (CDOs), explaining tranching, credit risk redistribution, and how senior, mezzanine, and junior tranches shape risk and return using analytical examples and simulations.&quot;]}],&quot;body&quot;:[0,&quot;Few financial products capture the imagination and confusion of investors quite like Collateralized Debt Obligations (CDOs). Born of the desire to turn illiquid debt into tradable securities, CDOs bundle cash flows and slice them into layers of risk and reward. This “tranching” process doesn’t just redistribute exposure; it fundamentally changes how investors think about credit, yield, and safety.\r\n\r\nAt their core, CDOs are all about tranching: taking a pool of underlying loans or bonds and splitting the cash flows into different paths. Each path has its own payment priority; senior tranches are at the top, protected from defaults by junior tranches at the bottom. These junior tranches might be the first to absorb any defaults, but they will also return eye-watering returns. The structure of CDOs allows the same pool of bonds/loans to serve many different investors willing to take different levels of risk.\r\n\r\nIn this post, we’ll see how a CDO is built from different layers, how collateral is assembled, how tranching is done, and why a simple change in structure can make the same assets appear much safer or riskier. This post will be an introduction to living life in the tranches.\r\n\r\n# Collateralized Debt Obligations\r\n\r\nThere are investors who like to take a lot of risk in exchange for the chance of a high return, and there are investors who might not be as willing to take that same level of risk. A pension fund might not be willing to take a high risk and will settle for a lower return and coupon. Other investors seeking higher returns might be willing to take greater risk. Companies can use CDOs to meet this specific demand ratio. Let’s explore a simple example to see how this would work.\r\n\r\nAssume we have two very simple bonds that at time $t=0$ cost $€X$. At time $t=1$, they will either repay $€X+c*€X$  with probability $p$, or they will repay $€0$ with probability $1-p$. Assume these two bonds have an independent chance of defaulting. In this situation, we have a pension fund that is legally prohibited from taking on more than a certain level of risk. The two bonds we have are currently too risky for the pension fund to purchase. How can we issue a new financial bond so the pension fund can make this investment?\r\n\r\n![Explains a CDO structure](assets/visualizing-a-cdo-structure.png)\r\n\r\nWe do this by buying the two bonds and putting them into a legal structure that protects them from the outside world. The cash flow arising from this new structure is divided between investors in a special way. We create two new fixed-income securities: a junior and senior tranche. These junior and senior tranches refer to the order in which investors are paid out in case of a default. The junior tranche will only get paid after the senior tranche has been paid. If our CDO is split evenly between junior and senior tranches, what would happen if one of the bonds in the CDO defaulted? Well, the senior tranche would be paid with the principal supplied by the bond that did not default. However, the junior tranche would lose its principal, as there is no further cash flow available. Only in the unlikely event that all bonds in our CDO default would the senior tranche not get back its principal. \r\n\r\nTo offset this risk for junior tranche holders, they will receive a higher coupon. So, if neither of the bonds in our simple CDO defaults, both the junior and senior tranches will receive their principal, and on top of that principal, the junior tranche will receive a higher coupon. We need to find a coupon high enough so that investors in both tranches are willing to buy the bond.\r\n\r\nLet&#39;s assume that the junior tranches have a probability *p* of defaulting; therefore, the senior tranche has a probability $p^2$ of defaulting. In the event of a bond default, the recovery rate is $R=0$. Given this, the minimum platatable coupon rate we need to pay the senior tranche is:\r\n\r\n$$\r\nc_A = \\frac{p^2+r}{1-p^2}\r\n$$\r\n\r\nThe interest remaining to pay the junior tranche can be found using the formula:\r\n\r\n$$\r\nc_B = \\frac{2p(1+r)+r+p^2}{1-p^2}\r\n$$\r\n\r\nBecause it is highly unlikely that both bonds in our CDO default, the junior tranche actually has a small recovery rate if only one bond defaults. The bond that did not default will still pay its coupon, allowing for some recovery rate. The recovery rate *R_2* for the junior tranche in this case can be calculated as:\r\n\r\n$$\r\nR_2 = \\frac{p(1+r)}{1+r+2p(1+r)} = \\frac{p(1+r)}{(1+r)(1+2p)} = \\frac{p}{1+2p}\r\n$$\r\n\r\n# CDO Simulations\r\n\r\nHaving a CDO consisting of just two bonds is a good example to get a clear understanding of how they work. However, this kind of CDO is not very realistic in the actual world. Luckily, even CDOs composed of many different bonds share the same cash flow principles as the small CDO we have discussed so far.\r\n\r\nOur new CDO will consist of three tranches: A, B, and C. Tranche A is the senior tranche, and tranche C is the junior tranche. In this simulation, we do not consider the bonds&#39; ability to pay a fair coupon rate, as we did before. All the parameters for this simulation are listed in the table below.\r\n\r\n| $r$ | 3% |\r\n| --- | --- |\r\n| $X$ | €1000 |\r\n| $p$ | 5% |\r\n| $R$ | 0% |\r\n| **$c_{fair}$** | 8% |\r\n| $c$ | 12% |\r\n\r\nThe thicknesses of tranches A, B and C in our CDO are shown in the table below. Tranche A and B will be the biggest tranches, and our junior tranche C will simply receive whatever is left after tranches A and B have been paid. \r\n\r\n| **Tranche** | **Tickeness** | **Coupon** | **Coupon %** |\r\n| --- | --- | --- | --- |\r\n| Tranche A | 70% | $c_{A}$ | 3% |\r\n| Tranche B | 20% | $c_{B}$ | 8% |\r\n| Tranche C | 10% | $c_{C}$ | 15% |\r\n\r\nIn the previous post about *default risk,* we wrote a small script to simulate the result of a simple bond structure. Let&#39;s adjust this script a bit so we can simulate a more complicated CDO structure with different tranches, ticknesses, and coupons. \r\n\r\n```python\r\nimport random\r\nimport math\r\nfrom typing import List\r\n\r\nclass BondPricing:\r\n    def __init__(\r\n        self,\r\n        trials: int,\r\n        num_loans: int,\r\n        loan_principal: float,\r\n        interest_rate: float,\r\n        default_prob: float,\r\n        tranche_thickness: List[float],\r\n        tranche_coupons: List[float],\r\n        tranche_min_recovery: List[float],\r\n    ):\r\n        self.trials = trials\r\n        self.num_loans = num_loans\r\n        self.X = loan_principal\r\n        self.r = interest_rate\r\n        self.p = default_prob\r\n        self.tranche_thickness = tranche_thickness\r\n        self.tranche_coupons = tranche_coupons\r\n        self.tranche_min_recovery = tranche_min_recovery\r\n\r\n        self.validate_tranches()\r\n\r\n    def validate_tranches(self) -&gt; None:\r\n        if not (\r\n            len(self.tranche_thickness)\r\n            == len(self.tranche_coupons)\r\n            == len(self.tranche_min_recovery)\r\n        ):\r\n            raise RuntimeError(\&quot;All tranche vectors must have identical sizes.\&quot;)\r\n\r\n        total = 0.0\r\n        for t in self.tranche_thickness:\r\n            if t &lt;= 0.0:\r\n                raise RuntimeError(\&quot;Tranche thickness must be positive.\&quot;)\r\n            total += t\r\n\r\n        if abs(total - 1.0) &gt; 1e-6:\r\n            raise RuntimeError(\&quot;Tranche thickness must sum to 1.0\&quot;)\r\n\r\n        for rr in self.tranche_min_recovery:\r\n            if rr &lt; 0.0 or rr &gt; 1.0:\r\n                raise RuntimeError(\r\n                    \&quot;Tranche minimum recovery must be between 0 and 1\&quot;\r\n                )\r\n\r\n    def get_portfolio_principal(self) -&gt; float:\r\n        return self.num_loans * self.X\r\n\r\n    def get_num_tranches(self) -&gt; int:\r\n        return len(self.tranche_thickness)\r\n\r\n    def simulate_bond_pricing(self) -&gt; None:\r\n        n_tranches = self.get_num_tranches()\r\n        portfolio_notional = self.get_portfolio_principal()\r\n\r\n        tranche_returns = [[] for _ in range(n_tranches)]\r\n\r\n        for _ in range(self.trials):\r\n            default_count = 0\r\n            performing_count = 0\r\n            total_loss = 0.0\r\n            coupon_pool = 0.0\r\n\r\n            # Simulate loan defaults\r\n            for _ in range(self.num_loans):\r\n                is_default = random.random() &lt; self.p\r\n                if is_default:\r\n                    loan_recovery = 0.40\r\n                    default_count += 1\r\n                    total_loss += self.X * (1.0 - loan_recovery)\r\n                else:\r\n                    performing_count += 1\r\n                    coupon_pool += self.X * self.r\r\n\r\n            # Initialize tranches\r\n            tranche_init = [\r\n                t * portfolio_notional for t in self.tranche_thickness\r\n            ]\r\n            tranche_remaining = tranche_init.copy()\r\n\r\n            remaining_loss = total_loss\r\n\r\n            # Loss waterfall (junior → senior)\r\n            for i in range(n_tranches):\r\n                if remaining_loss &lt;= 1e-12:\r\n                    break\r\n                absorbed = min(remaining_loss, tranche_remaining[i])\r\n                tranche_remaining[i] -= absorbed\r\n                remaining_loss -= absorbed\r\n\r\n            # Coupon waterfall (senior → junior)\r\n            tranche_coupons_paid = [0.0] * n_tranches\r\n            for i in reversed(range(n_tranches)):\r\n                if tranche_remaining[i] &gt; 1e-12:\r\n                    due = tranche_init[i] * self.tranche_coupons[i]\r\n                    paid = min(coupon_pool, due)\r\n                    tranche_coupons_paid[i] = paid\r\n                    coupon_pool -= paid\r\n\r\n            # Compute returns\r\n            for i in range(n_tranches):\r\n                end_value = tranche_remaining[i] + tranche_coupons_paid[i]\r\n                if tranche_init[i] &gt; 0.0:\r\n                    ret = (end_value - tranche_init[i]) / tranche_init[i]\r\n                else:\r\n                    ret = 0.0\r\n                tranche_returns[i].append(ret)\r\n\r\n        # Output results\r\n        print(\&quot;\\n================= TRANCHE RESULTS =================\&quot;)\r\n\r\n        for i in range(n_tranches):\r\n            rets = tranche_returns[i]\r\n\r\n            mean = sum(rets) / self.trials\r\n            best = max(rets)\r\n            worst = min(rets)\r\n\r\n            variance = sum((r - mean) ** 2 for r in rets) / self.trials\r\n            stddev = math.sqrt(variance)\r\n\r\n            print(f\&quot;\\n--- Tranche {i + 1} ---\&quot;)\r\n            print(f\&quot;Thickness: {self.tranche_thickness[i] * 100:.2f}%\&quot;)\r\n            print(f\&quot;Coupon:    {self.tranche_coupons[i] * 100:.2f}%\&quot;)\r\n            print(f\&quot;Min Recov: {self.tranche_min_recovery[i] * 100:.2f}%\&quot;)\r\n            print(f\&quot;Avg Return: {mean * 100:.2f}%\&quot;)\r\n            print(f\&quot;Best Case:  {best * 100:.2f}%\&quot;)\r\n            print(f\&quot;Worst Case: {worst * 100:.2f}%\&quot;)\r\n            print(f\&quot;Std Dev:    {stddev * 100:.2f}%\&quot;)\r\n\r\n        print(\&quot;===================================================\&quot;)\r\n\r\n```\r\n\r\nCompared to the previous script, we added some extra variables and methods to this header. We added methods to validate the tranches&#39; configuration, to calculate the total principal of the CDO portfolio, and to count the number of tranches in the CDO. When running this class, we will get the following output:\r\n\r\n```cpp\r\n================= TRANCHE RESULTS =================\r\n\r\n--- Tranche 1 ---\r\nThickness: 10%\r\nCoupon:    15%\r\nMin Recov: 30%\r\nAvg Return: -0.955%\r\nBest Case:  15%\r\nWorst Case: -100%\r\nStd Dev:    29.3405%\r\n\r\n--- Tranche 2 ---\r\nThickness: 20%\r\nCoupon:    8%\r\nMin Recov: 10%\r\nAvg Return: 7.6%\r\nBest Case:  8%\r\nWorst Case: -62%\r\nStd Dev:    3.41174%\r\n\r\n--- Tranche 3 ---\r\nThickness: 70%\r\nCoupon:    3%\r\nMin Recov: 0%\r\nAvg Return: 3%\r\nBest Case:  3%\r\nWorst Case: 3%\r\nStd Dev:    3.81639e-14%\r\n===================================================\r\n```\r\n\r\nThe simulation demonstrates how tranche design fundamentally shapes the risk-return profile of a CDO. Even though the underlying loan pool is homogeneous and relatively simple. The distribution of losses and coupons across tranches produces dramatically different outcomes.\r\n\r\nTo better understand these outcomes, we can analyze each tranche&#39;s performance using a Sharpe-like ratio, which provides insight into how returns compare to volatility. The junior tranche absorbs losses first and carries substantial risk, exhibiting high volatility with outcomes ranging from full principal loss to full coupon payment. Its average negative return suggests that it effectively sells insurance against portfolio defaults, highlighting a low risk-adjusted return.\r\n\r\nThe mezzanine tranche offers a more balanced profile, with lower volatility than the junior tranche. It presents a smaller coupon and a slightly lower exposure to losses, meaning it would require significant CDO-wide losses before it incurs losses. As such, its risk-adjusted return is more stable than that of the junior tranche.\r\n\r\nFinally, the senior tranche resembles a nearly risk-free instrument, with losses rarely affecting it. Its consistent returns, even in worst-case scenarios, reflect a high risk-adjusted return, demonstrating the stability that appeals to conservative investors. By relating returns to volatility in this manner, investors can make more informed decisions when assessing the appeal of each tranche. This type of risk-adjusted analysis is highly relevant when evaluating CDO investments.&quot;],&quot;filePath&quot;:[0,&quot;src/content/posts/finding-p-values-and-false-hope/3-tranching.mdx&quot;],&quot;assetImports&quot;:[1,[[0,&quot;./assets/tranching-in-collaterized-debt.png&quot;]]],&quot;digest&quot;:[0,&quot;d37f3ada1b99a6bd&quot;],&quot;deferredRender&quot;:[0,true],&quot;collection&quot;:[0,&quot;posts&quot;],&quot;slug&quot;:[0,&quot;finding-p-values-and-false-hope/3-tranching&quot;],&quot;render&quot;:[0,null]}],[0,{&quot;id&quot;:[0,&quot;from-transistor-to-system-a-friendly-guide-to-computer-architecture/7-beyond.mdx&quot;],&quot;data&quot;:[0,{&quot;author&quot;:[0,&quot;Gianni&quot;],&quot;collection&quot;:[0,&quot;From Transistor to System: A Friendly Guide to Computer Architecture&quot;],&quot;chapter&quot;:[0,7],&quot;title&quot;:[0,&quot;Beyond the CPU: I/O, Buses, Multicore Systems, and Modern Computer Architecture&quot;],&quot;shortname&quot;:[0,&quot;Beyond&quot;],&quot;date&quot;:[3,&quot;2025-12-28T00:00:00.000Z&quot;],&quot;tags&quot;:[1,[[0,&quot;Computer Architecture&quot;]]],&quot;metaTags&quot;:[1,[[0,&quot;CPU&quot;],[0,&quot;I/O Systems&quot;],[0,&quot;Buses&quot;],[0,&quot;Multicore Processors&quot;],[0,&quot;GPU&quot;],[0,&quot;DMA&quot;],[0,&quot;Operating Systems&quot;],[0,&quot;how CPUs communicate with hardware&quot;],[0,&quot;memory mapped I/O&quot;],[0,&quot;interrupts vs polling&quot;],[0,&quot;multicore vs GPU&quot;],[0,&quot;modern computer systems&quot;]]],&quot;difficulty&quot;:[0,&quot;Intermediate&quot;],&quot;readTime&quot;:[0,&quot;10 min&quot;],&quot;image&quot;:[0,{&quot;src&quot;:[0,&quot;/assets/computer-architecture-transistor-to-system-guide.BpaNqm1a.png&quot;],&quot;width&quot;:[0,1024],&quot;height&quot;:[0,1024],&quot;format&quot;:[0,&quot;png&quot;]}],&quot;alt&quot;:[0,&quot;Cover image for the blog series \&quot;From Transistor to System: A Friendly Guide to Computer Architecture,\&quot; showing various computer components in a cheerful, cartoon style&quot;],&quot;description&quot;:[0,&quot;Learn how modern computers work beyond the CPU. This chapter explores I/O systems, buses, interrupts, DMA, multicore processors, GPUs, and how all components cooperate in a complete computer system.&quot;]}],&quot;body&quot;:[0,&quot;By now, we have taken a deep look inside the CPU. We’ve seen how instructions are fetched, decoded, and executed, how registers and memory work together, and how the ALU performs calculations under the control of carefully timed signals.\r\n\r\nBut a CPU by itself is not very useful. A computer becomes powerful only when the CPU can **communicate with the outside world**, store data permanently, and share work with other processing units. In this chapter, we step beyond the CPU and look at the larger system that surrounds it.\r\n\r\n## The CPU Is Not Alone\r\n\r\nThe CPU is often called the “brain” of the computer, but even a brain cannot function in isolation. A CPU cannot directly:\r\n\r\n- Read keystrokes from a keyboard\r\n- Display pixels on a screen\r\n- Store files permanently\r\n- Send data over a network\r\n\r\nTo do any of these things, it must work together with other hardware components. These components are connected through communication pathways and coordinated by the operating system. Together, they form a **computer system**, not just a processor.\r\n\r\n## Input and Output (I/O) Systems\r\n\r\n**Input/Output (I/O)** refers to how a computer exchanges data with the outside world.\r\n\r\n- **Input devices** send data *into* the system (keyboard, mouse, camera, network).\r\n- **Output devices** receive data *from* the system (display, speakers, printer).\r\n- Many devices, like storage and network cards, do both.\r\n\r\n### How the CPU Talks to Devices\r\n\r\nFrom the CPU’s point of view, hardware devices look like special regions of memory. Each device exposes **control registers** that the CPU can read or write.\r\n\r\nFor example:\r\n\r\n- Writing a value to a graphics device register might change a pixel.\r\n- Reading a network register might return received data.\r\n\r\nThis approach is often called **memory-mapped I/O**. The CPU uses the same load and store instructions it already knows; it just talks to *devices* instead of RAM.\r\n\r\n### Polling vs. Interrupts\r\n\r\nThere are two main ways a CPU can interact with devices:\r\n\r\n- **Polling** (is like a chef walking to the front door every 30 seconds to see if a customer has arrived):\r\n    \r\n    The CPU repeatedly checks a device to see if it’s ready.\r\n    \r\n    - Simple, but inefficient.\r\n    - Wastes CPU time if nothing happens.\r\n- **Interrupts** (are like a doorbell. The chef can keep cooking until the bell rings):\r\n    \r\n    The device signals the CPU when it needs attention.\r\n    \r\n    - Much more efficient.\r\n    - Allows the CPU to work on other tasks meanwhile.\r\n\r\nModern systems rely heavily on interrupts to stay responsive.\r\n\r\n## Buses: The System’s Highways\r\n\r\nAll communication inside a computer happens over **buses**, shared pathways that carry signals between components.\r\n\r\nA bus typically carries three kinds of information:\r\n\r\n- **Data:** the actual values being transferred\r\n- **Addresses:** where the data should go. The \&quot;width\&quot; of this bus determines how much memory the CPU can \&quot;see.\&quot; For example, a 32-bit address bus can name about 4 billion unique locations, which is why many 32-bit systems are limited to around 4 GB of RAM without special techniques.\r\n- **Control signals:** read, write, interrupt, and timing information\r\n\r\nYou can think of buses as highways:\r\n\r\n- Wider highways move more data at once.\r\n- Faster highways deliver data more quickly.\r\n\r\n&gt; Did you know?: Modern smartphone and laptops like Apple’s M-series, often pack the CPU, GPU and RAM into a single **systems-on-chip** (SoC). This reduces the \&quot;highway distance\&quot; data has to travel, improving performance and energy efficiency.\r\n&gt; \r\n\r\n### Modern Interconnects\r\n\r\nIn modern computers, simple shared buses have largely been replaced by faster, point-to-point connections, such as:\r\n\r\n- **PCI Express (PCIe):** used for GPUs, SSDs, and expansion cards\r\n- **Memory buses:** dedicated links between CPU and RAM\r\n\r\nThe details are complex, but the idea is simple: **moving data efficiently is just as important as computing it.**\r\n\r\n## Peripheral Communication\r\n\r\nAny hardware device outside the CPU and main memory is called a **peripheral**.\r\n\r\nCommon peripherals include:\r\n\r\n- Storage devices\r\n- USB devices\r\n- Network interfaces\r\n- Graphics cards\r\n\r\n### The Role of the Operating System\r\n\r\nApplications do not talk to hardware directly. Instead, the **operating system** acts as an intermediary:\r\n\r\n- It provides **device drivers** for each type of hardware.\r\n- It presents a consistent interface to software.\r\n- It handles errors, timing, and security.\r\n\r\nThis is why the same program can run on many different machines without knowing the details of the hardware underneath.\r\n\r\n### Direct Memory Access (DMA)\r\n\r\nSome devices can transfer data directly to and from RAM without involving the CPU. This is called **Direct Memory Access (DMA)**.\r\n\r\nWith DMA:\r\n\r\n- The CPU sets up the transfer\r\n- The device moves the data itself\r\n- The CPU is interrupted when the transfer finishes\r\n\r\nDMA allows high-speed devices, like SSDs and network cards, to operate efficiently without slowing down the CPU. While the device moves data, the CPU remains free to run the OS or execute programs, which is why modern systems feel responsive even during large transfers.\r\n\r\n## Multicore Processors\r\n\r\nFor many years, CPUs became faster by increasing their clock speed. Eventually, this approach ran into physical limits related to power consumption and heat.\r\n\r\nThe solution was not one faster core, but **multiple cores**.\r\n\r\n### What Multicore Means\r\n\r\nA multicore processor contains:\r\n\r\n- Multiple independent CPU cores\r\n- Each has its own registers and execution units\r\n- Often sharing cache and main memory\r\n\r\nEach core runs its own instruction cycle, in parallel with the others.\r\n\r\n### Parallelism and Concurrency\r\n\r\n- **Concurrency** refers to managing multiple tasks simultaneously.\r\n- **Parallelism** means executing tasks simultaneously.\r\n\r\nMulticore processors make true parallel execution possible, but they also introduce challenges:\r\n\r\n- Coordinating shared memory\r\n- Avoiding race conditions\r\n- Keeping cores busy\r\n\r\nThese challenges are handled mostly by software (compilers, runtimes, and operating systems).\r\n\r\n## GPUs: Specialised Processors\r\n\r\nGraphics Processing Units (**GPUs**) were originally designed to draw images on screens. Over time, they evolved into powerful processors in their own right.\r\n\r\n### CPU vs. GPU\r\n\r\n- **CPU:**\r\n    - Few **complex cores\r\n    - Complex control logic\r\n    - Excellent at decision-making and serial tasks\r\n- **GPU:**\r\n    - Thousands of simpler cores\r\n    - Designed for massive parallel workloads\r\n    - Excellent at doing the same operation on lots of data\r\n\r\nThis makes GPUs ideal for:\r\n\r\n- Graphics rendering\r\n- Image and video processing\r\n- Machine learning\r\n- Scientific simulations\r\n\r\nIn modern systems, the CPU often acts as a **coordinator**, handing large data-parallel tasks to the GPU.\r\n\r\n## The Modern Computer as a Team\r\n\r\nA modern computer is not a single processor working alone; it is a **team of specialised components**:\r\n\r\n- The **CPU** coordinates and executes instructions.\r\n- **Memory** holds active data and programs.\r\n- **Storage** keeps data long-term.\r\n- **Peripherals** handle input and output.\r\n- The **GPU** accelerates massively parallel workloads.\r\n- The **Operating System** orchestrates communication and resource sharing.\r\n\r\nEach part plays a role, and performance depends on how well they work together.\r\n\r\n![High-level diagram of a computer system illustrating how the CPU, main memory, GPU, and I/O devices communicate over a system bus.](assets/computer-system-architecture-cpu-memory-gpu-io-diagram.jpg)\r\n\r\n## Closing Thoughts\r\n\r\nWe started this journey at the lowest levels: bits, logic gates, and simple operations. From there, we built up to CPUs, memory, and instruction cycles. Now we see the bigger picture: a computer is a carefully orchestrated system designed to move and transform information efficiently.\r\n\r\nAt its core, everything still comes down to simple steps:\r\n\r\n- move data\r\n- perform operations\r\n- make decisions\r\n\r\nUnderstanding these foundations makes everything else, operating systems, compilers, graphics, and networking, easier to reason about.\r\n\r\nThe CPU may be the heart of the machine, but it is the **system around it** that brings computation to life.&quot;],&quot;filePath&quot;:[0,&quot;src/content/posts/from-transistor-to-system-a-friendly-guide-to-computer-architecture/7-beyond.mdx&quot;],&quot;assetImports&quot;:[1,[[0,&quot;./assets/computer-architecture-transistor-to-system-guide.png&quot;]]],&quot;digest&quot;:[0,&quot;e68b0777f92c81ab&quot;],&quot;deferredRender&quot;:[0,true],&quot;collection&quot;:[0,&quot;posts&quot;],&quot;slug&quot;:[0,&quot;from-transistor-to-system-a-friendly-guide-to-computer-architecture/7-beyond&quot;],&quot;render&quot;:[0,null]}]]]}" ssr client="only" opts="{&quot;name&quot;:&quot;SearchModal&quot;,&quot;value&quot;:true}"></astro-island> <div data-astro-transition-persist="find-me-on-the-other-side" id="cc-container"> <script type="module" src="/assets/CookieConsent.astro_astro_type_script_index_0_lang.BGS9yL8D.js"></script> <script>
                // Restore the `show--consent` class if it was present before the page swap
                document.addEventListener(
                    "astro:before-preparation",
                    (event) => {
                        const htmlClassName =
                            window.document.documentElement.className;
                        const consentClassPresent = htmlClassName.includes(
                            "show--consent",
                        )
                            ? true
                            : false;
                        window._showConsentClass = consentClassPresent;
                    },
                );

                document.addEventListener("astro:before-swap", (event) => {
                    const showConsent = window._showConsentClass
                        ? ` show--consent`
                        : "";
                    event.newDocument.documentElement.className += showConsent;
                });
            </script> </div> </body> </html>